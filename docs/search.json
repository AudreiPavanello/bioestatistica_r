[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bioestatística Aplicada à Saúde usando R",
    "section": "",
    "text": "Prefácio\nEste livro foi desenvolvido como material didático para o curso de Bioestatística Aplicada à Saúde utilizando o Software R, ministrado pelos professores:",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#sobre-este-livro",
    "href": "index.html#sobre-este-livro",
    "title": "Bioestatística Aplicada à Saúde usando R",
    "section": "Sobre este Livro",
    "text": "Sobre este Livro\nEste material combina teoria e prática, apresentando conceitos fundamentais de bioestatística aplicados a dados reais da área da saúde. Através de exemplos práticos e códigos executáveis em R, você aprenderá a manipular, analisar e visualizar dados de saúde pública.\nTodos os exemplos utilizam dados reais de internações hospitalares de Maringá-PR referentes ao ano de 2024, disponibilizados pelo Sistema de Informações Hospitalares (SIH) do SUS.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#como-usar-este-livro",
    "href": "index.html#como-usar-este-livro",
    "title": "Bioestatística Aplicada à Saúde usando R",
    "section": "Como Usar este Livro",
    "text": "Como Usar este Livro\n\nCódigos Executáveis: Todos os códigos apresentados são executáveis e podem ser reproduzidos em seu próprio ambiente R\nEstrutura Progressiva: O conteúdo é apresentado de forma progressiva, desde conceitos básicos até análises avançadas\nExemplos Práticos: Cada capítulo contém exemplos práticos aplicados a dados reais de saúde pública",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#estrutura-do-livro",
    "href": "index.html#estrutura-do-livro",
    "title": "Bioestatística Aplicada à Saúde usando R",
    "section": "Estrutura do Livro",
    "text": "Estrutura do Livro\n\n1. Introdução ao R e RStudio\nPrimeiros passos com R, interface do RStudio, lógica de programação e boas práticas de código.\n\n\n2. Manipulação de Dados\nImportação e limpeza de dados usando o pacote tidyverse, principais funções de manipulação de data frames.\n\n\n3. Análise Exploratória de Dados\nEstatística descritiva com gtsummary e visualização de dados com ggplot2.\n\n\n4. Testes Estatísticos\nTestes de hipóteses paramétricos e não-paramétricos, incluindo teste t, ANOVA, Mann-Whitney, Kruskal-Wallis, qui-quadrado, Fisher, e correlações.\n\n\n5. Regressão Linear, Logística e Multinomial\nConstrução e interpretação de modelos de regressão linear, logística e multinomial, cálculo e interpretação de odds ratio.\n\n\n6. Análise Psicométrica\nConfiabilidade (Alfa de Cronbach, Ômega de McDonald), Análise Fatorial Exploratória e Confirmatória, validação de escalas e instrumentos.\n\n\n7. Análise de Dados Textuais e Mineração de Texto\nTokenização, análise de frequência, word clouds, análise de sentimento com léxico e LLMs, e regressão multinomial para dados textuais.",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#pré-requisitos",
    "href": "index.html#pré-requisitos",
    "title": "Bioestatística Aplicada à Saúde usando R",
    "section": "Pré-requisitos",
    "text": "Pré-requisitos\nPara acompanhar este livro, você precisará:\n\nR (versão 4.0 ou superior): https://cran.r-project.org/\nRStudio (versão recente): https://posit.co/download/rstudio-desktop/\nPacotes R necessários:\nPacotes Básicos (Capítulos 1-3):\n\ntidyverse\nreadxl\njanitor\ngtsummary\nofficer\nflextable\nggpubr\n\nTestes Estatísticos (Capítulo 4):\n\ncar\nFSA\nvcd\n\nRegressão (Capítulo 5):\n\njtools\nsjPlot\nlmtest\nnnet\n\nAnálise Psicométrica (Capítulo 6):\n\npsych\nlavaan\nsemPlot\nqgraph\ncorrplot\nGGally\n\nAnálise de Texto (Capítulo 7):\n\ntidytext\nwordcloud\nquanteda\nlexiconPT\ntm\nmall (requer instalação prévia do Ollama - opcional)\nstopwords\n\n\nVocê pode instalar todos os pacotes executando:\n# Lista de pacotes necessários\npackages &lt;- c(\n  # Básicos\n  \"tidyverse\", \"readxl\", \"janitor\", \"gtsummary\",\n  \"officer\", \"flextable\", \"ggpubr\",\n  # Testes Estatísticos\n  \"car\", \"FSA\", \"vcd\",\n  # Regressão\n  \"jtools\", \"sjPlot\", \"lmtest\", \"nnet\",\n  # Análise Psicométrica\n  \"psych\", \"lavaan\", \"semPlot\", \"qgraph\", \"corrplot\", \"GGally\",\n  # Análise de Texto\n  \"tidytext\", \"wordcloud\", \"quanteda\", \"lexiconPT\", \"tm\", \"stopwords\"\n)\n\n# Instalar pacotes que não estão instalados\ninstall.packages(setdiff(packages, rownames(installed.packages())))\n\n# Para mall (análise de texto com LLMs) - opcional\n# install.packages(\"mall\")\n# Requer instalação prévia do Ollama: https://ollama.com/download",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "index.html#licença",
    "href": "index.html#licença",
    "title": "Bioestatística Aplicada à Saúde usando R",
    "section": "Licença",
    "text": "Licença\nEste material é disponibilizado para fins educacionais. Os dados utilizados são de domínio público, provenientes do Sistema de Informações Hospitalares (SIH) do SUS.\n\nData de Publicação: 2026-01-28\nVersão do R utilizada: R version 4.4.3",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "introducao-r.html",
    "href": "introducao-r.html",
    "title": "\n1  Introdução ao R e RStudio\n",
    "section": "",
    "text": "1.1 O que é o R?\nO R é uma linguagem de programação e ambiente de software livre para computação estatística e gráficos. Atualmente o R se tornou uma das ferramentas mais populares para análise de dados, especialmente nas áreas de estatística, bioestatística e ciência de dados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao R e RStudio</span>"
    ]
  },
  {
    "objectID": "introducao-r.html#o-que-é-o-r",
    "href": "introducao-r.html#o-que-é-o-r",
    "title": "\n1  Introdução ao R e RStudio\n",
    "section": "",
    "text": "1.1.1 Vantagens do R\n\n\nGratuito e Open Source: O R é completamente gratuito e possui código aberto\n\nAmpla Comunidade: Grande comunidade de usuários e desenvolvedores\n\nPacotes Especializados: Mais de 19.000 pacotes disponíveis no CRAN para diferentes análises\n\nGráficos de Alta Qualidade: Excelentes capacidades de visualização de dados\n\nReprodutibilidade: Facilita a pesquisa reproduzível através de scripts\n\nIntegração: Pode ser integrado com outras linguagens e ferramentas\n\n1.1.2 Desvantagens do R\n\n\nCurva de Aprendizado: Pode ser desafiador para iniciantes sem experiência em programação",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao R e RStudio</span>"
    ]
  },
  {
    "objectID": "introducao-r.html#interface-do-rstudio",
    "href": "introducao-r.html#interface-do-rstudio",
    "title": "\n1  Introdução ao R e RStudio\n",
    "section": "\n1.2 Interface do RStudio",
    "text": "1.2 Interface do RStudio\nO RStudio é um ambiente de desenvolvimento integrado (IDE) para R que facilita significativamente o trabalho com a linguagem. A interface do RStudio é dividida em quatro painéis principais:\n\n\nEditor de Scripts (superior esquerdo): Onde você escreve e salva seus códigos\n\nConsole (inferior esquerdo): Onde os comandos são executados e os resultados aparecem\n\nEnvironment/History (superior direito): Mostra objetos criados e histórico de comandos\n\nFiles/Plots/Packages/Help (inferior direito): Gerenciamento de arquivos, visualização de gráficos, pacotes e ajuda\n\n\n1.2.1 RStudio Projects\nOs Projects do RStudio são uma forma de organizar seu trabalho. Ao criar um projeto:\n\nMantém todos os arquivos relacionados em um único diretório\nDefine o diretório de trabalho automaticamente\nPreserva o histórico de comandos específico do projeto\nFacilita o controle de versão com Git\n\nDica: Sempre use Projects para organizar suas análises!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao R e RStudio</span>"
    ]
  },
  {
    "objectID": "introducao-r.html#primeiros-passos-com-r",
    "href": "introducao-r.html#primeiros-passos-com-r",
    "title": "\n1  Introdução ao R e RStudio\n",
    "section": "\n1.3 Primeiros Passos com R",
    "text": "1.3 Primeiros Passos com R\n\n1.3.1 Interface do RStudio\nBem-vindo à interface do RStudio! Nesta seção, vamos aprender os comandos básicos do R.\n\n# O uso de # no início de uma linha significa uma linha de comentário\n# Essa linha não é executada pelo R\n# Use comentários para documentar seu código!\n\n\n1.3.2 Declarando Variáveis\nNo R, usamos o operador &lt;- para atribuir valores a variáveis.\nAtalho útil: Alt + - (Windows) ou Option + - (Mac) insere automaticamente &lt;-\nPara executar código: Ctrl + Enter (Windows) ou Cmd + Enter (Mac)\n\n# Declarando variáveis simples\na &lt;- 1\nb &lt;- 2\n\n# Operações matemáticas\na + b\n\n[1] 3\n\n\n\n1.3.3 Estruturas de Dados\nO R possui diferentes estruturas para armazenar dados:\n\n1.3.3.1 Vetores\nVetores são a estrutura mais simples, contendo elementos de um único tipo:\n\n# Vetor numérico simples\na &lt;- 1\n\n# Vetor com múltiplos elementos\nnumeros &lt;- c(1, 2, 3, 4, 5)\n\n\n1.3.3.2 Listas\nListas podem conter diferentes tipos de dados:\n\n# Lista com diferentes tipos de dados\na &lt;- list(\"a\", 1, \"b\")\n\n\n1.3.3.3 Data Frames\nO data frame é a estrutura mais importante para análise de dados - é equivalente a uma planilha do Excel.\n\n# Criando um data frame com informações de pacientes\ndf &lt;- data.frame(\n  Nome = c(\"João\", \"José\", \"Maria\", \"Antônia\"),\n  Idade = c(65, 60, 22, 28),\n  Sexo = c(\"Masculino\", \"Masculino\", \"Feminino\", \"Feminino\"),\n  CEP = c(85802159, 87945632, 89745632, 85706984),\n  Curso = c(\"Nutrição\", \"Educação Física\", \"Fisioterapia\", \"Medicina\")\n)\n\n# Visualizando o resumo dos dados\nsummary(df)\n\n     Nome               Idade           Sexo                CEP          \n Length:4           Min.   :22.00   Length:4           Min.   :85706984  \n Class :character   1st Qu.:26.50   Class :character   1st Qu.:85778365  \n Mode  :character   Median :44.00   Mode  :character   Median :86873896  \n                    Mean   :43.75                      Mean   :87300102  \n                    3rd Qu.:61.25                      3rd Qu.:88395632  \n                    Max.   :65.00                      Max.   :89745632  \n    Curso          \n Length:4          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n1.3.3.4 Acessando Colunas de um Data Frame\nO símbolo $ é usado para acessar colunas específicas de um data frame:\n\n# Plotando a idade dos participantes\nplot(df$Idade,\n     main = \"Idade dos Participantes\",\n     ylab = \"Idade (anos)\",\n     xlab = \"Índice\",\n     col = \"navy\",\n     pch = 16)\n\n\n\nGráfico de dispersão da idade dos participantes\n\n\n\n\n1.3.4 Tipos de Dados no R\nCompreender os tipos de dados é fundamental para trabalhar com R:\n\n1.3.4.1 Numeric (Double)\nValores numéricos decimais:\n\na &lt;- 1\na\n\n[1] 1\n\nclass(a)\n\n[1] \"numeric\"\n\n\n\n1.3.4.2 Integer\nValores numéricos inteiros (use L para especificar):\n\na &lt;- 1L\na\n\n[1] 1\n\nclass(a)\n\n[1] \"integer\"\n\n\n\n1.3.4.3 Character\nDados de texto (strings):\n\na &lt;- \"1\"\na\n\n[1] \"1\"\n\nclass(a)\n\n[1] \"character\"\n\n\n\n1.3.4.4 Factor\nDados categóricos (nominais ou ordinais):\n\na &lt;- \"1\"\na &lt;- as.factor(a)\nclass(a)\n\n[1] \"factor\"\n\n\nFatores são essenciais para análises estatísticas com variáveis categóricas.\n\n1.3.4.5 Logical (Booleano)\nValores lógicos TRUE (verdadeiro) ou FALSE (falso):\n\na &lt;- 1\nb &lt;- 2\na == b  # Retorna FALSE\n\n[1] FALSE\n\n\n\n1.3.4.6 NA (Not Available)\nRepresenta valores ausentes em um conjunto de dados:\n\na &lt;- c(1, 2, NA)\na\n\n[1]  1  2 NA\n\na + 2  # O NA se propaga nas operações\n\n[1]  3  4 NA\n\n\n\n1.3.5 Convertendo Tipos de Dados\nVamos aplicar o que aprendemos ao nosso data frame:\n\n# Convertendo a variável Sexo para fator\ndf$Sexo &lt;- as.factor(df$Sexo)\n\n# Agora conseguimos criar um boxplot adequado\nplot(x = df$Sexo,\n     y = df$Idade,\n     xlab = \"Sexo\",\n     ylab = \"Idade (anos)\",\n     col = c(\"lightblue\", \"lightpink\"),\n     main = \"Distribuição de Idade por Sexo\")\n\n\n\nDistribuição de idade por sexo",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao R e RStudio</span>"
    ]
  },
  {
    "objectID": "introducao-r.html#lógica-de-programação-no-r",
    "href": "introducao-r.html#lógica-de-programação-no-r",
    "title": "\n1  Introdução ao R e RStudio\n",
    "section": "\n1.4 Lógica de Programação no R",
    "text": "1.4 Lógica de Programação no R\n\n1.4.1 Operadores Lógicos\nOs operadores lógicos são usados para realizar comparações:\n\n\nOperador\nSignificado\n\n\n\n==\nIgual a\n\n\n!=\nDiferente de\n\n\n&lt;\nMenor que\n\n\n&gt;\nMaior que\n\n\n&lt;=\nMenor ou igual\n\n\n&gt;=\nMaior ou igual\n\n\n\n\n# Exemplos de operadores lógicos\n1 &gt; 2   # FALSE\n\n[1] FALSE\n\n1 &lt; 2   # TRUE\n\n[1] TRUE\n\n1 &lt;= 2  # TRUE\n\n[1] TRUE\n\n1 &gt;= 2  # FALSE\n\n[1] FALSE\n\n1 != 2  # TRUE\n\n[1] TRUE\n\n2 == 2  # TRUE\n\n[1] TRUE\n\n\nPodemos aplicar operadores lógicos a colunas inteiras:\n\ndf$Idade &gt; 50  # Quais idades são maiores que 50?\n\n[1]  TRUE  TRUE FALSE FALSE\n\ndf$Idade &gt;= 60  # Quais são idosos (&gt;=60 anos)?\n\n[1]  TRUE  TRUE FALSE FALSE\n\n\n\n1.4.2 Condicionais: if, else, ifelse\n\n1.4.2.1 Estrutura if-else\n\na &lt;- 200\nb &lt;- 1\n\nif (a &gt; b) {\n  print(paste(a, \"é maior que\", b))\n} else {\n  print(paste(a, \"não é maior que\", b))\n}\n\n[1] \"200 é maior que 1\"\n\n\n\n1.4.2.2 Função ifelse\nA função ifelse() é útil para vetorização de condições:\n\n# Classificando idades em adultos e crianças\nidades &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 21, 25, 38, 48, 54)\nclassificacao &lt;- ifelse(idades &gt;= 10, \"Adulto\", \"Criança\")\nclassificacao\n\n [1] \"Criança\" \"Criança\" \"Criança\" \"Criança\" \"Criança\" \"Criança\" \"Criança\"\n [8] \"Criança\" \"Criança\" \"Adulto\"  \"Adulto\"  \"Adulto\"  \"Adulto\"  \"Adulto\" \n[15] \"Adulto\" \n\n\nAplicando ao nosso data frame:\n\n# Classificando participantes como idosos ou adultos\nclassificacao_idade &lt;- ifelse(df$Idade &gt;= 60, \"Idoso\", \"Adulto\")\nclassificacao_idade\n\n[1] \"Idoso\"  \"Idoso\"  \"Adulto\" \"Adulto\"\n\n\n\n1.4.3 Loops: Operações Repetidas\nLoops são úteis para realizar operações repetidas de forma automática.\n\n1.4.3.1 Loop for básico\n\n# Imprimindo números de 1 a 10\nfor (i in 1:10) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\n\n1.4.3.2 Loop for com condicionais\nExemplo avançado: criando gráficos automaticamente para cada coluna do data frame:\n\n# Loop para gerar gráficos de todas as colunas\nfor (col in names(df)) {\n  if (is.numeric(df[[col]])) {\n    # Se a coluna for numérica, cria gráfico de dispersão\n    plot(df[[col]],\n         main = paste(\"Gráfico da coluna:\", col),\n         xlab = \"Índice\",\n         ylab = \"Valor\",\n         col = \"navy\",\n         pch = 16)\n  } else if (is.factor(df[[col]])) {\n    # Se a coluna for fator, cria gráfico de barras\n    counts &lt;- table(df[[col]])\n    barplot(counts,\n            main = paste(\"Distribuição da coluna:\", col),\n            col = \"darkred\",\n            border = \"black\",\n            xlab = \"Categorias\",\n            ylab = \"Frequência\")\n  }\n}\n\n\n\nGráficos automáticos para cada variável do data frame\n\n\n\n\n\nGráficos automáticos para cada variável do data frame\n\n\n\n\n\nGráficos automáticos para cada variável do data frame",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao R e RStudio</span>"
    ]
  },
  {
    "objectID": "introducao-r.html#boas-práticas-de-formatação-de-código",
    "href": "introducao-r.html#boas-práticas-de-formatação-de-código",
    "title": "\n1  Introdução ao R e RStudio\n",
    "section": "\n1.5 Boas Práticas de Formatação de Código",
    "text": "1.5 Boas Práticas de Formatação de Código\nEscrever código limpo e legível é essencial para:\n\nFacilitar a manutenção e revisão do código\nPermitir que outros entendam seu trabalho\nEvitar erros e bugs\nPromover colaboração\n\n\n1.5.1 Uso de Espaços\nSempre use espaços ao redor de operadores para melhorar a legibilidade:\n\n# ✓ CORRETO - Código legível\na &lt;- 1\na &lt;- 1 + 2 * 3\n\n# ✗ ERRADO - Código difícil de ler\na&lt;-1+2*3\n\n\n1.5.2 Formatação de Data Frames\nCompare as duas formas de criar o mesmo data frame:\n\n# ✓ CORRETO - Cada argumento em uma linha, bem espaçado\ndf &lt;- data.frame(\n  Nome = c(\"João\", \"José\", \"Maria\", \"Antônia\"),\n  Idade = c(65, 60, 22, 28),\n  Sexo = c(\"Masculino\", \"Masculino\", \"Feminino\", \"Feminino\"),\n  CEP = c(85802159, 87945632, 89745632, 85706984),\n  Curso = c(\"Nutrição\", \"Educação Física\", \"Fisioterapia\", \"Medicina\")\n)\n\n\n# ✗ ERRADO - Tudo em poucas linhas, difícil de ler\ndf &lt;- data.frame(Nome=c(\"João\",\"José\",\"Maria\",\"Antônia\"),Idade=c(65,60,22,28),\n                 Sexo=c(\"Masculino\",\"Masculino\",\"Feminino\",\"Feminino\"),\n                 CEP=c(85802159,87945632,89745632,85706984),\n                 Curso=c(\"Nutrição\",\"Educação Física\",\"Fisioterapia\",\"Medicina\"))\n\n\n1.5.3 Convenções de Nomenclatura\nUse snake_case (minúsculas com underline) para nomear variáveis e objetos:\n\n# ✗ ERRADO - Nome com espaço (causa erro)\ntabela 1 &lt;- 1\n\n# ✗ ERRADO - Mistura de maiúsculas e espaço\ntabelA 1 &lt;- 1\n\n# ✓ CORRETO - snake_case\ntabela_1 &lt;- 1\ndados_pacientes &lt;- data.frame()\nmodelo_final &lt;- lm()\n\n\n1.5.4 Documentação com Comentários\nSempre documente seu código com comentários explicativos:\n\n# Carregando dados de internações hospitalares\ndados &lt;- read_excel(\"dados_internacoes_maringa_2024.xlsx\")\n\n# Filtrando apenas pacientes adultos (&gt;= 18 anos)\ndados_adultos &lt;- dados |&gt;\n  filter(idade &gt;= 18)\n\n# Calculando estatísticas descritivas por sexo\nresumo &lt;- dados_adultos |&gt;\n  group_by(sexo) |&gt;\n  summarise(\n    idade_media = mean(idade),\n    idade_dp = sd(idade)\n  )",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao R e RStudio</span>"
    ]
  },
  {
    "objectID": "introducao-r.html#resumo-do-capítulo",
    "href": "introducao-r.html#resumo-do-capítulo",
    "title": "\n1  Introdução ao R e RStudio\n",
    "section": "\n1.6 Resumo do Capítulo",
    "text": "1.6 Resumo do Capítulo\nNeste capítulo, você aprendeu:\n\n\nO que é o R e suas vantagens para análise de dados em saúde\n\nInterface do RStudio e como organizá-la com Projects\n\nTipos de dados no R: numeric, integer, character, factor, logical, NA\n\nEstruturas de dados: vetores, listas e data frames\n\nOperadores lógicos e como usá-los para comparações\n\nCondicionais com if-else e ifelse\n\nLoops para automatizar tarefas repetitivas\n\nBoas práticas de formatação e documentação de código\n\nNo próximo capítulo, você aprenderá a manipular dados de forma eficiente usando o pacote tidyverse, uma das ferramentas mais poderosas do ecossistema R.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao R e RStudio</span>"
    ]
  },
  {
    "objectID": "introducao-r.html#exercícios-práticos",
    "href": "introducao-r.html#exercícios-práticos",
    "title": "\n1  Introdução ao R e RStudio\n",
    "section": "\n1.7 Exercícios Práticos",
    "text": "1.7 Exercícios Práticos\n\nCrie um data frame com dados de 5 pacientes, incluindo variáveis: nome, idade, peso, altura e diagnóstico\nCalcule o IMC (Índice de Massa Corporal) de cada paciente usando a fórmula: IMC = peso / altura²\nUse ifelse() para classificar os pacientes em: “Baixo peso” (IMC &lt; 18.5), “Normal” (18.5 ≤ IMC &lt; 25), “Sobrepeso” (25 ≤ IMC &lt; 30), ou “Obesidade” (IMC ≥ 30)\nCrie gráficos apropriados para visualizar a distribuição de idade e IMC dos pacientes\nUse um loop para calcular e imprimir a idade de cada paciente daqui a 10 anos",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução ao R e RStudio</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html",
    "href": "manipulacao-dados.html",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "",
    "text": "2.1 O que é o Tidyverse?\nO tidyverse é uma coleção de pacotes R projetados para ciência de dados. Todos os pacotes compartilham uma filosofia de design, gramática e estruturas de dados subjacentes, tornando o trabalho com dados mais intuitivo e eficiente.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#o-que-é-o-tidyverse",
    "href": "manipulacao-dados.html#o-que-é-o-tidyverse",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "",
    "text": "2.1.1 Pacotes Principais do Tidyverse\n\n\ndplyr: Manipulação de dados (filtrar, selecionar, agrupar, sumarizar)\n\nggplot2: Criação de gráficos elegantes\n\ntidyr: Organização e limpeza de dados\n\nreadr: Leitura rápida de dados retangulares (CSV, TSV)\n\npurrr: Programação funcional\n\ntibble: Versão moderna de data frames\n\nstringr: Manipulação de strings\n\nforcats: Manipulação de fatores\n\n2.1.2 Por que usar o Tidyverse?\n\n\nCódigo mais legível: Sintaxe intuitiva e consistente\n\nPipe operator: Encadeamento de operações de forma natural\n\nEficiência: Otimizado para grandes volumes de dados\n\nComunidade: Ampla documentação e suporte\n\nIntegração: Pacotes funcionam perfeitamente juntos",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#instalação-e-carregamento-de-pacotes",
    "href": "manipulacao-dados.html#instalação-e-carregamento-de-pacotes",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "\n2.2 Instalação e Carregamento de Pacotes",
    "text": "2.2 Instalação e Carregamento de Pacotes\n\n2.2.1 Instalando Pacotes\nPara instalar um pacote no R, usamos a função install.packages():\n\n# Instalando um pacote individual\ninstall.packages(\"tidyverse\")\n\n# Instalando múltiplos pacotes\ninstall.packages(c(\"tidyverse\", \"readxl\", \"janitor\"))\n\nImportante: Você só precisa instalar um pacote uma vez. Após a instalação, o pacote fica disponível permanentemente.\n\n2.2.2 Carregando Pacotes\nApós instalados, os pacotes precisam ser carregados em cada sessão usando library():\n\n# Carregando os pacotes necessários\nlibrary(tidyverse)  # Manipulação e visualização de dados\nlibrary(readxl)     # Leitura de arquivos Excel",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#importando-dados",
    "href": "manipulacao-dados.html#importando-dados",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "\n2.3 Importando Dados",
    "text": "2.3 Importando Dados\n\n2.3.1 Leitura de Arquivos Excel\nA função read_excel() do pacote readxl permite importar dados de arquivos Excel:\n\n# Importando dados de internações hospitalares\ndados &lt;- read_excel(\"data/dados_internacoes_maringa_2024.xlsx\")\n\n\n\n\n\n\n\nNota sobre os Dados\n\n\n\nOs dados utilizados neste livro são de internações hospitalares de Maringá-PR referentes ao ano de 2024, disponibilizados pelo Sistema de Informações Hospitalares (SIH) do SUS. O arquivo dados_internacoes_maringa_2024.xlsx deve estar na pasta data/ do seu projeto.\n\n\n\n2.3.2 Explorando os Dados Importados\nApós importar, é importante explorar a estrutura dos dados:\n\n# Resumo estatístico das variáveis\nsummary(dados)\n\n# Visão geral da estrutura (tidyverse)\nglimpse(dados)\n\n# Estrutura detalhada (R base)\nstr(dados)\n\nEssas funções fornecem informações sobre:\n\nNúmero de linhas e colunas\nTipos de dados de cada variável\nPrimeiros valores de cada coluna\nValores ausentes (NAs)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#principais-funções-do-tidyverse",
    "href": "manipulacao-dados.html#principais-funções-do-tidyverse",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "\n2.4 Principais Funções do Tidyverse",
    "text": "2.4 Principais Funções do Tidyverse\nO tidyverse oferece um conjunto de funções poderosas para manipulação de dados:\n\n\nFunção\nDescrição\n\n\n\nselect()\nSeleciona colunas específicas\n\n\nfilter()\nFiltra linhas baseado em condições\n\n\nmutate()\nCria ou modifica colunas\n\n\nrename()\nRenomeia colunas\n\n\ngroup_by()\nAgrupa dados por variáveis\n\n\nsummarise()\nCalcula estatísticas resumidas\n\n\n\nVamos explorar cada uma dessas funções em detalhes.\n\n2.4.1 select(): Selecionando Colunas\nA função select() permite escolher quais colunas manter no seu data frame:\n\n# Selecionando apenas as colunas SEXO e IDADE\ndados_selecionados &lt;- select(dados, SEXO, IDADE)\n\nglimpse(dados_selecionados)\n\n\n2.4.1.1 Excluindo Colunas\nVocê pode também remover colunas específicas usando o sinal de menos -:\n\n# Removendo a coluna CEP\ndados2 &lt;- select(dados, -CEP)\n\n\n2.4.1.2 Seleção Avançada\n\n# Selecionar colunas que começam com determinado texto\nselect(dados, starts_with(\"VAL\"))\n\n# Selecionar colunas que terminam com determinado texto\nselect(dados, ends_with(\"_TOT\"))\n\n# Selecionar colunas que contêm determinado texto\nselect(dados, contains(\"IDADE\"))\n\n# Selecionar colunas numéricas\nselect(dados, where(is.numeric))\n\n\n2.4.2 filter(): Filtrando Linhas\nA função filter() permite selecionar linhas que atendem a determinadas condições:\n\n2.4.2.1 Filtro Simples\n\n# Filtrando apenas pacientes do sexo masculino\ndados_masculino &lt;- filter(dados, SEXO == \"Masculino\")\n\n# Filtrando pacientes que NÃO são do sexo masculino\ndados_feminino &lt;- filter(dados, SEXO != \"Masculino\")\n\n\n2.4.2.2 Múltiplas Condições\nUse o operador & (E) para combinar condições:\n\n# Homens que foram a óbito\ndados_masculino_morte &lt;- filter(dados, SEXO == \"Masculino\" & MORTE == \"Sim\")\n\n# Homens idosos (&gt;=60 anos) que foram a óbito\ndados_masculino_morte_idosos &lt;- filter(\n  dados,\n  SEXO == \"Masculino\" & MORTE == \"Sim\" & IDADE &gt;= 60\n)\n\n\n2.4.2.3 Outros Operadores Lógicos\n\n# Operador OU (|): pacientes com idade menor que 18 OU maior que 60\nfilter(dados, IDADE &lt; 18 | IDADE &gt; 60)\n\n# Operador %in%: selecionar múltiplos valores\nfilter(dados, RACA_COR %in% c(\"Branca\", \"Parda\"))\n\n# Valores ausentes\nfilter(dados, is.na(IDADE))  # Linhas com idade ausente\nfilter(dados, !is.na(IDADE))  # Linhas SEM idade ausente\n\n\n2.4.3 mutate(): Criando e Modificando Colunas\nA função mutate() é usada para criar novas colunas ou modificar existentes:\n\n2.4.3.1 Criando Nova Coluna\n\n# Criando nova coluna com valor total multiplicado por 1000\ndados_valor_1000 &lt;- mutate(dados, VAL_TOT_1000 = VAL_TOT * 1000)\n\n\n2.4.3.2 Modificando Tipo de Dados\nA função across() permite aplicar uma transformação a múltiplas colunas:\n\n# Convertendo IDADE e DIAS_PERM para numérico\ndados &lt;- mutate(dados, across(c(IDADE, DIAS_PERM), as.numeric))\n\n# Convertendo múltiplas colunas para fator\ndados &lt;- mutate(dados, across(c(SEXO, RACA_COR, MORTE), as.factor))\n\n\n2.4.3.3 Recodificando Variáveis com case_when()\nA função case_when() é útil para criar categorias baseadas em múltiplas condições:\n\n# Recodificando códigos numéricos de raça/cor para texto descritivo\ndados &lt;- mutate(\n  dados,\n  RACA_COR = case_when(\n    RACA_COR == '01' ~ \"Branca\",\n    RACA_COR == \"02\" ~ \"Preta\",\n    RACA_COR == \"03\" ~ \"Parda\",\n    RACA_COR == \"04\" ~ \"Amarela\",\n    RACA_COR == \"05\" ~ \"Indígena\"\n  )\n)\n\nOutros exemplos de case_when():\n\n# Classificando faixas etárias\ndados &lt;- mutate(\n  dados,\n  faixa_etaria = case_when(\n    IDADE &lt; 18 ~ \"Criança/Adolescente\",\n    IDADE &gt;= 18 & IDADE &lt; 60 ~ \"Adulto\",\n    IDADE &gt;= 60 ~ \"Idoso\"\n  )\n)\n\n# Classificando permanência hospitalar\ndados &lt;- mutate(\n  dados,\n  tempo_internacao = case_when(\n    DIAS_PERM &lt;= 3 ~ \"Curta\",\n    DIAS_PERM &gt; 3 & DIAS_PERM &lt;= 7 ~ \"Média\",\n    DIAS_PERM &gt; 7 ~ \"Longa\"\n  )\n)\n\n\n2.4.4 rename(): Renomeando Colunas\nA função rename() permite alterar nomes de colunas:\n\n# Renomeando a coluna ESPEC para ESPECIALIDADE\ndados &lt;- rename(dados, ESPECIALIDADE = ESPEC)\n\n# Sintaxe: novo_nome = nome_antigo\n\nRenomeando múltiplas colunas:\n\ndados &lt;- rename(\n  dados,\n  especialidade = ESPEC,\n  diagnostico = DIAG_PRINC,\n  idade_anos = IDADE\n)\n\n\n2.4.5 group_by() e summarise(): Sumarizando Dados\nEstas funções trabalham em conjunto para calcular estatísticas agrupadas.\n\n2.4.5.1 Agrupamento e Sumarização Básica\n\n# Calculando idade média por sexo e raça/cor\ndados_agrupados &lt;- dados |&gt;\n  group_by(SEXO, RACA_COR) |&gt;\n  summarise(mean_idade = mean(IDADE), .groups = \"drop\")\n\ndados_agrupados\n\n\n2.4.5.2 Múltiplas Estatísticas\n\n# Calculando várias estatísticas ao mesmo tempo\nestatisticas &lt;- dados |&gt;\n  group_by(SEXO) |&gt;\n  summarise(\n    n = n(),                          # Contagem\n    idade_media = mean(IDADE, na.rm = TRUE),\n    idade_dp = sd(IDADE, na.rm = TRUE),\n    idade_mediana = median(IDADE, na.rm = TRUE),\n    idade_min = min(IDADE, na.rm = TRUE),\n    idade_max = max(IDADE, na.rm = TRUE),\n    .groups = \"drop\"\n  )",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#o-operador-pipe",
    "href": "manipulacao-dados.html#o-operador-pipe",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "\n2.5 O Operador Pipe |>",
    "text": "2.5 O Operador Pipe |&gt;\nO pipe operator |&gt; é uma das características mais poderosas do tidyverse. Ele permite encadear múltiplas operações de forma legível.\n\n2.5.1 Como Ler o Pipe\nO símbolo |&gt; pode ser lido como “E ENTÃO” ou “PASSE PARA”.\n\n# Sem pipe (difícil de ler)\nresultado &lt;- summarise(\n  group_by(\n    filter(dados, SEXO == \"Masculino\"),\n    RACA_COR\n  ),\n  media_idade = mean(IDADE)\n)\n\n# Com pipe (fácil de ler)\nresultado &lt;- dados |&gt;\n  filter(SEXO == \"Masculino\") |&gt;\n  group_by(RACA_COR) |&gt;\n  summarise(media_idade = mean(IDADE))\n\nLeitura: “Pegue os dados E ENTÃO filtre para sexo masculino E ENTÃO agrupe por raça/cor E ENTÃO calcule a média de idade”\n\n2.5.2 Atalho de Teclado\n\n\nWindows/Linux: Ctrl + Shift + M\n\n\nMac: Cmd + Shift + M\n\n\n\n\n\n\n\n\nPipe Nativo vs. Pipe do magrittr\n\n\n\nO R possui dois operadores pipe:\n\n\n|&gt; - Pipe nativo do R (versão 4.1+) - usado neste livro\n\n%&gt;% - Pipe do pacote magrittr\n\nAmbos funcionam de forma similar. Usamos |&gt; por ser nativo e não requerer pacotes adicionais.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#encadeamento-de-operações",
    "href": "manipulacao-dados.html#encadeamento-de-operações",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "\n2.6 Encadeamento de Operações",
    "text": "2.6 Encadeamento de Operações\nO verdadeiro poder do tidyverse aparece quando combinamos múltiplas operações:\n\n2.6.1 Exemplo Completo de Pipeline\n\n# Pipeline complexo de limpeza e análise de dados\ndados_limpos &lt;- dados |&gt;\n  # 1. Selecionar colunas relevantes\n  select(SEXO, RACA_COR, IDADE, MORTE, COD_IDADE) |&gt;\n  # 2. Filtrar apenas idades em anos\n  filter(COD_IDADE == \"Anos\") |&gt;\n  # 3. Remover coluna COD_IDADE (não mais necessária)\n  select(-COD_IDADE) |&gt;\n  # 4. Converter IDADE para numérico\n  mutate(across(IDADE, as.numeric)) |&gt;\n  # 5. Converter variáveis categóricas para fator\n  mutate(across(c(SEXO, RACA_COR, MORTE), as.factor)) |&gt;\n  # 6. Recodificar raça/cor\n  mutate(RACA_COR = case_when(\n    RACA_COR == '01' ~ \"Branca\",\n    RACA_COR == \"02\" ~ \"Preta\",\n    RACA_COR == \"03\" ~ \"Parda\",\n    RACA_COR == \"04\" ~ \"Amarela\",\n    RACA_COR == \"05\" ~ \"Indígena\"\n  )) |&gt;\n  # 7. Renomear colunas para minúsculas\n  rename(\n    sexo = SEXO,\n    raca_cor = RACA_COR,\n    idade = IDADE,\n    morte = MORTE\n  ) |&gt;\n  # 8. Agrupar por raça/cor e sexo\n  group_by(raca_cor, sexo) |&gt;\n  # 9. Calcular idade média por grupo\n  summarise(mean_idade = mean(idade), .groups = \"drop\")\n\ndados_limpos\n\n\n2.6.2 Vantagens do Encadeamento\n\n\nLegibilidade: Código lido de cima para baixo, como uma receita\n\nManutenção: Fácil adicionar, remover ou modificar etapas\n\nEficiência: Evita criar múltiplos objetos intermediários\n\nDebug: Fácil testar executando até determinado ponto\n\n2.6.3 Dica para Debug\nVocê pode executar o pipeline até qualquer ponto selecionando o código desejado:\n\n# Selecione e execute até a linha que deseja inspecionar\ndados |&gt;\n  select(SEXO, RACA_COR, IDADE, MORTE, COD_IDADE) |&gt;\n  filter(COD_IDADE == \"Anos\")  # Execute até aqui para ver o resultado\n# |&gt; select(-COD_IDADE)          # Não será executado",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#outras-funções-úteis-do-dplyr",
    "href": "manipulacao-dados.html#outras-funções-úteis-do-dplyr",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "\n2.7 Outras Funções Úteis do dplyr",
    "text": "2.7 Outras Funções Úteis do dplyr\n\n2.7.1 arrange(): Ordenando Dados\n\n# Ordenar por idade (crescente)\ndados |&gt; arrange(IDADE)\n\n# Ordenar por idade (decrescente)\ndados |&gt; arrange(desc(IDADE))\n\n# Ordenar por múltiplas colunas\ndados |&gt; arrange(SEXO, desc(IDADE))\n\n\n2.7.2 count(): Contagem Rápida\n\n# Contar frequências de uma variável\ndados |&gt; count(SEXO)\n\n# Contar combinações\ndados |&gt; count(SEXO, MORTE)\n\n# Ordenar por frequência\ndados |&gt; count(RACA_COR, sort = TRUE)\n\n\n2.7.3 distinct(): Valores Únicos\n\n# Valores únicos de uma coluna\ndados |&gt; distinct(SEXO)\n\n# Remover linhas duplicadas completas\ndados |&gt; distinct()\n\n\n2.7.4 slice(): Seleção por Posição\n\n# Primeiras 10 linhas\ndados |&gt; slice(1:10)\n\n# Linhas específicas\ndados |&gt; slice(c(1, 5, 10))\n\n# Top 5 idades mais altas\ndados |&gt; slice_max(IDADE, n = 5)\n\n# Bottom 5 idades mais baixas\ndados |&gt; slice_min(IDADE, n = 5)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#pacote-janitor-limpeza-de-nomes",
    "href": "manipulacao-dados.html#pacote-janitor-limpeza-de-nomes",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "\n2.8 Pacote janitor: Limpeza de Nomes",
    "text": "2.8 Pacote janitor: Limpeza de Nomes\nO pacote janitor oferece funções úteis para limpeza de dados, especialmente nomes de colunas:\n\nlibrary(janitor)\n\n# Limpar nomes de colunas (remove acentos, espaços, caracteres especiais)\ndados &lt;- clean_names(dados)\n\n# Antes: \"Nome da Variável\"\n# Depois: \"nome_da_variavel\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#resumo-do-capítulo",
    "href": "manipulacao-dados.html#resumo-do-capítulo",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "\n2.9 Resumo do Capítulo",
    "text": "2.9 Resumo do Capítulo\nNeste capítulo, você aprendeu:\n\n\nO que é o tidyverse e seus principais pacotes\nComo instalar e carregar pacotes no R\n\nImportar dados de arquivos Excel com read_excel()\n\n\nExplorar dados com summary(), glimpse() e str()\n\n\nPrincipais funções do dplyr:\n\n\nselect() - Selecionar colunas\n\nfilter() - Filtrar linhas\n\nmutate() - Criar/modificar colunas\n\nrename() - Renomear colunas\n\ngroup_by() e summarise() - Agrupar e sumarizar\n\n\n\nUsar o pipe operator |&gt; para encadear operações\n\nCriar pipelines complexos de limpeza e análise de dados\n\nFunções adicionais como arrange(), count(), distinct(), slice()\n\n\nNo próximo capítulo, você aprenderá a realizar análises exploratórias de dados, incluindo estatística descritiva, testes estatísticos e visualização com ggplot2.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "manipulacao-dados.html#exercícios-práticos",
    "href": "manipulacao-dados.html#exercícios-práticos",
    "title": "\n2  Manipulação de Dados com Tidyverse\n",
    "section": "\n2.10 Exercícios Práticos",
    "text": "2.10 Exercícios Práticos\n\nCarregue o arquivo dados_internacoes_maringa_2024.xlsx e explore sua estrutura\n\nCrie um pipeline que:\n\nSelecione as colunas SEXO, IDADE, DIAS_PERM, VAL_TOT, MORTE\nFiltre apenas pacientes adultos (IDADE &gt;= 18)\nCrie uma coluna categorizando o tempo de permanência (curta: ≤3 dias, média: 4-7 dias, longa: &gt;7 dias)\nCalcule a idade média e o valor total médio por sexo e categoria de permanência\n\n\nIdentifique as 10 especialidades médicas com maior número de internações\nCalcule a taxa de mortalidade (%) por faixa etária (use intervalos de 10 anos)\nCrie um data frame limpo contendo apenas internações de pacientes idosos (≥60 anos) com todas as variáveis categóricas recodificadas de forma descritiva",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulação de Dados com Tidyverse</span>"
    ]
  },
  {
    "objectID": "analise-exploratoria.html",
    "href": "analise-exploratoria.html",
    "title": "\n3  Análise Exploratória de Dados\n",
    "section": "",
    "text": "3.1 Introdução\nA Análise Exploratória de Dados (EDA) é uma etapa fundamental em qualquer projeto de análise estatística. Consiste em investigar os dados usando estatísticas descritivas e visualizações para:\nNeste capítulo, abordaremos dois componentes essenciais da AED:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Análise Exploratória de Dados</span>"
    ]
  },
  {
    "objectID": "analise-exploratoria.html#introdução",
    "href": "analise-exploratoria.html#introdução",
    "title": "\n3  Análise Exploratória de Dados\n",
    "section": "",
    "text": "Compreender a distribuição das variáveis\nIdentificar padrões e tendências\nDetectar valores atípicos (outliers)\nFormular hipóteses para análises posteriores\nVerificar a qualidade dos dados\n\n\n\n\nEstatística Descritiva: Resumir dados usando tabelas e medidas\n\nVisualização de Dados: Criar gráficos informativos com ggplot2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Análise Exploratória de Dados</span>"
    ]
  },
  {
    "objectID": "analise-exploratoria.html#preparação-dos-dados",
    "href": "analise-exploratoria.html#preparação-dos-dados",
    "title": "\n3  Análise Exploratória de Dados\n",
    "section": "\n3.2 Preparação dos Dados",
    "text": "3.2 Preparação dos Dados\nAntes de iniciar a análise exploratória, precisamos carregar os pacotes necessários e preparar os dados.\n\n3.2.1 Carregando Pacotes\n\nlibrary(tidyverse)    # Manipulação e visualização\nlibrary(readxl)       # Leitura de Excel\nlibrary(janitor)      # Limpeza de dados\nlibrary(gtsummary)    # Tabelas descritivas\nlibrary(officer)      # Exportação para Word\nlibrary(flextable)    # Tabelas formatadas\nlibrary(ggpubr)       # Gráficos de publicação\nlibrary(sjPlot)       # Tabelas e gráficos\nlibrary(vcd)          # Visualização de dados categóricos\n\n# Remover notação científica\noptions(scipen = 999)\n\n\n3.2.2 Importando e Limpando Dados\n\n# Carregar banco de dados\ndados &lt;- read_excel(\"data/dados_internacoes_maringa_2024.xlsx\")\n\n# Pipeline de limpeza\ndados_limpos &lt;- dados |&gt;\n  clean_names() |&gt;                              # Padronizar nomes das colunas\n  filter(cod_idade == \"Anos\") |&gt;               # Filtrar apenas idades em anos\n  select(sexo, val_tot, raca_cor, idade,       # Selecionar colunas relevantes\n         morte, dias_perm, mes_cmpt) |&gt;\n  mutate(                                       # Recodificar raça/cor\n    raca_cor = case_when(\n      raca_cor == '01' ~ \"Branca\",\n      raca_cor == \"02\" ~ \"Preta\",\n      raca_cor == \"03\" ~ \"Parda\",\n      raca_cor == \"04\" ~ \"Amarela\",\n      raca_cor == \"05\" ~ \"Indígena\"\n    )\n  ) |&gt;\n  mutate(across(c(val_tot, idade, dias_perm), as.numeric)) |&gt;  # Converter para numérico\n  mutate(across(c(sexo, raca_cor, morte, mes_cmpt), as.factor))  # Converter para fator",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Análise Exploratória de Dados</span>"
    ]
  },
  {
    "objectID": "analise-exploratoria.html#estatística-descritiva",
    "href": "analise-exploratoria.html#estatística-descritiva",
    "title": "\n3  Análise Exploratória de Dados\n",
    "section": "\n3.3 Estatística Descritiva",
    "text": "3.3 Estatística Descritiva\nA estatística descritiva resume e apresenta as características principais dos dados.\n\n3.3.1 Medidas de Tendência Central\n\n\nMédia: Valor médio dos dados\n\nMediana: Valor central quando os dados estão ordenados\n\nModa: Valor mais frequente\n\n3.3.2 Medidas de Dispersão\n\n\nDesvio Padrão (DP): Variabilidade em torno da média\n\nVariância: Quadrado do desvio padrão\n\nAmplitude: Diferença entre máximo e mínimo\n\nIntervalo Interquartil (IQR): Diferença entre o 3º e 1º quartil\n\n3.3.3 Criando Tabelas Descritivas com gtsummary\nO pacote gtsummary facilita a criação de tabelas descritivas profissionais.\n\n3.3.3.1 Tabela Básica\n\n# Tabela descritiva simples\ndados_limpos |&gt;\n  tbl_summary()\n\n\n3.3.3.2 Tabela Estratificada\n\n# Tabela estratificada por desfecho (morte)\ntabela_1 &lt;- dados_limpos |&gt;\n  tbl_summary(\n    by = morte,                                                # Estratificar por morte\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\"),    # Média (DP) para contínuas\n    label = list(                                             # Renomear variáveis\n      idade ~ \"Idade (anos)\",\n      sexo ~ \"Sexo\",\n      val_tot ~ \"Valor da internação (Reais)\",\n      raca_cor ~ \"Raça/Cor\",\n      dias_perm ~ \"Dias de permanência\"\n    )\n  ) |&gt;\n  add_overall(col_label = \"**Total**\") |&gt;                    # Adicionar coluna total\n  bold_labels() |&gt;                                            # Negrito nos rótulos\n  modify_header(label = \"**Características avaliadas**\")     # Customizar cabeçalho\n\ntabela_1\n\n\n3.3.3.3 Personalizando Estatísticas\nVocê pode especificar diferentes estatísticas para diferentes tipos de variáveis:\n\ndados_limpos |&gt;\n  tbl_summary(\n    by = sexo,\n    statistic = list(\n      all_continuous() ~ \"{mean} ({sd}) | {median} [{p25}, {p75}]\",\n      all_categorical() ~ \"{n} ({p}%)\"\n    ),\n    digits = all_continuous() ~ 2\n  ) |&gt;\n  add_p() |&gt;                   # Adicionar p-valores\n  add_overall() |&gt;             # Adicionar coluna total\n  bold_p(t = 0.05) |&gt;          # Negrito em p &lt; 0.05\n  bold_labels()\n\n\n3.3.4 Exportando Tabelas\n\n3.3.4.1 Exportação para Word\n\n# Converter para flextable\nft &lt;- tabela_1 |&gt;\n  as_flex_table()\n\n# Criar documento Word\ndoc &lt;- read_docx() |&gt;\n  body_add_par(\n    \"Tabela 1: Estatísticas descritivas das internações de Maringá em 2024\",\n    style = \"heading 1\"\n  ) |&gt;\n  body_add_flextable(ft)\n\n# Salvar arquivo\nprint(doc, target = \"tabela_1.docx\")\n\n\n3.3.4.2 Exportação para Excel\n\nlibrary(openxlsx)\n\n# Criar workbook\nwb &lt;- createWorkbook()\naddWorksheet(wb, \"Tabela Descritiva\")\n\n# Adicionar tabela\nwriteData(wb, sheet = 1, x = tabela_1)\n\n# Salvar\nsaveWorkbook(wb, \"tabela_1.xlsx\", overwrite = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Análise Exploratória de Dados</span>"
    ]
  },
  {
    "objectID": "analise-exploratoria.html#testes-estatísticos",
    "href": "analise-exploratoria.html#testes-estatísticos",
    "title": "\n3  Análise Exploratória de Dados\n",
    "section": "\n3.4 Testes Estatísticos",
    "text": "3.4 Testes Estatísticos\nTestes estatísticos nos permitem fazer inferências sobre a população a partir da amostra.\n\n3.4.1 Teste de Correlação\nA correlação mede a força e direção da associação entre duas variáveis contínuas.\n\n3.4.1.1 Coeficiente de Correlação\n\n\nPearson: Para relações lineares (dados normais)\n\nSpearman: Para relações monotônicas (dados não normais ou ordinais)\n\nKendall: Alternativa robusta ao Spearman\n\nValores variam de -1 (correlação negativa perfeita) a +1 (correlação positiva perfeita).\n\n# Correlação de Spearman entre valor total e idade\ncor(x = dados_limpos$val_tot,\n    y = dados_limpos$idade,\n    method = \"spearman\")\n\n\n3.4.1.2 Visualizando Correlação\n\n# Gráfico de dispersão com linha de regressão\ncorrelation_plot &lt;- ggscatter(\n  dados_limpos,\n  x = \"val_tot\",\n  y = \"idade\",\n  add = \"reg.line\",                             # Adicionar linha de regressão\n  add.params = list(color = \"navyblue\"),        # Customizar linha\n  conf.int = TRUE,                              # Intervalo de confiança\n  cor.coef = TRUE,                              # Mostrar coeficiente\n  cor.method = \"spearman\"                       # Método de correlação\n) +\n  labs(\n    title = \"Correlação entre Valor Total e Idade\",\n    x = \"Valor total da internação (R$)\",\n    y = \"Idade (anos)\"\n  ) +\n  theme_minimal()\n\ncorrelation_plot\n\n\n3.4.1.3 Matriz de Correlação\n\n# Selecionar apenas variáveis numéricas\ndados_numericos &lt;- dados_limpos |&gt;\n  select(where(is.numeric))\n\n# Calcular matriz de correlação\nmatriz_cor &lt;- cor(dados_numericos, method = \"spearman\", use = \"complete.obs\")\n\n# Visualizar com corrplot\nlibrary(corrplot)\ncorrplot(matriz_cor,\n         method = \"color\",\n         type = \"upper\",\n         addCoef.col = \"black\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         diag = FALSE)\n\n\n3.4.2 Teste do Qui-Quadrado\nO teste qui-quadrado avalia a associação entre duas variáveis categóricas.\nHipóteses:\n\nH₀: As variáveis são independentes\nH₁: As variáveis são associadas\n\n\n# Teste qui-quadrado: sexo vs. morte\nresultado_chi &lt;- chisq.test(dados_limpos$sexo, dados_limpos$morte)\nresultado_chi\n\n\n3.4.2.1 Tabela de Contingência\n\n# Tabela cruzada com percentuais\nsjt.xtab(\n  var.row = dados_limpos$sexo,\n  var.col = dados_limpos$morte,\n  show.cell.prc = TRUE,              # Mostrar percentuais\n  show.row.prc = TRUE,               # Percentuais por linha\n  show.col.prc = TRUE                # Percentuais por coluna\n)\n\n\n3.4.2.2 Gráfico de Mosaico\nGráficos de mosaico visualizam a relação entre variáveis categóricas:\n\nmosaic(~ sexo + morte,\n       data = dados_limpos,\n       shade = TRUE,                  # Colorir por resíduos\n       legend = TRUE,                 # Mostrar legenda\n       main = \"Associação entre Sexo e Mortalidade\")\n\n\n3.4.3 Teste t de Student\nCompara médias entre dois grupos independentes.\n\n# Comparar idade média entre sexos\nt.test(idade ~ sexo, data = dados_limpos)\n\n# Teste t pareado (para dados pareados)\n# t.test(antes, depois, paired = TRUE)\n\n\n3.4.4 ANOVA (Análise de Variância)\nCompara médias entre três ou mais grupos.\n\n# ANOVA: idade entre categorias de raça/cor\nmodelo_anova &lt;- aov(idade ~ raca_cor, data = dados_limpos)\nsummary(modelo_anova)\n\n# Teste post-hoc (Tukey) para comparações múltiplas\nTukeyHSD(modelo_anova)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Análise Exploratória de Dados</span>"
    ]
  },
  {
    "objectID": "analise-exploratoria.html#visualização-de-dados-com-ggplot2",
    "href": "analise-exploratoria.html#visualização-de-dados-com-ggplot2",
    "title": "\n3  Análise Exploratória de Dados\n",
    "section": "\n3.5 Visualização de Dados com ggplot2",
    "text": "3.5 Visualização de Dados com ggplot2\nO ggplot2 é o sistema de visualização mais popular do R, baseado na “Gramática de Gráficos”.\n\n3.5.1 Estrutura Básica do ggplot2\nTodos os gráficos ggplot2 seguem esta estrutura:\nggplot(data = &lt;DATA&gt;, mapping = aes(&lt;MAPPINGS&gt;)) +\n  &lt;GEOM_FUNCTION&gt;() +\n  &lt;CUSTOMIZATIONS&gt;\n\n3.5.2 Tipos de Gráficos\n\n3.5.2.1 Gráfico de Barras\nIdeal para variáveis categóricas:\n\n# Gráfico de barras simples\nggplot(data = dados_limpos, mapping = aes(x = morte)) +\n  geom_bar() +\n  labs(\n    title = \"Distribuição de Mortalidade\",\n    x = \"Óbito\",\n    y = \"Frequência\"\n  ) +\n  theme_minimal()\n\n\n3.5.2.2 Gráfico de Barras Agrupadas\n\nggplot(data = dados_limpos, mapping = aes(x = sexo, fill = morte)) +\n  geom_bar() +\n  labs(\n    x = \"Sexo\",\n    y = \"Contagem\",\n    title = \"Mortalidade por Sexo em pacientes internados em Maringá\",\n    subtitle = \"Dados de 2024\",\n    caption = \"Fonte: SIH\"\n  ) +\n  scale_fill_manual(\n    name = \"Óbito\",\n    values = c(\"Sim\" = \"darkred\", \"Não\" = \"navy\")\n  ) +\n  theme_minimal()\n\n\n3.5.2.3 Gráfico de Barras Empilhadas (Proporções)\n\nggplot(data = dados_limpos, mapping = aes(x = sexo, fill = morte)) +\n  geom_bar(position = \"fill\") +                # position = \"fill\" para proporções\n  labs(\n    x = \"Sexo\",\n    y = \"Proporção\",\n    title = \"Percentual de Mortalidade por Sexo em pacientes internados em Maringá\",\n    subtitle = \"Dados de 2024\",\n    caption = \"Fonte: SIH\"\n  ) +\n  scale_fill_manual(\n    name = \"Óbito\",\n    values = c(\"Sim\" = \"darkred\", \"Não\" = \"navy\")\n  ) +\n  scale_y_continuous(labels = scales::percent) +  # Formatar eixo Y como percentual\n  facet_grid(~ raca_cor) +                        # Separar por raça/cor\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotacionar rótulos\n\n\n3.5.2.4 Boxplot\nMostra a distribuição de variáveis contínuas:\n\nggplot(data = dados_limpos, mapping = aes(x = sexo, y = idade)) +\n  geom_boxplot(fill = \"lightblue\", outlier.color = \"red\") +\n  labs(\n    title = \"Distribuição de Idade por Sexo\",\n    x = \"Sexo\",\n    y = \"Idade (anos)\"\n  ) +\n  theme_minimal()\n\nInterpretação do Boxplot:\n\n\nLinha central: Mediana\n\nCaixa: Intervalo interquartil (IQR) - contém 50% dos dados\n\nLinhas (whiskers): Extensão até 1.5 × IQR\n\nPontos: Valores atípicos (outliers)\n\n3.5.2.5 Histograma\nMostra a distribuição de frequências de uma variável contínua:\n\nggplot(data = dados_limpos, mapping = aes(x = idade)) +\n  geom_histogram(bins = 30, fill = \"navy\", color = \"white\") +\n  labs(\n    title = \"Distribuição de Idade dos Pacientes\",\n    x = \"Idade (anos)\",\n    y = \"Frequência\"\n  ) +\n  theme_minimal()\n\nVocê pode ajustar o número de bins ou especificar a largura:\n\n# Com binwidth específica\nggplot(data = dados_limpos, mapping = aes(x = idade)) +\n  geom_histogram(binwidth = 5, fill = \"navy\", color = \"white\")\n\n\n3.5.2.6 Gráfico de Dispersão (Scatter Plot)\nMostra a relação entre duas variáveis contínuas:\n\nggplot(data = dados_limpos, mapping = aes(x = idade, y = dias_perm)) +\n  geom_point(alpha = 0.5, color = \"navy\") +   # alpha para transparência\n  geom_smooth(method = \"lm\", color = \"red\") + # Linha de tendência\n  labs(\n    title = \"Relação entre Idade e Dias de Permanência\",\n    x = \"Idade (anos)\",\n    y = \"Dias de permanência\"\n  ) +\n  theme_minimal()\n\n\n3.5.2.7 Gráfico Hexagonal (para muitos pontos)\n\nggplot(data = dados_limpos, mapping = aes(x = dias_perm, y = val_tot)) +\n  geom_hex() +                                # Hexágonos para densidade\n  geom_smooth(method = \"glm\", color = \"red\") +\n  labs(\n    x = \"Dias de Permanência\",\n    y = \"Valor Total (R$)\",\n    title = \"Correlação entre Dias de Permanência e Valor Total\",\n    subtitle = \"Dados de 2024\",\n    caption = \"Fonte: SIH\"\n  ) +\n  scale_fill_viridis_c() +                    # Escala de cores viridis\n  theme_minimal()\n\n\n3.5.3 Gráficos de Tendência Temporal\nVisualizando tendências ao longo do tempo:\n\n# Preparar dados: ordenar meses corretamente\nmeses_pt &lt;- c(\"Janeiro\", \"Fevereiro\", \"Março\", \"Abril\", \"Maio\", \"Junho\",\n              \"Julho\", \"Agosto\", \"Setembro\", \"Outubro\", \"Novembro\", \"Dezembro\")\n\ndados_limpos$mes_cmpt &lt;- factor(dados_limpos$mes_cmpt,\n                                levels = 1:12,\n                                labels = meses_pt)\n\n\nggplot(data = dados_limpos, aes(x = mes_cmpt, y = val_tot)) +\n  stat_summary(fun = mean, geom = \"line\", aes(group = 1), color = \"navy\", size = 1) +\n  stat_summary(fun = mean, geom = \"point\", color = \"darkred\", size = 3) +\n  labs(\n    title = \"Valor Médio de Internações por Mês\",\n    subtitle = \"Maringá-PR, 2024\",\n    x = \"Mês\",\n    y = \"Valor médio (R$)\",\n    caption = \"Fonte: SIH\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n3.5.4 Faceting: Múltiplos Gráficos\nO faceting permite criar múltiplos gráficos baseados em uma variável categórica:\n\n3.5.4.1 facet_wrap()\n\nggplot(data = dados_limpos, aes(x = idade)) +\n  geom_histogram(bins = 30, fill = \"navy\") +\n  facet_wrap(~ raca_cor, ncol = 2) +\n  labs(\n    title = \"Distribuição de Idade por Raça/Cor\",\n    x = \"Idade (anos)\",\n    y = \"Frequência\"\n  ) +\n  theme_minimal()\n\n\n3.5.4.2 facet_grid()\n\nggplot(data = dados_limpos, aes(x = sexo, y = idade, fill = sexo)) +\n  geom_boxplot() +\n  facet_grid(morte ~ raca_cor) +\n  labs(\n    title = \"Idade por Sexo, Raça/Cor e Mortalidade\",\n    x = \"Sexo\",\n    y = \"Idade (anos)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n3.5.5 Customizando Temas\nO ggplot2 oferece vários temas prontos:\n\n# Temas disponíveis\ntheme_minimal()     # Minimalista (recomendado)\ntheme_classic()     # Clássico\ntheme_bw()          # Preto e branco\ntheme_light()       # Leve\ntheme_dark()        # Escuro\ntheme_void()        # Vazio (sem eixos)\n\n\n3.5.5.1 Criando Tema Personalizado\n\n# Tema personalizado para publicação\ntema_publicacao &lt;- theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(size = 12, hjust = 0.5),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    axis.text = element_text(size = 10),\n    legend.title = element_text(size = 11, face = \"bold\"),\n    legend.text = element_text(size = 10),\n    panel.grid.minor = element_blank()\n  )\n\n# Aplicar ao gráfico\nggplot(dados_limpos, aes(x = sexo, y = idade)) +\n  geom_boxplot() +\n  tema_publicacao\n\n\n3.5.6 Salvando Gráficos\n\n# Criar gráfico\np &lt;- ggplot(dados_limpos, aes(x = sexo, fill = morte)) +\n  geom_bar() +\n  theme_minimal()\n\n# Salvar como PNG\nggsave(\"grafico_mortalidade.png\", plot = p, width = 10, height = 6, dpi = 300)\n\n# Salvar como PDF (vetorial)\nggsave(\"grafico_mortalidade.pdf\", plot = p, width = 10, height = 6)\n\n# Salvar como TIFF (para publicação)\nggsave(\"grafico_mortalidade.tiff\", plot = p, width = 10, height = 6, dpi = 600)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Análise Exploratória de Dados</span>"
    ]
  },
  {
    "objectID": "analise-exploratoria.html#resumo-do-capítulo",
    "href": "analise-exploratoria.html#resumo-do-capítulo",
    "title": "\n3  Análise Exploratória de Dados\n",
    "section": "\n3.6 Resumo do Capítulo",
    "text": "3.6 Resumo do Capítulo\nNeste capítulo, você aprendeu:\n\n\nEstatística Descritiva:\n\nCriar tabelas descritivas profissionais com gtsummary\n\nEstratificar análises por grupos\nExportar tabelas para Word e Excel\n\n\n\nTestes Estatísticos:\n\nTeste de correlação (Pearson, Spearman)\nTeste qui-quadrado para variáveis categóricas\nTeste t para comparação de médias\nANOVA para comparação de múltiplos grupos\n\n\n\nVisualização com ggplot2:\n\nGráficos de barras (simples, agrupados, empilhados)\nBoxplots e histogramas\nGráficos de dispersão e hexagonais\nGráficos de tendência temporal\nFaceting para múltiplos gráficos\nCustomização de temas e cores\nExportação de gráficos em diferentes formatos\n\n\n\nNo próximo capítulo, você aprenderá sobre modelos de regressão linear e logística, ferramentas essenciais para análise preditiva em saúde.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Análise Exploratória de Dados</span>"
    ]
  },
  {
    "objectID": "analise-exploratoria.html#exercícios-práticos",
    "href": "analise-exploratoria.html#exercícios-práticos",
    "title": "\n3  Análise Exploratória de Dados\n",
    "section": "\n3.7 Exercícios Práticos",
    "text": "3.7 Exercícios Práticos\n\nCrie uma tabela descritiva estratificada por sexo, incluindo p-valores para testar diferenças entre grupos\nTeste se existe correlação significativa entre dias de permanência e valor total da internação\nRealize um teste qui-quadrado para verificar se existe associação entre raça/cor e mortalidade\nCrie um gráfico de barras mostrando a distribuição de internações por mês, colorido por mortalidade\nFaça um boxplot comparando dias de permanência entre pacientes que foram a óbito e os que sobreviveram\nCrie um gráfico de dispersão mostrando a relação entre idade e valor total, com pontos coloridos por sexo\nDesenvolva um painel com 4 gráficos usando faceting para comparar diferentes variáveis\nExporte sua melhor tabela descritiva para Word e seu melhor gráfico como PNG de alta resolução (300 dpi)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Análise Exploratória de Dados</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html",
    "href": "testes-estatisticos.html",
    "title": "\n4  Testes Estatísticos\n",
    "section": "",
    "text": "4.1 Introdução aos Testes de Hipóteses\nOs testes estatísticos são ferramentas fundamentais para responder perguntas científicas com base em dados. Eles nos permitem tomar decisões fundamentadas sobre relações, diferenças e associações entre variáveis, quantificando a incerteza das nossas conclusões.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#introdução-aos-testes-de-hipóteses",
    "href": "testes-estatisticos.html#introdução-aos-testes-de-hipóteses",
    "title": "\n4  Testes Estatísticos\n",
    "section": "",
    "text": "4.1.1 Lógica dos Testes de Hipóteses\nTodo teste estatístico segue uma lógica baseada em duas hipóteses complementares:\n\n\nHipótese Nula (H₀): Assume que não existe efeito, diferença ou associação entre as variáveis. É a hipótese de “status quo” ou “nenhuma mudança”.\n\nHipótese Alternativa (H₁): Propõe que existe um efeito, diferença ou associação. É o que geralmente buscamos evidenciar.\n\nExemplo prático:\nH₀: A média de idade entre homens e mulheres internados é igual\nH₁: A média de idade entre homens e mulheres internados é diferente\n\n4.1.2 Valor-p e Significância Estatística\nO valor-p (p-value) representa a probabilidade de obter os resultados observados (ou mais extremos) assumindo que a hipótese nula é verdadeira.\nInterpretação:\n\n\np &lt; 0,05: Rejeitamos H₀ → evidência estatisticamente significativa de que existe diferença/associação\n\np ≥ 0,05: Não rejeitamos H₀ → não há evidência estatística suficiente para afirmar que existe diferença/associação\n\nImportante: Significância estatística (p &lt; 0,05) não implica necessariamente relevância clínica ou prática. Sempre interprete os resultados no contexto do estudo.\n\n4.1.3 Intervalos de Confiança\nOs intervalos de confiança (IC) fornecem uma faixa de valores plausíveis para o parâmetro populacional.\n\n\nIC 95%: Temos 95% de confiança que o valor verdadeiro está dentro deste intervalo\nSe o IC não inclui zero (para diferenças) ou 1 (para razões), o resultado é estatisticamente significativo (p &lt; 0,05)\n\n4.1.4 Erros em Testes de Hipóteses\n\n\n\nH₀ Verdadeira\nH₀ Falsa\n\n\n\nRejeitar H₀\nErro Tipo I (α)\nDecisão correta\n\n\nNão rejeitar H₀\nDecisão correta\nErro Tipo II (β)\n\n\n\n\n\nErro Tipo I (α): Falso positivo - rejeitar H₀ quando ela é verdadeira (fixado em 0,05)\n\nErro Tipo II (β): Falso negativo - não rejeitar H₀ quando ela é falsa",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#árvore-de-decisão-qual-teste-usar",
    "href": "testes-estatisticos.html#árvore-de-decisão-qual-teste-usar",
    "title": "\n4  Testes Estatísticos\n",
    "section": "\n4.2 Árvore de Decisão: Qual Teste Usar?",
    "text": "4.2 Árvore de Decisão: Qual Teste Usar?\nAntes de realizar qualquer teste, é fundamental escolher o teste apropriado para suas variáveis e pergunta de pesquisa.\n\n4.2.1 Fluxograma de Seleção de Testes\n\nflowchart TD\n    A[Qual é o seu objetivo?] --&gt; B{Comparar grupos?}\n    A --&gt; C{Testar associação?}\n    A --&gt; D{Medir correlação?}\n\n    B --&gt; E{Variável dependente}\n    E --&gt; F[Numérica]\n    E --&gt; G[Categórica]\n\n    F --&gt; H{Quantos grupos?}\n    H --&gt; I[2 grupos]\n    H --&gt; J[3+ grupos]\n\n    I --&gt; K{Dados normais?}\n    K --&gt; |Sim| L[Teste t]\n    K --&gt; |Não| M[Mann-Whitney]\n\n    J --&gt; N{Dados normais?}\n    N --&gt; |Sim| O[ANOVA]\n    N --&gt; |Não| P[Kruskal-Wallis]\n\n    C --&gt; Q{Ambas categóricas}\n    Q --&gt; R{Tamanho da amostra?}\n    R --&gt; |Grande| S[Qui-quadrado]\n    R --&gt; |Pequena| T[Teste Exato de Fisher]\n\n    D --&gt; U{Ambas numéricas}\n    U --&gt; V{Dados normais?}\n    V --&gt; |Sim| W[Correlação de Pearson]\n    V --&gt; |Não| X[Correlação de Spearman]\n\n\n\n\nflowchart TD\n    A[Qual é o seu objetivo?] --&gt; B{Comparar grupos?}\n    A --&gt; C{Testar associação?}\n    A --&gt; D{Medir correlação?}\n\n    B --&gt; E{Variável dependente}\n    E --&gt; F[Numérica]\n    E --&gt; G[Categórica]\n\n    F --&gt; H{Quantos grupos?}\n    H --&gt; I[2 grupos]\n    H --&gt; J[3+ grupos]\n\n    I --&gt; K{Dados normais?}\n    K --&gt; |Sim| L[Teste t]\n    K --&gt; |Não| M[Mann-Whitney]\n\n    J --&gt; N{Dados normais?}\n    N --&gt; |Sim| O[ANOVA]\n    N --&gt; |Não| P[Kruskal-Wallis]\n\n    C --&gt; Q{Ambas categóricas}\n    Q --&gt; R{Tamanho da amostra?}\n    R --&gt; |Grande| S[Qui-quadrado]\n    R --&gt; |Pequena| T[Teste Exato de Fisher]\n\n    D --&gt; U{Ambas numéricas}\n    U --&gt; V{Dados normais?}\n    V --&gt; |Sim| W[Correlação de Pearson]\n    V --&gt; |Não| X[Correlação de Spearman]\n\n\n\n\n\n\n\n4.2.2 Tabela Resumo de Testes\n\n\n\n\n\n\n\n\n\nObjetivo\nVariável Dependente\nVariável Independente\nTeste Paramétrico\nTeste Não-Paramétrico\n\n\n\nComparar 2 grupos\nNumérica\nCategórica (2 níveis)\nTeste t\nMann-Whitney\n\n\nComparar 3+ grupos\nNumérica\nCategórica (3+ níveis)\nANOVA\nKruskal-Wallis\n\n\nTestar associação\nCategórica\nCategórica\nQui-quadrado\nTeste Exato de Fisher\n\n\nMedir correlação\nNumérica\nNumérica\nPearson\nSpearman / Kendall",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#preparação-dos-dados",
    "href": "testes-estatisticos.html#preparação-dos-dados",
    "title": "\n4  Testes Estatísticos\n",
    "section": "\n4.3 Preparação dos Dados",
    "text": "4.3 Preparação dos Dados\nAntes de realizar os testes estatísticos, precisamos carregar os pacotes e preparar os dados.\n\nlibrary(tidyverse)    # Manipulação de dados\nlibrary(readxl)       # Leitura de Excel\nlibrary(janitor)      # Limpeza de dados\nlibrary(car)          # Testes estatísticos avançados\nlibrary(FSA)          # Teste de Dunn (post-hoc Kruskal-Wallis)\nlibrary(ggpubr)       # Gráficos estatísticos\n\n# Remover notação científica\noptions(scipen = 999)\n\n\n# Carregar dados de internações\ndados &lt;- read_excel(\"data/dados_internacoes_maringa_2024.xlsx\")\n\n# Preparar dados\ndados_limpos &lt;- dados |&gt;\n  clean_names() |&gt;\n  filter(cod_idade == \"Anos\") |&gt;\n  select(sexo, val_tot, raca_cor, idade, morte, dias_perm) |&gt;\n  mutate(\n    raca_cor = case_when(\n      raca_cor == '01' ~ \"Branca\",\n      raca_cor == \"02\" ~ \"Preta\",\n      raca_cor == \"03\" ~ \"Parda\",\n      raca_cor == \"04\" ~ \"Amarela\",\n      raca_cor == \"05\" ~ \"Indígena\"\n    )\n  ) |&gt;\n  mutate(across(c(val_tot, idade, dias_perm), as.numeric)) |&gt;\n  mutate(across(c(sexo, raca_cor, morte), as.factor)) |&gt;\n  rename(df = everything())  # Para compatibilidade com scripts existentes",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#pressupostos-dos-testes-paramétricos",
    "href": "testes-estatisticos.html#pressupostos-dos-testes-paramétricos",
    "title": "\n4  Testes Estatísticos\n",
    "section": "\n4.4 Pressupostos dos Testes Paramétricos",
    "text": "4.4 Pressupostos dos Testes Paramétricos\nOs testes paramétricos (t-test, ANOVA, Pearson) assumem que os dados seguem certas condições. Quando essas condições não são atendidas, devemos usar alternativas não-paramétricas.\n\n4.4.1 Teste de Normalidade\nA normalidade dos dados é o pressuposto mais importante para testes paramétricos.\n\n4.4.1.1 Avaliação Visual\nO gráfico de densidade ou histograma fornece uma primeira impressão sobre a distribuição:\n\n# Histograma da idade\nggplot(dados_limpos, aes(x = idade)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  labs(title = \"Distribuição da Idade\",\n       x = \"Idade (anos)\",\n       y = \"Frequência\") +\n  theme_minimal()\n\n\n4.4.1.2 Teste de Shapiro-Wilk\nO teste de Shapiro-Wilk é o teste mais utilizado para avaliar normalidade:\n\n# Teste de Shapiro-Wilk (para amostras &lt; 5000)\nshapiro.test(sample(dados_limpos$idade, 5000))\n\nInterpretação:\n\n\nH₀: Os dados seguem distribuição normal\n\np &gt; 0,05: Não rejeitamos H₀ → dados são normais\n\np &lt; 0,05: Rejeitamos H₀ → dados não são normais\n\nImportante: O teste de Shapiro-Wilk é sensível ao tamanho da amostra. Com amostras muito grandes, pequenos desvios da normalidade podem ser significativos. Use também avaliação visual.\n\n4.4.1.3 Teste de Kolmogorov-Smirnov\nAlternativa para grandes amostras:\n\n# Teste de Kolmogorov-Smirnov\nks.test(dados_limpos$idade, \"pnorm\",\n        mean = mean(dados_limpos$idade),\n        sd = sd(dados_limpos$idade))\n\n\n4.4.2 Homogeneidade de Variâncias\nPara testes que comparam grupos (t-test, ANOVA), as variâncias entre grupos devem ser similares.\n\n4.4.2.1 Teste de Levene\n\n# Teste de Levene para homogeneidade de variâncias\nleveneTest(idade ~ sexo, data = dados_limpos)\n\nInterpretação:\n\n\nH₀: As variâncias dos grupos são iguais\n\np &gt; 0,05: Variâncias homogêneas → pode usar teste t padrão\n\np &lt; 0,05: Variâncias heterogêneas → usar Welch’s t-test",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#testes-paramétricos",
    "href": "testes-estatisticos.html#testes-paramétricos",
    "title": "\n4  Testes Estatísticos\n",
    "section": "\n4.5 Testes Paramétricos",
    "text": "4.5 Testes Paramétricos\n\n4.5.1 Teste t de Student\nO teste t compara as médias de dois grupos independentes assumindo distribuição normal e variâncias homogêneas.\n\n4.5.1.1 Quando usar?\n\n\nVariável dependente: Numérica contínua (ex: idade, custo, tempo)\n\nVariável independente: Categórica binária (ex: sexo, grupo tratamento/controle)\n\nPressupostos: Normalidade e homogeneidade de variâncias\n\n4.5.1.2 Exemplo: Diferença de idade entre sexos\nPergunta de pesquisa: Há diferença na idade média de internação entre homens e mulheres?\n\n# Passo 1: Verificar pressupostos\n# Normalidade\nshapiro.test(sample(dados_limpos$idade, 5000))\n\n# Homogeneidade de variâncias\nleveneTest(idade ~ sexo, data = dados_limpos)\n\n# Passo 2: Realizar teste t\n# Se variâncias iguais (Levene p &gt; 0.05)\nt.test(idade ~ sexo, data = dados_limpos, var.equal = TRUE)\n\n# Se variâncias diferentes (Levene p &lt; 0.05) - Welch's t-test\nt.test(idade ~ sexo, data = dados_limpos, var.equal = FALSE)\n\n\n4.5.1.3 Interpretação dos Resultados\nWelch Two Sample t-test\n\ndata:  idade by sexo\nt = -5.3159, df = 28465, p-value = 1.066e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.925  -1.094\nsample estimates:\nmean in group Feminino mean in group Masculino\n              45.09                  46.60\nInterpretação:\n\n\nt = -5.32: Estatística t (quanto maior, maior a diferença entre grupos)\n\ndf = 28.465: Graus de liberdade (relacionado ao tamanho da amostra)\n\np &lt; 0,001: Forte evidência de diferença significativa entre sexos\n\nIC 95% [-1,93; -1,09]: Não inclui zero → diferença é significativa\n\nMédias: Homens são internados, em média, 1,51 anos mais velhos que mulheres (46,60 - 45,09)\n\n4.5.1.4 Visualização\n\nggplot(dados_limpos, aes(x = sexo, y = idade, fill = sexo)) +\n  geom_boxplot(alpha = 0.6) +\n  stat_compare_means(method = \"t.test\") +  # Adiciona p-valor\n  labs(title = \"Distribuição da Idade por Sexo\",\n       x = \"Sexo\",\n       y = \"Idade (anos)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n4.5.2 ANOVA (Análise de Variância)\nA ANOVA compara as médias de três ou mais grupos independentes.\n\n4.5.2.1 Quando usar?\n\n\nVariável dependente: Numérica contínua\n\nVariável independente: Categórica com 3+ níveis (ex: raça/cor, região, faixa etária)\n\nPressupostos: Normalidade dos resíduos e homogeneidade de variâncias\n\n4.5.2.2 Exemplo: Idade média entre grupos de raça/cor\nPergunta de pesquisa: A idade média de internação varia entre os diferentes grupos de raça/cor?\n\n# Ajustar modelo ANOVA\nmodelo_anova &lt;- aov(idade ~ raca_cor, data = dados_limpos)\n\n# Resultados da ANOVA\nsummary(modelo_anova)\n\n\n4.5.2.3 Interpretação dos Resultados\n            Df   Sum Sq Mean Sq F value   Pr(&gt;F)\nraca_cor     4    24015    6004   23.11 &lt; 2e-16 ***\nResiduals 28994  7531748     260\nInterpretação:\n\n\nF = 23,11: Estatística F (razão entre variância entre grupos / variância dentro dos grupos)\n\np &lt; 0,001: Pelo menos um grupo difere significativamente dos demais\n\nLimitação: A ANOVA apenas indica que existe diferença, mas não informa quais grupos diferem\n\n4.5.2.4 Post-hoc: Teste de Tukey HSD\nPara identificar quais grupos diferem entre si, usamos testes post-hoc:\n\n# Teste de Tukey para comparações múltiplas\nTukeyHSD(modelo_anova)\n\n\n4.5.2.5 Interpretação do Teste de Tukey\n           diff      lwr      upr   p adj\nPreta-Branca     -2.14   -3.85   -0.43  0.0047\nParda-Branca     -1.67   -2.35   -0.98  0.0000\nAmarela-Branca    0.84   -2.76    4.44  0.9785\nIndígena-Branca  -4.23  -10.80    2.34  0.4320\n...\nInterpretação:\n\n\ndiff: Diferença média entre os grupos\n\nlwr / upr: Intervalo de confiança 95%\n\np adj: Valor-p ajustado para múltiplas comparações\nSe p adj &lt; 0,05 e o IC não inclui zero → grupos diferem significativamente\n\nExemplo: Pessoas de raça Preta são internadas, em média, 2,14 anos mais jovens que pessoas de raça Branca (p = 0,0047).\n\n4.5.2.6 Verificação dos Pressupostos da ANOVA\n\n# 1. Normalidade dos resíduos\nshapiro.test(sample(residuals(modelo_anova), 5000))\n\n# Q-Q plot dos resíduos\nqqnorm(residuals(modelo_anova))\nqqline(residuals(modelo_anova), col = \"red\")\n\n# 2. Homogeneidade de variâncias\nleveneTest(idade ~ raca_cor, data = dados_limpos)\n\n\n4.5.2.7 Visualização\n\nggplot(dados_limpos, aes(x = raca_cor, y = idade, fill = raca_cor)) +\n  geom_boxplot(alpha = 0.6) +\n  stat_compare_means(method = \"anova\") +\n  labs(title = \"Distribuição da Idade por Raça/Cor\",\n       x = \"Raça/Cor\",\n       y = \"Idade (anos)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#testes-não-paramétricos",
    "href": "testes-estatisticos.html#testes-não-paramétricos",
    "title": "\n4  Testes Estatísticos\n",
    "section": "\n4.6 Testes Não-Paramétricos",
    "text": "4.6 Testes Não-Paramétricos\nQuando os pressupostos dos testes paramétricos não são atendidos (dados não normais ou variâncias heterogêneas), usamos alternativas não-paramétricas.\n\n4.6.1 Teste de Mann-Whitney (Wilcoxon)\nAlternativa não-paramétrica ao teste t para comparar dois grupos independentes.\n\n4.6.1.1 Quando usar?\n\nOs dados não seguem distribuição normal\nVariâncias muito heterogêneas\nDados ordinais (ex: escalas Likert)\nPresença de outliers extremos\n\n4.6.1.2 Exemplo\n\n# Teste de Mann-Whitney\nwilcox.test(idade ~ sexo, data = dados_limpos)\n\n\n4.6.1.3 Interpretação\nWilcoxon rank sum test with continuity correction\n\ndata:  idade by sexo\nW = 98234567, p-value = 2.234e-07\nalternative hypothesis: true location shift is not equal to 0\nInterpretação:\n\n\nW: Estatística do teste (soma dos ranks)\n\np &lt; 0,001: Diferença significativa entre os grupos\nO teste compara medianas e distribuições, não médias\nPara identificar a direcionalidade, calcular medianas por grupo:\n\n\ndados_limpos %&gt;%\n  group_by(sexo) %&gt;%\n  summarise(\n    Mediana = median(idade, na.rm = TRUE),\n    Media = mean(idade, na.rm = TRUE),\n    n = n()\n  )\n\n\n4.6.2 Teste de Kruskal-Wallis\nAlternativa não-paramétrica à ANOVA para comparar três ou mais grupos.\n\n4.6.2.1 Quando usar?\n\nDados não seguem distribuição normal\nVariâncias heterogêneas\nVariável dependente ordinal\n\n4.6.2.2 Exemplo\n\n# Teste de Kruskal-Wallis\nkruskal.test(idade ~ raca_cor, data = dados_limpos)\n\n\n4.6.2.3 Interpretação\nKruskal-Wallis rank sum test\n\ndata:  idade by raca_cor\nKruskal-Wallis chi-squared = 89.456, df = 4, p-value &lt; 2.2e-16\nInterpretação:\n\n\nχ² = 89,46: Estatística do teste\n\ndf = 4: Graus de liberdade (número de grupos - 1)\n\np &lt; 0,001: Pelo menos um grupo difere dos demais\n\n4.6.2.4 Post-hoc: Teste de Dunn\nPara comparações múltiplas após Kruskal-Wallis:\n\n# Teste de Dunn com correção de Bonferroni\ndunnTest(idade ~ raca_cor, data = dados_limpos, method = \"bonferroni\")\n\nInterpretação: Similar ao Tukey HSD, identifica quais pares de grupos diferem significativamente.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#testes-para-variáveis-categóricas",
    "href": "testes-estatisticos.html#testes-para-variáveis-categóricas",
    "title": "\n4  Testes Estatísticos\n",
    "section": "\n4.7 Testes para Variáveis Categóricas",
    "text": "4.7 Testes para Variáveis Categóricas\n\n4.7.1 Teste Qui-Quadrado (χ²)\nO teste qui-quadrado avalia a associação entre duas variáveis categóricas.\n\n4.7.1.1 Quando usar?\n\nAmbas as variáveis são categóricas\nTamanho amostral grande (todas as células da tabela de contingência devem ter frequência esperada ≥ 5)\n\n4.7.1.2 Exemplo: Associação entre sexo e mortalidade\nPergunta de pesquisa: Existe associação entre sexo e mortalidade hospitalar?\n\n# Criar tabela de contingência\ntabela_contingencia &lt;- table(dados_limpos$sexo, dados_limpos$morte)\n\n# Visualizar tabela\ntabela_contingencia\n\n# Aplicar teste qui-quadrado\nchisq.test(tabela_contingencia)\n\n\n4.7.1.3 Interpretação\nPearson's Chi-squared test with Yates' continuity correction\n\ndata:  tabela_contingencia\nX-squared = 12.34, df = 1, p-value = 0.0004432\nInterpretação:\n\n\nX² = 12,34: Estatística qui-quadrado (mede discrepância entre frequências observadas e esperadas)\n\ndf = 1: Graus de liberdade = (linhas - 1) × (colunas - 1)\n\np &lt; 0,001: Existe associação significativa entre sexo e mortalidade\n\nPara entender a direção da associação:\n\n# Proporções por linha\nprop.table(tabela_contingencia, margin = 1)\n\n\n4.7.1.4 Visualização com Mosaic Plot\n\nlibrary(vcd)\n\nmosaic(~ sexo + morte, data = dados_limpos,\n       shade = TRUE,\n       legend = TRUE,\n       main = \"Associação entre Sexo e Mortalidade\")\n\n\n4.7.2 Teste Exato de Fisher\nAlternativa ao qui-quadrado para amostras pequenas (frequência esperada &lt; 5 em alguma célula).\n\n4.7.2.1 Quando usar?\n\nVariáveis categóricas\nTabelas 2×2 ou pequenas\nFrequências esperadas &lt; 5\n\n4.7.2.2 Exemplo\n\n# Criar tabela de contingência\ntabela2 &lt;- table(dados_limpos$raca_cor, dados_limpos$sexo)\n\n# Teste exato de Fisher\nfisher.test(tabela2, simulate.p.value = TRUE)  # Simulação para tabelas maiores\n\nNota: Para tabelas maiores que 2×2, o teste pode ser computacionalmente intensivo. Use simulate.p.value = TRUE para aproximação por simulação.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#testes-de-correlação",
    "href": "testes-estatisticos.html#testes-de-correlação",
    "title": "\n4  Testes Estatísticos\n",
    "section": "\n4.8 Testes de Correlação",
    "text": "4.8 Testes de Correlação\nA correlação mede a força e direção da relação linear entre duas variáveis numéricas.\n\n4.8.1 Coeficiente de Correlação\nO coeficiente varia de -1 a +1:\n\n\nr = +1: Correlação positiva perfeita\n\nr = 0: Sem correlação linear\n\nr = -1: Correlação negativa perfeita\n\nInterpretação da magnitude:\n\n\nValor de |r|\nInterpretação\n\n\n\n0,00 - 0,10\nDesprezível\n\n\n0,10 - 0,30\nFraca\n\n\n0,30 - 0,50\nModerada\n\n\n0,50 - 0,70\nForte\n\n\n0,70 - 1,00\nMuito forte\n\n\n\n4.8.2 Correlação de Pearson\nA correlação de Pearson mede a relação linear entre variáveis com distribuição normal.\n\n4.8.2.1 Quando usar?\n\nAmbas as variáveis são numéricas contínuas\nRelação linear entre as variáveis\nDados seguem distribuição normal\n\n4.8.2.2 Exemplo: Correlação entre idade e custo de internação\n\n# Teste de correlação de Pearson\ncor.test(dados_limpos$idade, dados_limpos$val_tot, method = \"pearson\")\n\n\n4.8.2.3 Interpretação\nPearson's product-moment correlation\n\ndata:  dados_limpos$idade and dados_limpos$val_tot\nt = 8.234, df = 28998, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.0357  0.0589\nsample estimates:\n      cor\n0.0473\nInterpretação:\n\n\nr = 0,047: Correlação positiva muito fraca\n\np &lt; 0,001: A correlação é estatisticamente significativa\n\nIC 95% [0,036; 0,059]: Não inclui zero → significativo\n\nConclusão: Embora estatisticamente significativa, a correlação é muito fraca (praticamente desprezível), indicando que idade explica apenas 0,22% da variabilidade no custo (r² = 0,047² = 0,0022)\n\n4.8.3 Correlação de Spearman\nAlternativa não-paramétrica que mede correlação monotônica (não necessariamente linear).\n\n4.8.3.1 Quando usar?\n\nDados não seguem distribuição normal\nRelação monotônica (não linear)\nPresença de outliers\nDados ordinais\n\n4.8.3.2 Exemplo\n\n# Teste de correlação de Spearman\ncor.test(dados_limpos$idade, dados_limpos$val_tot, method = \"spearman\")\n\n\n4.8.4 Visualização de Correlação\n\n4.8.4.1 Gráfico de Dispersão\n\nggplot(dados_limpos, aes(x = idade, y = val_tot)) +\n  geom_point(alpha = 0.3, size = 1) +\n  geom_smooth(method = \"loess\", color = \"red\", se = TRUE) +\n  labs(title = \"Relação entre Idade e Custo de Internação\",\n       x = \"Idade (anos)\",\n       y = \"Custo da Internação (R$)\") +\n  scale_y_continuous(labels = scales::number_format(big.mark = \".\", decimal.mark = \",\")) +\n  theme_minimal()\n\nObservações:\n\nA curva de suavização (loess) mostra uma relação quase plana\nMuitos outliers (custos muito altos) podem distorcer a correlação\nA visualização confirma a correlação muito fraca encontrada no teste\n\n4.8.4.2 Matriz de Correlação\nPara examinar múltiplas correlações simultaneamente:\n\nlibrary(corrplot)\n\n# Selecionar variáveis numéricas\nvars_numericas &lt;- dados_limpos %&gt;%\n  select(idade, val_tot, dias_perm) %&gt;%\n  na.omit()\n\n# Calcular matriz de correlação\nmatriz_cor &lt;- cor(vars_numericas, method = \"spearman\")\n\n# Visualizar\ncorrplot(matriz_cor,\n         method = \"color\",\n         type = \"upper\",\n         addCoef.col = \"black\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         diag = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#resumo-e-recomendações",
    "href": "testes-estatisticos.html#resumo-e-recomendações",
    "title": "\n4  Testes Estatísticos\n",
    "section": "\n4.9 Resumo e Recomendações",
    "text": "4.9 Resumo e Recomendações\n\n4.9.1 Escolhendo o Teste Apropriado\n\n\nIdentifique o tipo de variáveis:\n\nNuméricas contínuas → testes t, ANOVA, correlação\nCategóricas → qui-quadrado, Fisher\n\n\n\nVerifique os pressupostos:\n\nNormalidade (Shapiro-Wilk, Q-Q plot)\nHomogeneidade de variâncias (Levene)\n\n\n\nEscolha entre paramétrico e não-paramétrico:\n\nPressupostos atendidos → testes paramétricos (mais poder estatístico)\nPressupostos violados → testes não-paramétricos (mais robustos)\n\n\n\n4.9.2 Tabela de Decisão Rápida\n\n\nSituação\nTeste Recomendado\n\n\n\nComparar 2 grupos (normal)\nTeste t\n\n\nComparar 2 grupos (não normal)\nMann-Whitney\n\n\nComparar 3+ grupos (normal)\nANOVA + Tukey\n\n\nComparar 3+ grupos (não normal)\nKruskal-Wallis + Dunn\n\n\nAssociação entre categóricas (n grande)\nQui-quadrado\n\n\nAssociação entre categóricas (n pequeno)\nTeste Exato de Fisher\n\n\nCorrelação (normal, linear)\nPearson\n\n\nCorrelação (não normal, monotônica)\nSpearman\n\n\n\n4.9.3 Boas Práticas\n\n\nSempre verifique os pressupostos antes de escolher o teste\n\nVisualize os dados antes de interpretar os testes\n\nReporte os intervalos de confiança, não apenas p-valores\n\nInterprete no contexto clínico/prático, não apenas estatístico\n\nUse testes post-hoc para comparações múltiplas (Tukey, Dunn)\n\nConsidere o tamanho do efeito, não apenas significância\n\n4.9.4 Reportando Resultados\nAo reportar resultados de testes estatísticos em artigos científicos:\n\nTeste t: “Homens foram internados com idade média significativamente maior que mulheres (46,6 vs 45,1 anos; t = -5,32; p &lt; 0,001; IC 95%: -1,93 a -1,09)”\nANOVA: “A idade média de internação diferiu significativamente entre grupos de raça/cor (F(4, 28994) = 23,11; p &lt; 0,001). Testes post-hoc de Tukey revelaram…”\nQui-quadrado: “Observou-se associação significativa entre sexo e mortalidade (χ² = 12,34; df = 1; p &lt; 0,001)”\nCorrelação: “Idade e custo de internação apresentaram correlação positiva fraca, mas estatisticamente significativa (r = 0,047; p &lt; 0,001; IC 95%: 0,036 a 0,059)”",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "testes-estatisticos.html#exercícios-práticos",
    "href": "testes-estatisticos.html#exercícios-práticos",
    "title": "\n4  Testes Estatísticos\n",
    "section": "\n4.10 Exercícios Práticos",
    "text": "4.10 Exercícios Práticos\n\n4.10.1 Exercício 1: Teste t\nUse o dataset de internações para responder: Existe diferença significativa no tempo de permanência hospitalar (dias_perm) entre pacientes que foram a óbito e os que sobreviveram?\n\nVerifique os pressupostos (normalidade e homogeneidade de variâncias)\nEscolha o teste apropriado\nRealize o teste e interprete os resultados\nCrie um boxplot visualizando a comparação\n\n4.10.2 Exercício 2: ANOVA\nInvestigue se o custo médio de internação (val_tot) difere entre os diferentes meses de competência (mes_cmpt).\n\nRealize ANOVA\nSe significativo, faça o teste post-hoc de Tukey\nIdentifique quais meses diferem significativamente\nCrie um gráfico de boxplot com os resultados\n\n4.10.3 Exercício 3: Qui-quadrado\nAnalise se existe associação entre raça/cor (raca_cor) e mortalidade (morte).\n\nCrie uma tabela de contingência\nCalcule as proporções de óbito por grupo\nRealize o teste qui-quadrado\nCrie um mosaic plot para visualizar a associação\n\n4.10.4 Exercício 4: Correlação\nExamine a relação entre dias de permanência (dias_perm) e custo de internação (val_tot).\n\nCrie um gráfico de dispersão\nAvalie a normalidade das variáveis\nCalcule a correlação apropriada (Pearson ou Spearman)\nInterprete a força e direção da correlação\n\n4.10.5 Exercício 5: Comparações Múltiplas\nEscolha uma variável numérica e uma categórica do dataset. Realize uma análise completa:\n\nFormule uma pergunta de pesquisa\nVerifique pressupostos\nEscolha e realize o teste apropriado\nVisualize os resultados\nEscreva uma conclusão em formato de artigo científico\n\n\nReferências:\n\nField, A., Miles, J., & Field, Z. (2012). Discovering Statistics Using R. SAGE Publications.\nMotulsky, H. (2014). Intuitive Biostatistics: A Nonmathematical Guide to Statistical Thinking. Oxford University Press.\nWhitlock, M. C., & Schluter, D. (2015). The Analysis of Biological Data. Roberts and Company Publishers.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Testes Estatísticos</span>"
    ]
  },
  {
    "objectID": "regressao.html",
    "href": "regressao.html",
    "title": "\n5  Regressão Linear, Logística e Multinomial\n",
    "section": "",
    "text": "5.1 Introdução à Regressão\nNeste capítulo, exploraremos três técnicas estatísticas fundamentais em pesquisa em saúde: a regressão linear, a regressão logística e a regressão multinomial. Cada técnica é adequada para diferentes tipos de variáveis resposta.\nA análise de regressão é uma ferramenta estatística fundamental que permite:\nTrabalharemos com dados reais de internações hospitalares em Maringá-PR (2024) para ilustrar como essas técnicas podem ser aplicadas em contextos práticos da área da saúde.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regressão Linear, Logística e Multinomial</span>"
    ]
  },
  {
    "objectID": "regressao.html#introdução-à-regressão",
    "href": "regressao.html#introdução-à-regressão",
    "title": "\n5  Regressão Linear, Logística e Multinomial\n",
    "section": "",
    "text": "Inferência e causalidade: Avaliar precisamente como uma variável impacta outra\n\nPredição: Predizer o comportamento de uma variável a partir de outras",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regressão Linear, Logística e Multinomial</span>"
    ]
  },
  {
    "objectID": "regressao.html#regressão-linear",
    "href": "regressao.html#regressão-linear",
    "title": "\n5  Regressão Linear, Logística e Multinomial\n",
    "section": "\n5.2 Regressão Linear",
    "text": "5.2 Regressão Linear\n\n5.2.1 O que é uma Regressão Linear?\nA regressão linear é utilizada quando queremos modelar a relação entre uma variável dependente contínua (como custo de internação, pressão arterial, peso) e uma ou mais variáveis independentes (também chamadas de preditoras).\nVisualmente, a regressão linear é representada por uma linha que cruza os pontos de duas ou mais variáveis no gráfico de dispersão. Essa linha é definida por dois componentes principais:\n\n\nIntercepto (β₀): Ponto onde a variável X cruza Y no eixo vertical. Representa o valor de Y quando X for 0.\n\nInclinação ou slope (β₁): Inclinação da reta. Indica quanto Y varia para cada aumento de uma unidade em X.\n\nA qualidade do ajuste da reta é medida pelo R² (coeficiente de determinação), que varia de 0 a 1. Quanto mais próximo de 1, melhor a reta relaciona as duas variáveis.\n\n5.2.2 Equação da Regressão Linear\nA forma matemática da regressão linear simples é:\n\\[Y = \\beta_0 + \\beta_1X\\]\nOnde:\n\n\n\\(Y\\) = variável dependente (ex: valor total da internação)\n\n\\(\\beta_0\\) = intercepto (valor de Y quando X = 0)\n\n\\(\\beta_1\\) = coeficiente que indica a variação em Y para cada aumento da unidade de X\n\n\\(X\\) = variável independente (ex: idade)\n\n5.2.3 Exemplo Prático com R\nVamos trabalhar com dados de internações por apendicite em Maringá-PR para entender como a idade influencia o custo total das internações.\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(gtsummary)\nlibrary(officer)\nlibrary(flextable)\nlibrary(jtools)\nlibrary(car)\n\n# Retirar notação científica\noptions(scipen = 999)\n\n\n# Carregar banco de dados\ndados &lt;- read_excel(\"data/dados_internacoes_maringa_2024.xlsx\")\n\n\n5.2.3.1 Preparação dos Dados\nPrimeiro, vamos filtrar e limpar os dados, focando em internações por apendicite (CID K35):\n\n# Identificar doenças mais frequentes\ndf &lt;- table(dados$DIAG_PRINC)\ndf &lt;- data.frame(df)\n\n# Filtrando para apendicite (K35)\ndados_limpos &lt;- dados |&gt;\n  clean_names() |&gt;\n  filter(str_starts(diag_princ, \"K35\")) |&gt;\n  filter(cod_idade == \"Anos\") |&gt;\n  select(sexo, val_tot, raca_cor, idade, morte, dias_perm) |&gt;\n  mutate(raca_cor = case_when(\n    raca_cor == '01' ~ \"Branca\",\n    raca_cor == \"02\" ~ \"Preta\",\n    raca_cor == \"03\" ~ \"Parda\",\n    raca_cor == \"04\" ~ \"Amarela\",\n    raca_cor == \"05\" ~ \"Indígena\"\n  )) |&gt;\n  mutate(across(c(val_tot, idade, dias_perm), as.numeric)) |&gt;\n  mutate(across(c(sexo, raca_cor, morte), as.factor))\n\n\n5.2.3.2 Visualizando a Relação entre Idade e Custo\n\nggplot(dados_limpos, aes(x = idade, y = val_tot, colour = sexo)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", colour = \"navy\") +\n  labs(x = \"Idade\", y = \"Valor Total (BRL)\",\n       title = \"Custo de internações causadas por apendicite de acordo com a idade\",\n       subtitle = \"Dados de Maringá-PR referentes a 2024\",\n       caption = \"Fonte: SIH\") +\n  theme_minimal()\n\n\n\n\n\n\nFigure 5.1: Relação entre idade e custo de internações por apendicite\n\n\n\n\n\n5.2.3.3 Visualização com Escala Logarítmica\nQuando há outliers (valores extremos), podemos usar escala logarítmica para melhor visualização:\n\nggplot(dados_limpos, aes(x = idade, y = val_tot, colour = sexo)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", colour = \"navy\") +\n  labs(x = \"Idade\", y = \"Valor Total (BRL) - Escala Log\",\n       title = \"Relação entre Idade e o Valor Total da Internação\") +\n  scale_y_log10() +\n  theme_minimal()\n\n\n\n\n\n\nFigure 5.2: Relação entre idade e custo com escala logarítmica\n\n\n\n\n\n5.2.4 Etapas para Ajuste de um Modelo de Regressão\nA construção de um modelo de regressão segue etapas progressivas:\n\n\nModelo somente com intercepto: Útil para verificar o basal de Y\n\nModelo univariado: Uma única variável preditora\n\nModelo multivariado: Ajustado por várias variáveis preditoras\n\nImportante: Maior número de variáveis aumenta a complexidade e a dificuldade de interpretação do modelo.\n\n5.2.4.1 1. Modelo Somente com Intercepto\n\nmodelo &lt;- lm(val_tot ~ 1, dados_limpos)\n\n# Visualizando o modelo\nsumm(modelo)\n\n\n\n\nObservations\n115\n\n\nDependent variable\nval_tot\n\n\nType\nOLS linear regression\n\n\n\n  \n\n\n\n\nEst.\nS.E.\nt val.\np\n\n\n(Intercept)\n839.73\n92.34\n9.09\n0.00\n\n\n\n Standard errors: OLS\n\n\n\n\n\n\n\n\n\nO intercepto representa o valor médio basal de Y (custo total) sem considerar nenhuma variável preditora.\n\n5.2.4.2 2. Modelo Univariado com Idade\n\nmodelo_idade &lt;- lm(val_tot ~ idade, dados_limpos)\n\n# Visualizando resultados\nsumm(modelo_idade)\n\n\n\n\nObservations\n115\n\n\nDependent variable\nval_tot\n\n\nType\nOLS linear regression\n\n\n\n \n\n\n\nF(1,113)\n7.45\n\n\nR²\n0.06\n\n\nAdj. R²\n0.05\n\n\n\n \n\n\n\n\nEst.\nS.E.\nt val.\np\n\n\n\n(Intercept)\n408.80\n181.67\n2.25\n0.03\n\n\nidade\n15.48\n5.67\n2.73\n0.01\n\n\n\n\n Standard errors: OLS\n\n\n\n\n\n\n\n\n\nInterpretação do modelo:\n\nO intercepto (β₀) é 408,80\nO coeficiente da idade (β₁) é 15,48\nPara um paciente de 50 anos: Valor total = 408,80 + (15,48 × 50) = R$ 1.182,00\n\nO R² = 0,06 indica que a idade explica apenas 6% da variação no custo\n\n5.2.4.3 3. Modelo Ajustado por Sexo\nVariáveis categóricas são tratadas de forma especial. O R cria variáveis dummy, usando uma categoria como referência (baseline).\n\nmodelo_idade_sexo &lt;- lm(val_tot ~ idade + sexo, dados_limpos)\n\nsumm(modelo_idade_sexo)\n\n\n\n\nObservations\n115\n\n\nDependent variable\nval_tot\n\n\nType\nOLS linear regression\n\n\n\n \n\n\n\nF(2,112)\n5.31\n\n\nR²\n0.09\n\n\nAdj. R²\n0.07\n\n\n\n \n\n\n\n\nEst.\nS.E.\nt val.\np\n\n\n\n(Intercept)\n203.53\n215.07\n0.95\n0.35\n\n\nidade\n16.13\n5.63\n2.86\n0.01\n\n\nsexoMasculino\n316.77\n181.51\n1.75\n0.08\n\n\n\n\n Standard errors: OLS\n\n\n\n\n\n\n\n\n\nPor padrão, o R usa ordem alfabética para definir a categoria de referência. Podemos alterar isso:\n\n# Definindo Masculino como referência\ndados_limpos$sexo &lt;- factor(dados_limpos$sexo, levels = c(\"Masculino\", \"Feminino\"))\n\nmodelo_idade_sexo &lt;- lm(val_tot ~ idade + sexo, dados_limpos)\n\nsumm(modelo_idade_sexo)\n\n\n\n\nObservations\n115\n\n\nDependent variable\nval_tot\n\n\nType\nOLS linear regression\n\n\n\n \n\n\n\nF(2,112)\n5.31\n\n\nR²\n0.09\n\n\nAdj. R²\n0.07\n\n\n\n \n\n\n\n\nEst.\nS.E.\nt val.\np\n\n\n\n(Intercept)\n520.30\n191.05\n2.72\n0.01\n\n\nidade\n16.13\n5.63\n2.86\n0.01\n\n\nsexoFeminino\n-316.77\n181.51\n-1.75\n0.08\n\n\n\n\n Standard errors: OLS\n\n\n\n\n\n\n\n\n\n\n5.2.5 Diagnóstico do Modelo\n\n5.2.5.1 Multicolinearidade (VIF)\nQuando incluímos múltiplas variáveis, precisamos verificar se há multicolinearidade (correlação forte entre preditores).\nVIF (Variance Inflation Factor): se &gt; 5, há problema de multicolinearidade.\n\nvif(modelo_idade_sexo)\n\n   idade     sexo \n1.004327 1.004327 \n\n\n\n5.2.5.2 Teste de Heterocedasticidade\nA regressão linear assume que os resíduos têm variância constante (homocedasticidade).\n\nlmtest::bptest(modelo_idade_sexo)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_idade_sexo\nBP = 5.5554, df = 2, p-value = 0.06218\n\n\nSe p &lt; 0,05, há evidência de heterocedasticidade, o que pode violar as suposições do modelo.\n\n5.2.6 Modelo Multivariado Completo\n\nmodelo_final &lt;- lm(val_tot ~ idade + sexo + raca_cor + dias_perm, dados_limpos)\n\n# Verificar VIF\nvif(modelo_final)\n\n              GVIF Df GVIF^(1/(2*Df))\nidade     1.039816  1        1.019713\nsexo      1.068702  1        1.033781\nraca_cor  1.079688  3        1.012861\ndias_perm 1.083600  1        1.040961\n\n# Visualizar resultados\nsumm(modelo_final)\n\n\n\n\nObservations\n115\n\n\nDependent variable\nval_tot\n\n\nType\nOLS linear regression\n\n\n\n \n\n\n\nF(6,108)\n5.29\n\n\nR²\n0.23\n\n\nAdj. R²\n0.18\n\n\n\n \n\n\n\n\nEst.\nS.E.\nt val.\np\n\n\n\n(Intercept)\n-352.98\n467.83\n-0.75\n0.45\n\n\nidade\n20.06\n5.37\n3.74\n0.00\n\n\nsexoFeminino\n-246.24\n175.39\n-1.40\n0.16\n\n\nraca_corBranca\n122.79\n420.47\n0.29\n0.77\n\n\nraca_corParda\n364.11\n440.33\n0.83\n0.41\n\n\nraca_corPreta\n74.14\n755.77\n0.10\n0.92\n\n\ndias_perm\n196.26\n45.77\n4.29\n0.00\n\n\n\n\n Standard errors: OLS\n\n\n\n\n\n\n\n\n\n\n5.2.7 Apresentação de Resultados com Tabela\n\nmodelo_final |&gt;\n  tbl_regression(label = list(\n    idade ~ \"Idade (anos)\",\n    sexo ~ \"Sexo\",\n    raca_cor ~ \"Raça/Cor\",\n    dias_perm ~ \"Dias de hospitalização\"\n  )) |&gt;\n  bold_p(t = 0.05) |&gt;\n  bold_labels() |&gt;\n  italicize_levels() |&gt;\n  modify_header(label = \"**Variáveis preditoras**\") |&gt;\n  modify_footnote(label = \"Tabela 1: Efeito das variáveis preditoras sobre o custo de internação\") |&gt;\n  modify_header(estimate = \"**Coeficiente**\") |&gt;\n  as_flex_table()\n\n\nTable 5.1: Modelo de regressão linear para custo de internação por apendicite\n\n\n\n\n\n\nVariáveis preditoras1\nCoeficiente\n95% CI\np-value\n\n\n\nIdade (anos)\n20\n9.4, 31\n&lt;0.001\n\n\nSexo\n\n\n\n\n\nMasculino\n—\n—\n\n\n\nFeminino\n-246\n-594, 101\n0.2\n\n\nRaça/Cor\n\n\n\n\n\nAmarela\n—\n—\n\n\n\nBranca\n123\n-711, 956\n0.8\n\n\nParda\n364\n-509, 1,237\n0.4\n\n\nPreta\n74\n-1,424, 1,572\n&gt;0.9\n\n\nDias de hospitalização\n196\n106, 287\n&lt;0.001\n\n\n\n1Tabela 1: Efeito das variáveis preditoras sobre o custo de internação\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n5.2.8 Predição com o Modelo\nPodemos usar a função predict() para estimar valores:\n\n# Homem de 45 anos\npredict(modelo_idade_sexo, newdata = data.frame(\n  sexo = \"Masculino\", idade = 45))\n\n       1 \n1246.009 \n\n# Mulher de 45 anos\npredict(modelo_idade_sexo, newdata = data.frame(\n  sexo = \"Feminino\", idade = 45))\n\n      1 \n929.244",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regressão Linear, Logística e Multinomial</span>"
    ]
  },
  {
    "objectID": "regressao.html#regressão-logística",
    "href": "regressao.html#regressão-logística",
    "title": "\n5  Regressão Linear, Logística e Multinomial\n",
    "section": "\n5.3 Regressão Logística",
    "text": "5.3 Regressão Logística\n\n5.3.1 O que é uma Regressão Logística?\nA regressão logística é utilizada quando a variável dependente é categórica binária (sim/não, vivo/morto, doente/saudável). Diferentemente da regressão linear, que prediz valores contínuos, a regressão logística prediz a probabilidade de um determinado evento acontecer.\n\n5.3.2 Equação da Regressão Logística\nA forma matemática é:\n\\[\\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1X_1\\]\nOnde:\n\n\n\\(p\\) = probabilidade do evento ocorrer\n\n\\(\\frac{p}{1-p}\\) = odds (razão de chances) do evento\n\n\\(\\log\\left(\\frac{p}{1-p}\\right)\\) = log-odds ou logit\n\n\\(\\beta_0\\) = intercepto (log-odds quando todas as variáveis preditoras são 0)\n\n\\(\\beta_1\\) = coeficiente que quantifica a variação na probabilidade\n\n5.3.3 Exemplo Prático: Mortalidade por Septicemia\nVamos analisar fatores associados à morte hospitalar em pacientes com septicemia.\n\n5.3.3.1 Preparação dos Dados\n\n# Identificar diagnósticos com mortes\ndf_morte &lt;- table(dados$DIAG_PRINC, dados$MORTE)\ndf_morte &lt;- data.frame(df_morte)\n\n# Filtrar para septicemia (CID A419)\ndados_limpos_log &lt;- dados |&gt;\n  clean_names() |&gt;\n  filter(str_starts(diag_princ, \"A419\")) |&gt;\n  filter(cod_idade == \"Anos\") |&gt;\n  select(sexo, val_tot, raca_cor, idade, morte, dias_perm) |&gt;\n  mutate(raca_cor = case_when(\n    raca_cor == '01' ~ \"Branca\",\n    raca_cor == \"02\" ~ \"Preta\",\n    raca_cor == \"03\" ~ \"Parda\",\n    raca_cor == \"04\" ~ \"Amarela\",\n    raca_cor == \"05\" ~ \"Indígena\"\n  )) |&gt;\n  mutate(across(c(val_tot, idade, dias_perm), as.numeric)) |&gt;\n  mutate(across(c(sexo, raca_cor, morte), as.factor))\n\n# Criar variável binária para plotagem\ndados_limpos_log$morte_bin &lt;- ifelse(dados_limpos_log$morte == \"Sim\", 1, 0)\n\n\n5.3.3.2 Visualização da Relação Logística\n\nggplot(dados_limpos_log, aes(x = idade, y = morte_bin, colour = sexo)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), colour = \"navy\") +\n  labs(x = \"Idade\", y = \"Probabilidade de Morte Hospitalar\",\n       title = \"Aumento da idade leva a maior mortalidade por septicemia\",\n       subtitle = \"Dados de Maringá-PR referentes a 2024\",\n       caption = \"Fonte: SIH\") +\n  theme_minimal()\n\n\n\n\n\n\nFigure 5.3: Probabilidade de morte hospitalar por septicemia de acordo com a idade\n\n\n\n\n\n5.3.3.3 Visualização Separada por Sexo\n\nggplot(dados_limpos_log, aes(x = idade, y = morte_bin, colour = sexo)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), se = TRUE) +\n  labs(x = \"Idade\", y = \"Probabilidade de Morte Hospitalar\",\n       title = \"Aumento da idade leva a maior mortalidade por septicemia\",\n       subtitle = \"Dados de Maringá-PR referentes a 2024\",\n       caption = \"Fonte: SIH\") +\n  theme_minimal()\n\n\n\n\n\n\nFigure 5.4: Probabilidade de morte por septicemia estratificada por sexo\n\n\n\n\n\n5.3.3.4 Visualização com Jitter\nPara melhor visualização da densidade de pontos:\n\nggplot(dados_limpos_log, aes(x = idade, y = morte_bin, color = sexo)) +\n  geom_jitter(height = 0.05, alpha = 0.5) +\n  geom_smooth(method = \"glm\",\n              method.args = list(family = \"binomial\"),\n              se = TRUE) +\n  labs(x = \"Idade\",\n       y = \"Probabilidade de Morte Hospitalar\",\n       title = \"Aumento da idade leva a maior mortalidade por septicemia\",\n       subtitle = \"Dados de Maringá-PR referentes a 2024\",\n       caption = \"Fonte: SIH\") +\n  theme_minimal()\n\n\n\n\n\n\nFigure 5.5: Probabilidade de morte com jitter para melhor visualização\n\n\n\n\n\n5.3.4 Construindo Modelos Logísticos\n\n5.3.4.1 Preparação da Variável Dependente\nImportante: A variável dependente deve ser um fator. O R usa ordem alfabética para definir qual categoria é o “evento”. Podemos alterar isso:\n\n# Definir \"Sim\" como evento (segundo nível)\ndados_limpos_log$morte &lt;- factor(dados_limpos_log$morte, levels = c(\"Não\", \"Sim\"))\n\n\n5.3.4.2 1. Modelo com Intercepto Apenas\n\nmodelo_log &lt;- glm(morte ~ 1, family = \"binomial\", dados_limpos_log)\n\n# Visualizando\nsumm(modelo_log)\n\n\n\n\nObservations\n467\n\n\nDependent variable\nmorte\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n \n\n\n\nχ²(0)\n-0.00\n\n\np\nNA\n\n\nPseudo-R² (Cragg-Uhler)\n0.00\n\n\nPseudo-R² (McFadden)\n0.00\n\n\nAIC\n632.33\n\n\nBIC\n636.48\n\n\n\n \n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n(Intercept)\n-0.39\n0.09\n-4.09\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n# Com odds-ratio (exponenciando os coeficientes)\nsumm(modelo_log, exp = TRUE)\n\n\n\n\nObservations\n467\n\n\nDependent variable\nmorte\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n \n\n\n\nχ²(0)\n-0.00\n\n\np\nNA\n\n\nPseudo-R² (Cragg-Uhler)\n0.00\n\n\nPseudo-R² (McFadden)\n0.00\n\n\nAIC\n632.33\n\n\nBIC\n636.48\n\n\n\n \n\n\n\n\nexp(Est.)\n2.5%\n97.5%\nz val.\np\n\n\n(Intercept)\n0.68\n0.57\n0.82\n-4.09\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n5.3.4.3 2. Modelo Univariado com Idade\n\nmodelo_log_idade &lt;- glm(morte ~ idade, family = \"binomial\", dados_limpos_log)\n\n# Coeficientes brutos (log-odds)\nsumm(modelo_log_idade)\n\n\n\n\nObservations\n467\n\n\nDependent variable\nmorte\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n \n\n\n\nχ²(1)\n38.52\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.11\n\n\nPseudo-R² (McFadden)\n0.06\n\n\nAIC\n595.81\n\n\nBIC\n604.10\n\n\n\n \n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n\n(Intercept)\n-2.87\n0.46\n-6.25\n0.00\n\n\nidade\n0.04\n0.01\n5.67\n0.00\n\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n# Odds-ratio\nsumm(modelo_log_idade, exp = TRUE)\n\n\n\n\nObservations\n467\n\n\nDependent variable\nmorte\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n \n\n\n\nχ²(1)\n38.52\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.11\n\n\nPseudo-R² (McFadden)\n0.06\n\n\nAIC\n595.81\n\n\nBIC\n604.10\n\n\n\n \n\n\n\n\nexp(Est.)\n2.5%\n97.5%\nz val.\np\n\n\n\n(Intercept)\n0.06\n0.02\n0.14\n-6.25\n0.00\n\n\nidade\n1.04\n1.02\n1.05\n5.67\n0.00\n\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n5.3.4.4 3. Modelo com Idade e Sexo\n\nmodelo_log_idade_sexo &lt;- glm(morte ~ idade + sexo, family = \"binomial\", dados_limpos_log)\n\n# Verificar multicolinearidade\nvif(modelo_log_idade_sexo)\n\n  idade    sexo \n1.01195 1.01195 \n\n# Visualizar odds-ratio\nsumm(modelo_log_idade_sexo, exp = TRUE)\n\n\n\n\nObservations\n467\n\n\nDependent variable\nmorte\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n \n\n\n\nχ²(2)\n41.29\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.11\n\n\nPseudo-R² (McFadden)\n0.07\n\n\nAIC\n595.04\n\n\nBIC\n607.48\n\n\n\n \n\n\n\n\nexp(Est.)\n2.5%\n97.5%\nz val.\np\n\n\n\n(Intercept)\n0.04\n0.02\n0.12\n-6.37\n0.00\n\n\nidade\n1.04\n1.02\n1.05\n5.74\n0.00\n\n\nsexoMasculino\n1.39\n0.94\n2.05\n1.66\n0.10\n\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n5.3.5 Predição de Probabilidades\n\n# Homem de 45 anos\npredict(modelo_log_idade_sexo,\n        newdata = data.frame(sexo = \"Masculino\", idade = 45),\n        type = \"response\")\n\n        1 \n0.2443032 \n\n# Mulher de 45 anos\npredict(modelo_log_idade_sexo,\n        newdata = data.frame(sexo = \"Feminino\", idade = 45),\n        type = \"response\")\n\n        1 \n0.1887685 \n\n\n\n5.3.6 Apresentação de Resultados\n\nmodelo_log_idade_sexo |&gt;\n  tbl_regression(\n    label = list(\n      idade ~ \"Idade (anos)\",\n      sexo ~ \"Sexo\"\n    ),\n    exponentiate = TRUE\n  ) |&gt;\n  bold_p(t = 0.05) |&gt;\n  bold_labels() |&gt;\n  italicize_levels() |&gt;\n  modify_header(label = \"**Variáveis preditoras**\") |&gt;\n  modify_footnote(label = \"Tabela 2: Odds-ratio de mortalidade por septicemia\") |&gt;\n  modify_header(estimate = \"**OR**\") |&gt;\n  as_flex_table()\n\n\nTable 5.2: Modelo de regressão logística para mortalidade - modelo simples\n\n\n\n\n\n\nVariáveis preditoras1\nOR\n95% CI\np-value\n\n\n\nIdade (anos)\n1.04\n1.02, 1.05\n&lt;0.001\n\n\nSexo\n\n\n\n\n\nFeminino\n—\n—\n\n\n\nMasculino\n1.39\n0.94, 2.05\n0.10\n\n\n\n1Tabela 2: Odds-ratio de mortalidade por septicemia\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\n\n5.3.7 Modelo Multivariado Completo\n\nmodelo_log_final &lt;- glm(morte ~ idade + sexo + val_tot + raca_cor + dias_perm,\n                        family = \"binomial\",\n                        dados_limpos_log)\n\n# Verificar VIF\nvif(modelo_log_final)\n\n              GVIF Df GVIF^(1/(2*Df))\nidade     1.050219  1        1.024802\nsexo      1.038572  1        1.019104\nval_tot   3.430582  1        1.852183\nraca_cor  1.044049  3        1.007210\ndias_perm 3.349259  1        1.830098\n\n# Visualizar com odds-ratio\nsumm(modelo_log_final, exp = TRUE)\n\n\n\n\nObservations\n467\n\n\nDependent variable\nmorte\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n \n\n\n\nχ²(7)\n94.53\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.25\n\n\nPseudo-R² (McFadden)\n0.15\n\n\nAIC\n551.80\n\n\nBIC\n584.97\n\n\n\n \n\n\n\n\nexp(Est.)\n2.5%\n97.5%\nz val.\np\n\n\n\n(Intercept)\n0.06\n0.01\n0.31\n-3.30\n0.00\n\n\nidade\n1.04\n1.03\n1.05\n5.74\n0.00\n\n\nsexoMasculino\n1.20\n0.79\n1.83\n0.87\n0.38\n\n\nval_tot\n1.00\n1.00\n1.00\n5.29\n0.00\n\n\nraca_corBranca\n1.30\n0.31\n5.43\n0.36\n0.72\n\n\nraca_corParda\n0.85\n0.19\n3.80\n-0.21\n0.84\n\n\nraca_corPreta\n3.46\n0.66\n18.24\n1.46\n0.14\n\n\ndias_perm\n0.86\n0.82\n0.91\n-5.92\n0.00\n\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n5.3.7.1 Ajustando Categoria de Referência\n\n# Verificar distribuição\ntable(dados_limpos_log$raca_cor)\n\n\nAmarela  Branca   Parda   Preta \n     11     341      89      26 \n\n# Mudar \"Branca\" para categoria de referência (mais frequente)\ndados_limpos_log$raca_cor &lt;- factor(dados_limpos_log$raca_cor,\n                                     levels = c(\"Branca\", \"Amarela\", \"Parda\", \"Preta\"))\n\n# Rodar modelo novamente\nmodelo_log_final &lt;- glm(morte ~ idade + sexo + val_tot + raca_cor + dias_perm,\n                        family = \"binomial\",\n                        dados_limpos_log)\n\nsumm(modelo_log_final, exp = TRUE)\n\n\n\n\nObservations\n467\n\n\nDependent variable\nmorte\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n \n\n\n\nχ²(7)\n94.53\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.25\n\n\nPseudo-R² (McFadden)\n0.15\n\n\nAIC\n551.80\n\n\nBIC\n584.97\n\n\n\n \n\n\n\n\nexp(Est.)\n2.5%\n97.5%\nz val.\np\n\n\n\n(Intercept)\n0.07\n0.03\n0.21\n-4.88\n0.00\n\n\nidade\n1.04\n1.03\n1.05\n5.74\n0.00\n\n\nsexoMasculino\n1.20\n0.79\n1.83\n0.87\n0.38\n\n\nval_tot\n1.00\n1.00\n1.00\n5.29\n0.00\n\n\nraca_corAmarela\n0.77\n0.18\n3.20\n-0.36\n0.72\n\n\nraca_corParda\n0.66\n0.38\n1.14\n-1.51\n0.13\n\n\nraca_corPreta\n2.66\n1.06\n6.69\n2.08\n0.04\n\n\ndias_perm\n0.86\n0.82\n0.91\n-5.92\n0.00\n\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n5.3.8 Tabela Final do Modelo Multivariado\n\nmodelo_log_final |&gt;\n  tbl_regression(\n    label = list(\n      idade ~ \"Idade (anos)\",\n      sexo ~ \"Sexo\",\n      val_tot ~ \"Valor total (BRL)\",\n      raca_cor ~ \"Raça/Cor\",\n      dias_perm ~ \"Dias de hospitalização\"\n    ),\n    exponentiate = TRUE\n  ) |&gt;\n  bold_p(t = 0.05) |&gt;\n  bold_labels() |&gt;\n  italicize_levels() |&gt;\n  modify_header(label = \"**Variáveis preditoras**\") |&gt;\n  modify_footnote(label = \"Tabela 3: Odds-ratio de mortalidade por septicemia - modelo ajustado\") |&gt;\n  modify_header(estimate = \"**OR**\") |&gt;\n  as_flex_table()\n\n\nTable 5.3: Modelo multivariado de regressão logística para mortalidade por septicemia\n\n\n\n\n\n\nVariáveis preditoras1\nOR\n95% CI\np-value\n\n\n\nIdade (anos)\n1.04\n1.03, 1.05\n&lt;0.001\n\n\nSexo\n\n\n\n\n\nFeminino\n—\n—\n\n\n\nMasculino\n1.20\n0.79, 1.83\n0.4\n\n\nValor total (BRL)\n1.00\n1.00, 1.00\n&lt;0.001\n\n\nRaça/Cor\n\n\n\n\n\nBranca\n—\n—\n\n\n\nAmarela\n0.77\n0.16, 3.01\n0.7\n\n\nParda\n0.66\n0.37, 1.13\n0.13\n\n\nPreta\n2.66\n1.07, 6.87\n0.038\n\n\nDias de hospitalização\n0.86\n0.82, 0.90\n&lt;0.001\n\n\n\n1Tabela 3: Odds-ratio de mortalidade por septicemia - modelo ajustado\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regressão Linear, Logística e Multinomial</span>"
    ]
  },
  {
    "objectID": "regressao.html#interpretando-odds-ratio",
    "href": "regressao.html#interpretando-odds-ratio",
    "title": "\n5  Regressão Linear, Logística e Multinomial\n",
    "section": "\n5.4 Interpretando Odds Ratio",
    "text": "5.4 Interpretando Odds Ratio\nO Odds Ratio (OR) ou Razão de Chances é a métrica mais importante em regressão logística. É obtido exponenciando os coeficientes do modelo (exp = TRUE).\n\n5.4.1 Como Interpretar\n\n\nOR = 1: Não há associação entre a variável e o desfecho\n\nOR &gt; 1: As chances do evento são maiores no grupo exposto\n\nExemplo: OR = 1,04 → 4% mais chances\nExemplo: OR = 2,66 → 166% mais chances (ou 2,66 vezes mais chances)\n\n\n\nOR &lt; 1: As chances do evento são menores no grupo exposto\n\nExemplo: OR = 0,86 → 14% menos chances (1 - 0,86 = 0,14)\nExemplo: OR = 0,66 → 34% menos chances\n\n\n\n5.4.2 Exemplos Práticos de Interpretação\n\n5.4.2.1 1. Idade (OR = 1,04)\n\nCada ano a mais de idade aumenta em 4% as chances de óbito\n\nPara calcular o efeito cumulativo: OR^anos\n\nIndivíduo de 50 anos: 1,04^50 = 7\nChances de óbito 7 vezes maiores comparado a um recém-nascido\n\n\n\n5.4.2.2 2. Valor Total (OR = 1,00)\n\nEmbora significativo (p &lt; 0,001), o OR = 1,00 indica que cada real a mais no custo não altera as chances de morte\n\nValores muito próximos de 1 geralmente indicam efeito pequeno ou nulo\n\n5.4.2.3 3. Raça/Cor Preta (OR = 2,66)\n\nComparado a indivíduos brancos (categoria de referência), indivíduos pretos têm:\n\n\n2,66 vezes mais chances de óbito OU\n\n166% mais chances de óbito (2,66 - 1 = 1,66 = 166%)\n\n\n\n5.4.2.4 4. Dias de Hospitalização (OR = 0,86)\n\nCada dia a mais de hospitalização reduz em 14% as chances de óbito (1 - 0,86 = 0,14)\nPara múltiplos dias: 0,86^dias\n\n4 dias de hospitalização: 0,86^4 = 0,54\n\n46% menos chances de óbito (1 - 0,54 = 0,46)\n\n\n\n\n\n\n\n\n\nInterpretação Importante\n\n\n\nOdds ratio &lt; 1 indica efeito protetor (reduz chances do evento), enquanto &gt; 1 indica fator de risco (aumenta chances do evento).\nPara calcular a redução percentual quando OR &lt; 1: (1 - OR) × 100\n\n\n\n5.4.3 Cálculo Manual da Probabilidade\nEmbora o R faça isso automaticamente com predict(), entender o cálculo manual ajuda a compreender o modelo:\n\\[\\log\\left(\\frac{p}{1-p}\\right) = -2,87 + (0,04 \\times 50)\\]\n\\[\\log\\left(\\frac{p}{1-p}\\right) = -0,87\\]\n\\[\\frac{p}{1-p} = \\exp(-0,87) = 0,42\\]\nResolvendo para p:\n\\[p = \\frac{0,42}{1 + 0,42} = 0,29\\]\nResultado: Um paciente de 50 anos tem 29% de probabilidade de óbito.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regressão Linear, Logística e Multinomial</span>"
    ]
  },
  {
    "objectID": "regressao.html#regressão-multinomial",
    "href": "regressao.html#regressão-multinomial",
    "title": "\n5  Regressão Linear, Logística e Multinomial\n",
    "section": "\n5.5 Regressão Multinomial",
    "text": "5.5 Regressão Multinomial\n\n5.5.1 O que é Regressão Multinomial?\nA regressão multinomial (também chamada de regressão logística multinomial ou politômica) é uma extensão da regressão logística binária para variáveis resposta categóricas com três ou mais níveis não ordenados.\n\n5.5.1.1 Quando Usar?\nUse regressão multinomial quando:\n\n\nVariável resposta: Categórica com 3+ níveis não ordenados\n\nExemplos: tipo de tratamento escolhido (cirurgia, medicamento, fisioterapia)\nCategoria de diagnóstico (doença A, doença B, doença C)\n\nAnálise de sentimento (positivo, neutro, negativo)\n\n\n\nVariáveis preditoras: Numéricas e/ou categóricas\n\nObjetivo: Modelar probabilidade de cada categoria em função das preditoras\n\n\n\n\n\n\n\nRegressão Multinomial vs. Ordinal\n\n\n\n\n\nMultinomial: Categorias não têm ordem natural (ex: tipo sanguíneo A, B, AB, O)\n\nOrdinal: Categorias têm ordem natural (ex: leve, moderado, grave)\n\nPara variáveis ordinais, use regressão logística ordinal (não coberto neste livro).\n\n\n\n5.5.2 Conexão com o Capítulo 7\nA regressão multinomial é particularmente útil para análise de sentimento, onde classificamos texto em categorias como positivo, neutro, negativo. Consulte o Capítulo 7 - Análise de Dados Textuais para exemplos completos de análise de sentimento seguida de modelagem multinomial.\n\n5.5.3 Estrutura do Modelo\nA regressão multinomial estima coeficientes para cada categoria em relação a uma categoria de referência.\nExemplo com 3 categorias (positivo, neutro, negativo):\nSe “neutro” for a referência:\n\n\nModelo 1: Log-odds de positivo vs. neutro\n\nModelo 2: Log-odds de negativo vs. neutro\n\nEquações:\n\\[\n\\log\\left(\\frac{P(\\text{positivo})}{P(\\text{neutro})}\\right) = \\beta_{0,pos} + \\beta_{1,pos}X_1 + \\beta_{2,pos}X_2\n\\]\n\\[\n\\log\\left(\\frac{P(\\text{negativo})}{P(\\text{neutro})}\\right) = \\beta_{0,neg} + \\beta_{1,neg}X_1 + \\beta_{2,neg}X_2\n\\]\n\n5.5.4 Exemplo Prático: Modelando Tipo de Alta Hospitalar\nVamos usar os dados de internações para modelar o tipo de alta (simulado para demonstração, pois o dataset original tem apenas dados binários de morte).\n\nlibrary(nnet)        # Para regressão multinomial\n\n# Criar variável categórica de tipo de alta (simulada para demonstração)\nset.seed(123)\ndados_multi &lt;- dados_limpos %&gt;%\n  filter(!is.na(idade), !is.na(sexo)) %&gt;%\n  mutate(tipo_alta = sample(c(\"Alta melhorada\", \"Alta a pedido\", \"Transferência\"),\n                             size = n(),\n                             replace = TRUE,\n                             prob = c(0.70, 0.15, 0.15))) %&gt;%\n  mutate(tipo_alta = as.factor(tipo_alta))\n\n# Definir categoria de referência (\"Alta melhorada\" é a mais comum)\ndados_multi$tipo_alta &lt;- relevel(dados_multi$tipo_alta, ref = \"Alta melhorada\")\n\n# Visualizar distribuição\ntable(dados_multi$tipo_alta)\nprop.table(table(dados_multi$tipo_alta))\n\n\n5.5.5 Ajustando o Modelo Multinomial\n\n# Ajustar modelo multinomial\nmodelo_multi &lt;- multinom(tipo_alta ~ idade + sexo + val_tot,\n                         data = dados_multi)\n\n# Resumo do modelo\nsummary(modelo_multi)\n\n# Odds ratios e tabela formatada\ntbl_regression(modelo_multi, exponentiate = TRUE)\n\n\n5.5.6 Interpretação dos Coeficientes\nOs coeficientes representam o log-odds de cada categoria comparado à categoria de referência (“Alta melhorada”).\nExemplo de interpretação:\nSe o OR para idade no modelo “Transferência” vs. “Alta melhorada” é 1,02 (IC 95%: 1,01-1,03; p &lt; 0,001):\n\nPara cada ano adicional de idade, as chances de transferência (vs. alta melhorada) aumentam 2%\nÉ estatisticamente significativo (p &lt; 0,001)\n\n5.5.7 Verificando Multicolinearidade\n\n# Calcular VIF\nvif(modelo_multi)\n\n\n5.5.8 Predições de Probabilidade\n\n# Criar grid para predições\ngrid_pred &lt;- expand.grid(\n  idade = seq(20, 80, by = 10),\n  sexo = c(\"Feminino\", \"Masculino\"),\n  val_tot = median(dados_multi$val_tot, na.rm = TRUE)\n)\n\n# Predizer probabilidades\nprobs &lt;- predict(modelo_multi, newdata = grid_pred, type = \"probs\")\n\n# Combinar e visualizar\ngrid_pred &lt;- grid_pred %&gt;%\n  bind_cols(as.data.frame(probs)) %&gt;%\n  pivot_longer(cols = c(`Alta melhorada`, `Alta a pedido`, `Transferência`),\n               names_to = \"tipo_alta\",\n               values_to = \"probabilidade\")\n\n# Plotar\nggplot(grid_pred, aes(x = idade, y = probabilidade, color = tipo_alta)) +\n  geom_line(size = 1.2) +\n  facet_wrap(~ sexo) +\n  labs(title = \"Probabilidade Predita de Tipo de Alta\",\n       x = \"Idade\",\n       y = \"Probabilidade\",\n       color = \"Tipo de Alta\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n5.5.9 Comparação: Logística Binária vs. Multinomial\n\n\n\n\n\n\n\nAspecto\nRegressão Logística Binária\nRegressão Multinomial\n\n\n\nVariável resposta\n2 categorias (sim/não)\n3+ categorias não ordenadas\n\n\nModelos estimados\n1 modelo\nK-1 modelos (K = nº categorias)\n\n\nInterpretação\nOdds ratio direto\nOdds ratio vs. categoria referência\n\n\nCategoria referência\nAutomática\nDeve ser definida\n\n\nComplexidade\nSimples\nMais complexa\n\n\nExemplo\nMorte (sim/não)\nTipo de alta (3 categorias)\n\n\n\n5.5.10 Aplicação em Análise de Sentimento\nA regressão multinomial é amplamente usada em análise de sentimento de dados textuais. No Capítulo 7 - Análise de Dados Textuais, você encontrará exemplos completos de:\n\nAnálise de sentimento usando léxicos e LLMs\n\nClassificação de texto em categorias (positivo, neutro, negativo)\nModelagem multinomial completa com dados textuais reais\nInterpretação de resultados no contexto de pesquisa qualitativa\n\nFluxo típico:\nTexto bruto → Análise de sentimento → Categorias → Regressão multinomial\n\n5.5.11 Limitações e Considerações\n\n\nTamanho amostral: Requer amostras maiores que regressão logística binária\n\nRegra prática: Pelo menos 10 eventos por preditor por categoria\n\n\n\n\nCategoria de referência: Escolha a categoria mais comum ou mais relevante clinicamente\n\nInterpretação: Mais complexa que regressão logística binária - cada coeficiente é relativo à referência\n\nAlternativas: Se categorias são ordenadas (leve, moderado, grave), use regressão logística ordinal",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regressão Linear, Logística e Multinomial</span>"
    ]
  },
  {
    "objectID": "regressao.html#resumo-do-capítulo",
    "href": "regressao.html#resumo-do-capítulo",
    "title": "\n5  Regressão Linear, Logística e Multinomial\n",
    "section": "\n5.6 Resumo do Capítulo",
    "text": "5.6 Resumo do Capítulo\nNeste capítulo, aprendemos sobre três tipos de regressão:\n\n\nRegressão Linear:\n\nUsada para desfechos contínuos (custo, peso, pressão)\nInterpreta-se pelos coeficientes β\nAvalia-se a qualidade do ajuste pelo R²\nDiagnósticos importantes: VIF e teste de heterocedasticidade\n\n\n\nRegressão Logística:\n\nUsada para desfechos binários (morte, doença, evento)\nInterpreta-se pelos odds ratios (OR)\nOR &gt; 1 = fator de risco; OR &lt; 1 = fator protetor\nPrediz probabilidades de eventos\n\n\n\nRegressão Multinomial:\n\nUsada para desfechos categóricos com 3+ níveis não ordenados\nEstima K-1 modelos (K = número de categorias)\nInterpreta-se pelos OR relativos à categoria de referência\nAplicações: análise de sentimento, escolha de tratamento, classificação de diagnósticos\n\n\n\nEtapas de Modelagem:\n\nModelo com intercepto → Modelo univariado → Modelo multivariado\nVerificar sempre multicolinearidade (VIF)\nEscolher categoria de referência apropriada\n\n\n\nApresentação de Resultados:\n\nTabelas formatadas com tbl_regression()\n\nOdds ratios com intervalos de confiança\nValores p destacados\n\n\n\n\n5.6.1 Exercícios Práticos\n\nRegressão Linear: Construa um modelo de regressão linear com uma doença de sua escolha. Gere gráficos e interprete os coeficientes. Verifique os pressupostos (VIF, heterocedasticidade).\nRegressão Logística: Construa um modelo de regressão logística para predizer algum desfecho binário. Calcule e interprete os odds ratios. Compare modelos univariado e multivariado.\nRegressão Multinomial: Crie uma variável categórica com 3 categorias (ex: faixa de custo: baixo, médio, alto) e ajuste um modelo multinomial. Interprete os odds ratios e crie visualizações de probabilidades preditas.\nComparação de Modelos: Para um mesmo desfecho, compare modelos com diferentes conjuntos de preditores. Use critérios de ajuste (AIC, BIC) para selecionar o melhor modelo.\nIntegração com Capítulo 7: Após estudar o Capítulo 7, realize uma análise de sentimento completa e modele os resultados usando regressão multinomial com variáveis demográficas como preditores.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Regressão Linear, Logística e Multinomial</span>"
    ]
  },
  {
    "objectID": "psicometria.html",
    "href": "psicometria.html",
    "title": "\n6  Análise Psicométrica\n",
    "section": "",
    "text": "6.1 Introdução à Psicometria\nA psicometria é uma especialidade dentro das ciências comportamentais e sociais dedicada à mensuração de fenômenos psicológicos e sociais. Em pesquisas de saúde, a psicometria é fundamental para validar instrumentos que avaliam construtos como qualidade de vida, satisfação do paciente, literacia em saúde, sintomas psicológicos, entre outros.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "psicometria.html#introdução-à-psicometria",
    "href": "psicometria.html#introdução-à-psicometria",
    "title": "\n6  Análise Psicométrica\n",
    "section": "",
    "text": "6.1.1 Por que fazer um estudo antes de fazer um estudo?\nEsta é a pergunta central da análise psicométrica. Antes de utilizar um questionário ou escala em uma pesquisa substantiva, é essencial validar o instrumento para garantir que ele mede o que realmente pretende medir.\n\n6.1.2 O Custo de Medidas Inadequadas\nUsar instrumentos que não avaliam corretamente o que propõem leva a decisões erradas baseadas em dados não confiáveis. Enquanto uma medida imperfeita pode ser melhor que nenhuma medida, pesquisadores devem reconhecer quando os procedimentos são falhos e moderar suas conclusões adequadamente.\n\nPrincípio fundamental: Medidas adequadas são uma condição necessária para pesquisa válida.\n\n\n6.1.3 Aplicações em Saúde\n\n\nValidação transcultural de instrumentos (adaptação entre idiomas e culturas)\n\nDesenvolvimento de escalas (criação de novos instrumentos)\n\nAvaliação de propriedades psicométricas de questionários existentes\n\nGarantia de qualidade dos instrumentos antes da pesquisa principal\n\nExemplo: Adaptação do Questionário SF-8 para Swahili (Tanzânia) para populações com lesão cerebral traumática.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "psicometria.html#preparação-dos-dados-psicométricos",
    "href": "psicometria.html#preparação-dos-dados-psicométricos",
    "title": "\n6  Análise Psicométrica\n",
    "section": "\n6.2 Preparação dos Dados Psicométricos",
    "text": "6.2 Preparação dos Dados Psicométricos\nNeste capítulo, utilizaremos o dataset literacia_data.csv, que contém respostas de uma pesquisa sobre literacia digital, incluindo dados demográficos e 10 itens de escala (L1 a L10).\n\n6.2.1 Carregando Pacotes\n\nlibrary(tidyverse)    # Manipulação de dados\nlibrary(psych)        # Análise psicométrica (Alpha, Omega, EFA)\nlibrary(corrplot)     # Visualização de correlações\nlibrary(lavaan)       # Análise Fatorial Confirmatória (CFA)\nlibrary(semPlot)      # Visualização de modelos SEM\nlibrary(qgraph)       # Análise de redes\nlibrary(GGally)       # Gráficos de correlação\n\n# Remover notação científica\noptions(scipen = 999)\n\n\n6.2.2 Importando e Explorando os Dados\n\n# Importar dados de literacia digital\ndados &lt;- read_csv(\"data/literacia_data.csv\")\n\n# Visualizar primeiras linhas\nhead(dados)\n\n# Estrutura do dataframe\nstr(dados)\n\n# Resumo estatístico\nsummary(dados)\n\n\n6.2.3 Convertendo Variáveis Categóricas\n\n# Converter variáveis qualitativas em fatores\ndados &lt;- dados %&gt;%\n  mutate(across(c(sexo, etnia, estcivil, escolaridade, economia,\n                  renda, beneficio, comunicacao, celular,\n                  internet, acesso), as.factor))\n\n# Verificar estrutura após conversão\nstr(dados)\n\n\n6.2.4 Tratamento de Dados Faltantes\n\n# Verificar quantidade de dados faltantes por coluna\ncolSums(is.na(dados))\n\n# Proporção de dados faltantes (%)\ncolMeans(is.na(dados)) * 100\n\n# Estratégias de tratamento:\n# 1. Exclusão listwise (casos completos)\ndados_completo &lt;- dados[complete.cases(dados), ]\n\n# 2. Imputação por média (se apropriado)\n# dados$idade[is.na(dados$idade)] &lt;- mean(dados$idade, na.rm = TRUE)\n\nImportante: A escolha da estratégia de tratamento de dados faltantes depende do padrão dos missing data (MCAR, MAR, MNAR) e dos objetivos da pesquisa. Para análises psicométricas, geralmente preferimos casos completos.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "psicometria.html#matriz-de-correlação",
    "href": "psicometria.html#matriz-de-correlação",
    "title": "\n6  Análise Psicométrica\n",
    "section": "\n6.3 Matriz de Correlação",
    "text": "6.3 Matriz de Correlação\nAntes de realizar análises fatoriais, é útil examinar a estrutura de correlações entre os itens.\n\n6.3.1 Calculando e Visualizando Correlações\n\n# Selecionar itens da escala de literacia (L1 a L10) e idade\ndados_cor &lt;- dados %&gt;%\n  select(L1:L10, idade)\n\n# Calcular matriz de correlação\nmatriz_cor &lt;- cor(dados_cor, use = \"complete.obs\")\n\n# Visualização com corrplot - círculos\ncorrplot(matriz_cor,\n         method = \"circle\",\n         type = \"upper\",\n         tl.col = \"black\",\n         tl.srt = 45)\n\n# Visualização com números\ncorrplot(matriz_cor,\n         method = \"number\",\n         type = \"upper\",\n         tl.col = \"black\",\n         tl.srt = 45)\n\n# Visualização com cores e ordenação por clusters\ncorrplot(matriz_cor,\n         method = \"color\",\n         type = \"upper\",\n         order = \"hclust\",\n         addCoef.col = \"black\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         number.cex = 0.7)\n\n\n6.3.2 Interpretação da Matriz de Correlação\nOs valores de correlação variam de -1 a +1:\n\n\nr ≈ +1: Correlação positiva forte\n\nr ≈ 0: Correlação fraca ou ausente\n\nr ≈ -1: Correlação negativa forte\n\nPara análise fatorial, esperamos:\n\n\nCorrelações moderadas a fortes entre itens do mesmo fator\n\nCorrelações mais fracas entre itens de fatores diferentes\n\nAusência de correlações muito altas (r &gt; 0,90), que indicam redundância\n\n6.3.3 Heatmap de Correlação\n\n# Heatmap com cores\nheatmap(matriz_cor,\n        col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(20),\n        main = \"Heatmap de Correlações - Itens de Literacia\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "psicometria.html#análise-de-redes",
    "href": "psicometria.html#análise-de-redes",
    "title": "\n6  Análise Psicométrica\n",
    "section": "\n6.4 Análise de Redes",
    "text": "6.4 Análise de Redes\nA análise de redes oferece uma perspectiva alternativa sobre as relações entre itens, visualizando-os como nós conectados por arestas.\n\n6.4.1 Criando a Rede\n\n# Selecionar itens da escala\ndados_rede &lt;- dados %&gt;%\n  select(L1:L10) %&gt;%\n  na.omit()\n\n# Calcular matriz de correlação\nmatriz_rede &lt;- cor(dados_rede)\n\n# Calcular tamanho da amostra\nn_amostra &lt;- nrow(dados_rede)\n\n# Criar rede com qgraph\nrede &lt;- qgraph(matriz_rede,\n               graph = \"glasso\",        # Regularização LASSO\n               layout = \"spring\",       # Layout spring\n               vsize = 8,               # Tamanho dos nós\n               sampleSize = n_amostra,  # Tamanho da amostra\n               edge.labels = TRUE,      # Mostrar valores nas arestas\n               edge.label.cex = 0.8,    # Tamanho dos rótulos\n               title = \"Rede de Literacia Digital\")\n\n\n6.4.2 Interpretação da Análise de Redes\n\n\nNós: Representam as variáveis (itens)\n\nArestas: Representam relações entre variáveis\n\nEspessura das arestas: Indica a força da relação\n\nCor das arestas: Verde = positiva, Vermelho = negativa\n\nPosição dos nós: Algoritmo agrupa nós fortemente relacionados\n\nMedidas de centralidade (grau, intermediação, proximidade) podem identificar os itens mais importantes na rede.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "psicometria.html#análise-de-confiabilidade",
    "href": "psicometria.html#análise-de-confiabilidade",
    "title": "\n6  Análise Psicométrica\n",
    "section": "\n6.5 Análise de Confiabilidade",
    "text": "6.5 Análise de Confiabilidade\nA confiabilidade refere-se ao grau de consistência e precisão de um instrumento de medida. Representa a proporção da variância atribuível ao verdadeiro escore da variável latente.\n\n6.5.1 Alfa de Cronbach\nO Alfa de Cronbach (α) é a medida mais amplamente utilizada de consistência interna.\n\n6.5.1.1 Teoria\n\nBaseado nas correlações entre itens\nUsa a matriz de covariância dos itens\nValores aceitáveis: α &gt; 0,70\n\nValores ideais: 0,70 &lt; α &lt; 0,95\n\n\nFórmula:\n\\[\n\\alpha = \\frac{k}{k-1} \\left(1 - \\frac{\\sum \\sigma^2_i}{\\sigma^2_T}\\right)\n\\]\nOnde: - k = número de itens - σ²ᵢ = variância de cada item - σ²_T = variância total da escala\n\n6.5.1.2 Calculando o Alfa de Cronbach\n\n# Selecionar itens da escala\nitens_escala &lt;- dados %&gt;%\n  select(L1:L10) %&gt;%\n  na.omit()\n\n# Calcular Alfa de Cronbach\nalfa &lt;- psych::alpha(itens_escala,\n                     n.iter = 1000,      # Iterações para bootstrap\n                     check.keys = TRUE)  # Verifica itens reversos\n\n# Exibir resultados\nprint(alfa)\n\n\n6.5.1.3 Interpretação do Output\nReliability analysis\n\nraw_alpha std.alpha G6(smc) average_r S/N\n     0.89      0.89    0.91      0.42  8.1\n\nlower alpha upper     95% confidence boundaries\n0.87  0.89  0.91\nInterpretação:\n\n\nraw_alpha = 0,89: Alfa de Cronbach bruto (excelente consistência interna)\n\nstd.alpha = 0,89: Alfa padronizado\n\naverage_r = 0,42: Correlação média entre itens\n\nIC 95% [0,87; 0,91]: Intervalo de confiança do alfa\n\nCritérios de interpretação:\n\n\nAlfa de Cronbach\nConsistência Interna\n\n\n\nα &lt; 0,60\nInaceitável\n\n\n0,60 ≤ α &lt; 0,70\nQuestionável\n\n\n0,70 ≤ α &lt; 0,80\nAceitável\n\n\n0,80 ≤ α &lt; 0,90\nBoa\n\n\nα ≥ 0,90\nExcelente (pode indicar redundância)\n\n\n\n6.5.1.4 Limitação Importante\n\n“Alpha não valida um teste”\n\nAlta consistência interna não garante que o instrumento mede o que afirma medir. Confiabilidade é necessária, mas não suficiente para validade.\n\n6.5.2 Ômega de McDonald\nO Ômega de McDonald (ω) é uma medida alternativa de confiabilidade composta, considerada mais geral que o Alfa de Cronbach.\n\n6.5.2.1 Teoria\n\nCalculado usando cargas fatoriais e unicidades da análise fatorial\nBaseado em estrutura CFA\nMais apropriado para escalas multidimensionais\nValores aceitáveis: ω &gt; 0,70\n\n\nFórmula:\n\\[\n\\omega = \\frac{(\\sum \\lambda_i)^2}{(\\sum \\lambda_i)^2 + \\sum \\theta_i}\n\\]\nOnde: - λᵢ = cargas fatoriais - θᵢ = variâncias de erro\n\n6.5.2.2 Calculando o Ômega de McDonald\n\n# Calcular Ômega de McDonald\nomega_result &lt;- omega(itens_escala)\n\n# Exibir resultados\nprint(omega_result)\n\n\n6.5.3 Comparação: Alfa vs. Ômega\n\n\n\n\n\n\n\nCaracterística\nAlfa de Cronbach\nÔmega de McDonald\n\n\n\nBase de cálculo\nMatriz de covariância\nCargas fatoriais (CFA)\n\n\nEstrutura fatorial\nNão requer\nRequer modelo CFA\n\n\nDimensionalidade\nAssume unidimensionalidade\nAdequado para multidimensional\n\n\nGeneralidade\nMais restrito\nMais geral\n\n\n\nRecomendação: Reporte ambos os índices quando possível, especialmente para escalas multidimensionais.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "psicometria.html#análise-fatorial-exploratória-efa",
    "href": "psicometria.html#análise-fatorial-exploratória-efa",
    "title": "\n6  Análise Psicométrica\n",
    "section": "\n6.6 Análise Fatorial Exploratória (EFA)",
    "text": "6.6 Análise Fatorial Exploratória (EFA)\nA Análise Fatorial Exploratória (AFE) é usada para desenvolvimento de teoria, explorando a estrutura latente dos dados sem hipóteses prévias sobre o número de fatores.\n\n6.6.1 Teoria da EFA\n\n6.6.1.1 Características Principais\n\n\nNatureza exploratória: Número de fatores determinado pelos dados\n\nCargas não fixadas: Padrão de cargas emerge dos dados\n\nRedução de dimensionalidade: Reduz muitos itens a poucos fatores latentes\n\nRotação: Fatores rotacionados para interpretação mais clara\n\n6.6.1.2 Equação Básica\n\\[\nX = \\Lambda F + \\epsilon\n\\]\nOnde: - X = variáveis observadas (itens) - Λ = matriz de cargas fatoriais - F = fatores latentes - ε = erros de medida\n\n6.6.2 Pressupostos da EFA\n\n6.6.2.1 Teste KMO (Kaiser-Meyer-Olkin)\nO KMO avalia a adequação da amostra para análise fatorial.\n\n# Calcular KMO\nkmo_resultado &lt;- KMO(itens_escala)\n\n# Imprimir KMO geral\ncat(\"KMO geral:\", kmo_resultado$MSA, \"\\n\")\n\n# Interpretar resultado\nif (kmo_resultado$MSA &gt;= 0.9) {\n  cat(\"A adequação da amostra é excelente.\\n\")\n} else if (kmo_resultado$MSA &gt;= 0.8) {\n  cat(\"A adequação da amostra é boa.\\n\")\n} else if (kmo_resultado$MSA &gt;= 0.7) {\n  cat(\"A adequação da amostra é razoável.\\n\")\n} else if (kmo_resultado$MSA &gt;= 0.6) {\n  cat(\"A adequação da amostra é medíocre.\\n\")\n} else if (kmo_resultado$MSA &gt;= 0.5) {\n  cat(\"A adequação da amostra é inadequada.\\n\")\n} else {\n  cat(\"A adequação da amostra é inaceitável.\\n\")\n}\n\nCritérios de interpretação:\n\n\nKMO\nAdequação da Amostra\n\n\n\nKMO ≥ 0,90\nExcelente\n\n\n0,80 ≤ KMO &lt; 0,90\nBoa\n\n\n0,70 ≤ KMO &lt; 0,80\nRazoável\n\n\n0,60 ≤ KMO &lt; 0,70\nMedíocre\n\n\n0,50 ≤ KMO &lt; 0,60\nInadequada\n\n\nKMO &lt; 0,50\nInaceitável\n\n\n\n6.6.2.2 Teste de Esfericidade de Bartlett\nTesta se a matriz de correlação é significativamente diferente de uma matriz identidade.\n\n\nH₀: Matriz de correlação é uma matriz identidade (variáveis não correlacionadas)\n\nH₁: Existem correlações significativas entre variáveis\n\nDesejado: p &lt; 0,05 (rejeitar H₀)\n\n6.6.3 Determinando o Número de Fatores\n\n6.6.3.1 Análise Paralela\nA análise paralela é o método mais confiável para determinar o número de fatores.\n\n# Realizar análise paralela\nfa.parallel(itens_escala,\n            fa = \"fa\",          # Análise fatorial (não PCA)\n            n.iter = 100,       # Número de iterações\n            main = \"Análise Paralela - Scree Plot\")\n\nInterpretação:\n\n\nLinha azul: Autovalores observados nos dados reais\n\nLinha vermelha: Autovalores médios de dados aleatórios (simulados)\n\nLinha verde: Autovalores do 95º percentil dos dados simulados\n\nDecisão: Reter fatores onde a linha azul está acima da linha vermelha\n\n6.6.3.2 Regra de Kaiser (Autovalores &gt; 1)\nMétodo tradicional, mas menos confiável que análise paralela.\n\n# Scree plot simples\nscree(itens_escala, main = \"Scree Plot\")\n\n\n6.6.4 Realizando a EFA\n\n# Determinar número de fatores (baseado em análise paralela)\nn_fatores &lt;- 4  # Ajustar baseado em análise paralela\n\n# Realizar EFA\nefa_resultado &lt;- fa(itens_escala,\n                    nfactors = n_fatores,\n                    rotate = \"varimax\",  # Rotação ortogonal\n                    fm = \"ml\")           # Máxima verossimilhança\n\n# Imprimir resultados\nprint(efa_resultado)\n\n# Visualizar diagrama de fatores\nfa.diagram(efa_resultado)\n\n\n6.6.5 Interpretação das Cargas Fatoriais\nAs cargas fatoriais (factor loadings) representam a correlação entre item e fator.\nCritérios de interpretação:\n\n\nCarga Fatorial\nInterpretação\n\n\n\n|λ| ≥ 0,70\nExcelente\n\n\n|λ| ≥ 0,63\nMuito boa\n\n\n|λ| ≥ 0,55\nBoa\n\n\n|λ| ≥ 0,45\nRazoável\n\n\n|λ| ≥ 0,32\nFraca\n\n\n|λ| &lt; 0,32\nInaceitável\n\n\n\nVariância explicada: λ² = R²\nExemplo: Carga de 0,70 explica 0,49 (49%) da variância do item.\n\n6.6.6 Rotação de Fatores\n\n\nVarimax (ortogonal): Fatores não correlacionados - mais simples de interpretar\n\nOblimin (oblíqua): Permite correlação entre fatores - mais realista em muitos contextos\n\n6.6.7 EFA Unidimensional (Exemplo com Literacia)\nSe a teoria sugere que o instrumento é unidimensional:\n\n# EFA com 1 fator (modelo teórico unidimensional)\nefa_uni &lt;- fa(itens_escala,\n              nfactors = 1,\n              rotate = \"none\",   # Sem rotação (1 fator)\n              fm = \"ml\")\n\n# Resultados\nprint(efa_uni)\n\n# Diagrama\nfa.diagram(efa_uni)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "psicometria.html#análise-fatorial-confirmatória-cfa",
    "href": "psicometria.html#análise-fatorial-confirmatória-cfa",
    "title": "\n6  Análise Psicométrica\n",
    "section": "\n6.7 Análise Fatorial Confirmatória (CFA)",
    "text": "6.7 Análise Fatorial Confirmatória (CFA)\nA Análise Fatorial Confirmatória (AFC) é usada para testar teoria, verificando se uma estrutura fatorial pré-especificada se ajusta aos dados.\n\n6.7.1 Teoria da CFA\n\n6.7.1.1 Características Principais\n\n\nNatureza confirmatória: Número de fatores especificado a priori\n\n\nCargas fixadas: Padrão de cargas especificado antes da análise\n\nTesta teoria: Verifica se estrutura teórica se ajusta aos dados empíricos\n\nFatores correlacionados: Geralmente permite correlações entre fatores\n\n6.7.1.2 Diferenças EFA vs. CFA\n\n\n\n\n\n\n\nAspecto\nEFA\nCFA\n\n\n\nObjetivo\nDesenvolvimento de teoria\nTeste de teoria\n\n\nFatores\nDeterminados pelos dados\nEspecificados a priori\n\n\n\nCargas\nNão fixadas\nPadrão fixo\n\n\nRotação\nSim (para interpretação)\nNão aplicável\n\n\nCorrelação entre fatores\nGeralmente ortogonais\nGeralmente correlacionados\n\n\nErros correlacionados\nNão permitidos\nPodem ser permitidos\n\n\nTestes estatísticos\nLimitados\nExtensivos (índices de ajuste)\n\n\n\n6.7.2 Especificação do Modelo no lavaan\nO pacote lavaan usa sintaxe intuitiva para especificar modelos CFA.\n\n6.7.2.1 Sintaxe básica\n# =~ define fatores latentes\n# ~~ define correlações/covariâncias\n\n6.7.2.2 Exemplo: Modelo Unidimensional\n\n# Carregar lavaan\nlibrary(lavaan)\n\n# Especificar modelo unidimensional\nmodelo_cfa &lt;- '\n  # Definição do fator latente\n  Literacia =~ L1 + L2 + L3 + L4 + L5 + L6 + L7 + L8 + L9 + L10\n'\n\n# Estimar modelo\najuste_cfa &lt;- cfa(modelo_cfa,\n                  data = itens_escala,\n                  estimator = \"ML\")  # Máxima verossimilhança\n\n# Sumarizar resultados\nsummary(ajuste_cfa,\n        fit.measures = TRUE,    # Mostrar índices de ajuste\n        standardized = TRUE)    # Mostrar coeficientes padronizados\n\n\n6.7.2.3 Exemplo: Modelo Bidimensional\n\n# Modelo com 2 fatores correlacionados\nmodelo_cfa_2f &lt;- '\n  # Definição dos fatores\n  Fator1 =~ L1 + L2 + L3 + L4 + L5\n  Fator2 =~ L6 + L7 + L8 + L9 + L10\n'\n\n# Estimar modelo\najuste_cfa_2f &lt;- cfa(modelo_cfa_2f, data = itens_escala)\n\n# Resultados\nsummary(ajuste_cfa_2f, fit.measures = TRUE, standardized = TRUE)\n\n\n6.7.3 Índices de Ajuste do Modelo\nOs índices de ajuste (fit indices) avaliam o quão bem o modelo teórico se ajusta aos dados observados.\n\n6.7.3.1 1. Qui-Quadrado (χ²)\nTeste formal de ajuste exato:\n\n\nH₀: O modelo se ajusta perfeitamente aos dados\n\nBom ajuste: p &gt; 0,05 (não rejeitar H₀)\n\nProblema: Sensível ao tamanho da amostra (sempre significativo com n grande)\n\nQui-quadrado normalizado:\n\n\nχ²/df &lt; 2: Bom ajuste\n\nχ²/df &lt; 3: Ajuste aceitável\n\n6.7.3.2 2. CFI (Comparative Fit Index)\n\nCompara o modelo proposto com modelo nulo (independência)\n\nBom ajuste: CFI ≥ 0,95\n\nAjuste aceitável: CFI ≥ 0,90\n\n6.7.3.3 3. TLI (Tucker-Lewis Index)\n\nSimilar ao CFI, mas penaliza complexidade do modelo\n\nBom ajuste: TLI ≥ 0,95\n\nAjuste aceitável: TLI ≥ 0,90\n\n6.7.3.4 4. RMSEA (Root Mean Square Error of Approximation)\n\nMede erro de aproximação na população\n\nBom ajuste: RMSEA ≤ 0,05\n\nAjuste aceitável: RMSEA ≤ 0,08\n\nAjuste mediocre: 0,08 &lt; RMSEA ≤ 0,10\n\nAjuste ruim: RMSEA &gt; 0,10\n\nImportante: O IC 90% do RMSEA também deve ser considerado.\n\n6.7.3.5 5. SRMR (Standardized Root Mean Square Residual)\n\nRaiz quadrada média do resíduo padronizado\n\nBom ajuste: SRMR ≤ 0,05\n\nAjuste aceitável: SRMR ≤ 0,08\n\n6.7.4 Tabela Resumo de Critérios de Ajuste\n\n\nÍndice\nBom Ajuste\nAjuste Aceitável\n\n\n\nχ²/df\n≤ 2\n≤ 3\n\n\nCFI\n≥ 0,95\n≥ 0,90\n\n\nTLI\n≥ 0,95\n≥ 0,90\n\n\nRMSEA\n≤ 0,05\n≤ 0,08\n\n\nSRMR\n≤ 0,05\n≤ 0,08\n\n\n\n6.7.5 Interpretação dos Resultados da CFA\n\n# Exibir índices de ajuste\nfitMeasures(ajuste_cfa, c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n# Exibir cargas fatoriais padronizadas\nstandardizedSolution(ajuste_cfa)\n\n# Exibir R² dos itens\ninspect(ajuste_cfa, \"r2\")\n\n\n6.7.6 Modificação de Modelos\nSe o modelo não ajustar bem, considere modificações baseadas em:\n\n\nTeoria: Modificações devem ser teoricamente justificáveis\n\nÍndices de modificação: Sugestões estatísticas do lavaan\n\n\n# Índices de modificação\nmodindices(ajuste_cfa, sort = TRUE, maximum.number = 10)\n\nCuidado: Não realize modificações baseadas apenas em estatísticas - sempre justifique teoricamente.\n\n6.7.7 Visualização do Modelo com semPaths\n\nlibrary(semPlot)\n\n# Plotar modelo CFA\nsemPaths(ajuste_cfa,\n         what = \"std\",             # Coeficientes padronizados\n         layout = \"tree2\",         # Layout hierárquico\n         edge.label.cex = 0.8,     # Tamanho das etiquetas\n         sizeMan = 8,              # Tamanho dos nós observados\n         sizeLat = 10,             # Tamanho dos nós latentes\n         esize = 1,                # Tamanho das setas\n         residuals = TRUE,         # Mostrar resíduos\n         intercepts = FALSE,       # Não mostrar interceptos\n         title = TRUE,\n         nCharNodes = 0)           # Sem abreviação de nomes\n\nElementos do diagrama:\n\n\nRetângulos: Variáveis observadas (itens)\n\nElipses/Círculos: Variáveis latentes (fatores)\n\nSetas unidirecionais (→): Relações de regressão\n\nSetas bidirecionais (↔︎): Correlações/Covariâncias\n\nPequenos círculos → retângulos: Erros de medida",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "psicometria.html#validação-de-constructo",
    "href": "psicometria.html#validação-de-constructo",
    "title": "\n6  Análise Psicométrica\n",
    "section": "\n6.8 Validação de Constructo",
    "text": "6.8 Validação de Constructo\nA validação baseada na estrutura interna avalia se as relações entre itens e componentes do teste se conformam ao constructo teórico.\n\n6.8.1 Métodos de Validação\n\n\nAnálise fatorial (EFA e CFA)\nCorrelações item-total\nCorrelações inter-itens\n\nCoeficientes de confiabilidade (α, ω)\n\n6.8.2 Critérios de Avaliação\n\nAgrupamento de itens corresponde à teoria\nÍndices de ajuste adequados (CFA)\nConfiabilidade aceitável\nCargas fatoriais apropriadas",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "psicometria.html#exercícios-práticos",
    "href": "psicometria.html#exercícios-práticos",
    "title": "\n6  Análise Psicométrica\n",
    "section": "\n6.9 Exercícios Práticos",
    "text": "6.9 Exercícios Práticos\n\n6.9.1 Exercício 1: Confiabilidade\nUse o dataset de literacia para:\n\nCalcular o Alfa de Cronbach para os 10 itens\nCalcular o Ômega de McDonald\nIdentificar se algum item reduz a confiabilidade (item-total correlations)\nComparar os dois índices e interpretar os resultados\n\n6.9.2 Exercício 2: Análise Fatorial Exploratória\n\nCalcule o KMO e interprete a adequação da amostra\nRealize análise paralela para determinar o número de fatores\nRealize EFA com o número apropriado de fatores\nInterprete as cargas fatoriais e nomeie os fatores\nCompare a solução unidimensional vs. multidimensional\n\n6.9.3 Exercício 3: Análise Fatorial Confirmatória\n\nEspecifique um modelo CFA unidimensional para os 10 itens\nEstime o modelo e avalie os índices de ajuste\nExamine as cargas fatoriais padronizadas\nSe o ajuste for inadequado, explore índices de modificação\nVisualize o modelo final com semPaths\n\n6.9.4 Exercício 4: Comparação de Modelos\nCompare três modelos CFA:\n\n\nModelo 1: Unidimensional (1 fator geral)\n\nModelo 2: Bidimensional (2 fatores correlacionados)\n\nModelo 3: Hierárquico (2 fatores de primeira ordem + 1 fator de segunda ordem)\n\n\nEspecifique e estime os três modelos\nCompare os índices de ajuste\nUse o teste qui-quadrado de diferença para modelos aninhados\nSelecione o melhor modelo e justifique\n\n6.9.5 Exercício 5: Análise de Redes\n\nCrie uma rede psicométrica para os 10 itens\nIdentifique os itens mais centrais na rede\nExamine se há comunidades (clusters) de itens\nCompare a estrutura da rede com os resultados da análise fatorial\n\n\nReferências:\n\nCronbach, L. J. (1951). Coefficient alpha and the internal structure of tests. Psychometrika, 16(3), 297-334.\nDeVellis, R. F. (2003). Scale Development: Theory and Applications. SAGE Publications.\nFornell, C., & Larcker, D. F. (1981). Evaluating structural equation models with unobservable variables and measurement error. Journal of Marketing Research, 18(1), 39-50.\nHu, L. T., & Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis. Structural Equation Modeling, 6(1), 1-55.\nMcDonald, R. P. (1999). Test Theory: A Unified Treatment. Lawrence Erlbaum Associates.\nRosseel, Y. (2012). lavaan: An R package for structural equation modeling. Journal of Statistical Software, 48(2), 1-36.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análise Psicométrica</span>"
    ]
  },
  {
    "objectID": "analise-texto.html",
    "href": "analise-texto.html",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "",
    "text": "7.1 Introdução à Mineração de Texto\nA mineração de texto (text mining) e a análise de sentimento são técnicas cada vez mais importantes em pesquisas de saúde, permitindo extrair informações valiosas de dados não estruturados como narrativas de pacientes, respostas abertas em questionários, postagens em redes sociais, registros médicos, e transcrições de entrevistas.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#introdução-à-mineração-de-texto",
    "href": "analise-texto.html#introdução-à-mineração-de-texto",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "",
    "text": "7.1.1 Aplicações em Saúde\n\n\nAnálise de feedback de pacientes: Avaliar satisfação através de comentários abertos\n\nPesquisa qualitativa: Processar transcrições de entrevistas e grupos focais\n\nMonitoramento de redes sociais: Acompanhar discussões públicas sobre saúde\n\nAnálise de registros médicos: Extrair informações de notas clínicas\n\nPesquisas de percepção: Avaliar atitudes em relação a medicamentos, tratamentos, ou políticas de saúde\n\n7.1.2 Estrutura do Capítulo\nNeste capítulo, abordaremos:\n\n\nPreparação e limpeza de dados textuais\n\nTokenização e análise de frequência\n\nVisualização com word clouds\n\nAnálise de sentimento usando dois métodos:\n\nAbordagem baseada em léxico (dicionário)\nAbordagem baseada em LLMs (Large Language Models)\n\n\n\nRegressão multinomial para modelar sentimento",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#preparação-do-ambiente",
    "href": "analise-texto.html#preparação-do-ambiente",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.2 Preparação do Ambiente",
    "text": "7.2 Preparação do Ambiente\n\n7.2.1 Carregando Pacotes\n\nlibrary(tidyverse)      # Manipulação de dados\nlibrary(readxl)         # Leitura de Excel\nlibrary(janitor)        # Limpeza de nomes\nlibrary(tidytext)       # Mineração de texto (tokenização)\nlibrary(wordcloud)      # Nuvens de palavras\nlibrary(quanteda)       # Análise quantitativa de texto\nlibrary(lexiconPT)      # Léxico de sentimentos em português\nlibrary(tm)             # Text mining básico\nlibrary(mall)           # Interface para LLMs locais\nlibrary(nnet)           # Regressão multinomial\nlibrary(gtsummary)      # Tabelas de regressão\n\n# Remover notação científica\noptions(scipen = 999)\n\n\n7.2.2 Sobre os Datasets\nUtilizaremos dois conjuntos de dados neste capítulo:\n\n\nentrevistas.xlsx: Respostas abertas sobre impacto de tecnologias digitais na educação\n\nrespostas_questionario.xlsx: Dados de percepção de marca com variáveis demográficas",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#tokenização-e-análise-de-frequência",
    "href": "analise-texto.html#tokenização-e-análise-de-frequência",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.3 Tokenização e Análise de Frequência",
    "text": "7.3 Tokenização e Análise de Frequência\nA tokenização é o processo de dividir texto em unidades menores chamadas tokens (palavras, frases, ou n-gramas).\n\n7.3.1 Importando Dados de Entrevistas\n\n# Importar dados de entrevistas\ndados_entrevistas &lt;- read_excel(\"data/entrevistas.xlsx\")\n\n# Visualizar estrutura\nglimpse(dados_entrevistas)\n\n\n7.3.2 Tokenização por Sentenças\nPrimeiro, vamos segmentar o texto em sentenças para facilitar análises posteriores:\n\n# Tokenizar em sentenças\nentrevistas_frases &lt;- dados_entrevistas %&gt;%\n  # Segmentar em frases (sentences)\n  unnest_tokens(output = frase,\n                input = `Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`,\n                token = \"sentences\") %&gt;%\n  # Agrupar por ID da entrevista\n  group_by(ID) %&gt;%\n  # Criar identificador de frase dentro de cada entrevista\n  mutate(id_frase_entrevista = row_number()) %&gt;%\n  ungroup() %&gt;%\n  # Selecionar colunas relevantes\n  select(ID, id_frase_entrevista, frase)\n\n# Visualizar resultado\nhead(entrevistas_frases, 10)\n\nExplicação:\n\n\nunnest_tokens(): Função do tidytext que separa texto em tokens\n\ntoken = \"sentences\": Especifica tokenização por sentenças\n\nrow_number(): Cria ID sequencial para cada frase dentro de cada entrevista\n\n7.3.3 Tokenização por Palavras\nPara análise de frequência, tokenizamos em palavras:\n\n# Tokenizar em palavras\npalavras_tokens &lt;- dados_entrevistas %&gt;%\n  unnest_tokens(output = word,\n                input = `Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`,\n                token = \"words\") %&gt;%\n  select(ID, word)\n\n# Visualizar\nhead(palavras_tokens, 20)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#remoção-de-stopwords",
    "href": "analise-texto.html#remoção-de-stopwords",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.4 Remoção de Stopwords",
    "text": "7.4 Remoção de Stopwords\nStopwords são palavras muito comuns que geralmente não carregam significado importante para análise (ex: “a”, “o”, “que”, “de”, “em”).\n\n7.4.1 Criando Lista de Stopwords em Português\n\n# Stopwords em português (lista customizada)\nstop_words_pt &lt;- tibble(\n  word = c(\"a\", \"o\", \"que\", \"e\", \"do\", \"da\", \"em\", \"um\", \"para\", \"é\",\n           \"com\", \"não\", \"uma\", \"os\", \"no\", \"se\", \"na\", \"por\", \"mais\", \"as\",\n           \"dos\", \"como\", \"mas\", \"foi\", \"ao\", \"ele\", \"das\", \"tem\", \"à\", \"seu\",\n           \"sua\", \"ou\", \"ser\", \"quando\", \"muito\", \"há\", \"nos\", \"já\", \"está\",\n           \"eu\", \"também\", \"só\", \"pelo\", \"pela\", \"até\", \"isso\", \"ela\", \"entre\",\n           \"era\", \"depois\", \"sem\", \"mesmo\", \"aos\", \"ter\", \"seus\", \"quem\", \"nas\",\n           \"me\", \"esse\", \"eles\", \"estão\", \"você\", \"tinha\", \"foram\", \"essa\",\n           \"num\", \"nem\", \"suas\", \"meu\", \"às\", \"minha\", \"têm\", \"numa\", \"pelos\",\n           \"elas\", \"havia\", \"seja\", \"qual\", \"será\", \"nós\", \"tenho\", \"lhe\",\n           \"deles\", \"essas\", \"esses\", \"pelas\", \"este\", \"fosse\", \"dele\", \"tu\",\n           \"te\", \"vocês\", \"vos\", \"lhes\", \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\",\n           \"tuas\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"dela\", \"delas\",\n           \"esta\", \"estes\", \"estas\", \"aquele\", \"aquela\", \"aqueles\", \"aquelas\",\n           \"isto\", \"aquilo\", \"sabe\", \"acho\", \"pode\", \"podem\", \"então\", \"vai\",\n           \"são\", \"ainda\", \"bem\", \"só\", \"cada\", \"cada\", \"onde\", \"muitos\",\n           \"alguma\", \"alguns\", \"tudo\", \"toda\", \"todos\", \"todas\")\n)\n\n# Alternativamente, usar pacote stopwords\nlibrary(stopwords)\nstopwords_pt_pacote &lt;- tibble(word = stopwords(\"pt\"))\n\n\n7.4.2 Calculando Frequência de Palavras\n\n# Calcular frequência, removendo stopwords\npalavras_frequentes &lt;- dados_entrevistas %&gt;%\n  unnest_tokens(word, `Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`) %&gt;%\n  anti_join(stop_words_pt, by = \"word\") %&gt;%  # Remove stopwords\n  count(word, sort = TRUE) %&gt;%                # Conta frequência\n  filter(n &gt; 1)                               # Remove palavras únicas\n\n# Visualizar top 20 palavras\nprint(palavras_frequentes, n = 20)\n\n\n7.4.3 Visualizando Frequência com Gráfico de Barras\n\n# Top 20 palavras mais frequentes\npalavras_frequentes %&gt;%\n  slice_max(n, n = 20) %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(x = n, y = word)) +\n  geom_col(fill = \"steelblue\") +\n  labs(title = \"20 Palavras Mais Frequentes\",\n       x = \"Frequência\",\n       y = \"Palavra\") +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#visualização-com-word-clouds",
    "href": "analise-texto.html#visualização-com-word-clouds",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.5 Visualização com Word Clouds",
    "text": "7.5 Visualização com Word Clouds\nWord clouds (nuvens de palavras) são representações visuais onde o tamanho da palavra é proporcional à sua frequência.\n\n7.5.1 Criando uma Função para Word Cloud\n\n# Função para criar word cloud\ncriar_wordcloud &lt;- function(coluna) {\n  # Processar texto\n  palavras &lt;- coluna %&gt;%\n    str_to_lower() %&gt;%                         # Minúsculas\n    str_replace_all(\"[[:punct:]]\", \"\") %&gt;%     # Remover pontuação\n    str_replace_all(\"[[:digit:]]\", \"\") %&gt;%     # Remover números\n    str_split(\"\\\\s+\") %&gt;%                      # Dividir por espaços\n    unlist()\n\n  # Remover stopwords e palavras curtas\n  stopwords_pt &lt;- stopwords(\"portuguese\")\n  palavras &lt;- palavras[!palavras %in% stopwords_pt & nchar(palavras) &gt; 2]\n\n  # Contar frequência\n  freq_palavras &lt;- table(palavras) %&gt;%\n    as.data.frame() %&gt;%\n    arrange(desc(Freq)) %&gt;%\n    filter(Freq &gt; 1)  # Apenas palavras que aparecem mais de 1 vez\n\n  # Plotar word cloud\n  wordcloud(words = freq_palavras$palavras,\n            freq = freq_palavras$Freq,\n            max.words = 100,              # Máximo de palavras\n            scale = c(3, 0.5),            # Escala de tamanho\n            random.order = FALSE,         # Palavras mais frequentes no centro\n            rot.per = 0.35,               # 35% de palavras rotacionadas\n            colors = brewer.pal(8, \"Dark2\"))  # Paleta de cores\n}\n\n\n7.5.2 Aplicando a Função\n\n# Word cloud para primeira pergunta\ncriar_wordcloud(dados_entrevistas$`Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`)\n\n# Word cloud para segunda pergunta\ncriar_wordcloud(dados_entrevistas$`Quais são os principais desafios para a implementação dessas tecnologias nas instituições de ensino?`)\n\nInterpretação:\n\nPalavras maiores aparecem com maior frequência\nPalavras centrais geralmente são as mais frequentes\n\nCores ajudam a diferenciar grupos de palavras\nÚtil para identificar temas principais rapidamente",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#análise-de-sentimento-abordagem-baseada-em-léxico",
    "href": "analise-texto.html#análise-de-sentimento-abordagem-baseada-em-léxico",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.6 Análise de Sentimento: Abordagem Baseada em Léxico",
    "text": "7.6 Análise de Sentimento: Abordagem Baseada em Léxico\nA análise de sentimento baseada em léxico usa dicionários pré-definidos que atribuem polaridade (positiva, negativa, neutra) a palavras.\n\n7.6.1 Sobre o Léxico SentiLex-PT\nO SentiLex-PT é um léxico de sentimentos para português que atribui:\n\n\nPolaridade: -1 (negativo), 0 (neutro), +1 (positivo)\n\nScores contínuos: Valores intermediários indicam intensidade\n\n7.6.2 Importando Dados de Percepção de Marca\n\n# Importar dados de questionário sobre percepção de marca\ndados_marca &lt;- read_excel(\"data/respostas_questionario.xlsx\")\n\n# Limpar nomes e preparar dados\ndados_marca &lt;- dados_marca %&gt;%\n  clean_names() %&gt;%\n  mutate(across(c(genero, estado, nivel_de_escolaridade,\n                  avaliacao_da_marca_1_5), as.factor))\n\n# Visualizar estrutura\nglimpse(dados_marca)\n\n\n7.6.3 Carregando o Léxico de Sentimentos\n\n# Carregar léxico SentiLex-PT\ndata(\"sentiLex_lem_PT02\")\n\n# Visualizar estrutura do léxico\nhead(sentiLex_lem_PT02)\n\n\n7.6.4 Pré-processamento do Texto\n\n# Pré-processar texto e tokenizar\ndados_tokens &lt;- dados_marca %&gt;%\n  mutate(percepcao_da_marca = percepcao_da_marca %&gt;%\n           tolower() %&gt;%              # Converter para minúsculas\n           removePunctuation()) %&gt;%   # Remover pontuação\n  unnest_tokens(term, percepcao_da_marca)  # Tokenizar\n\n# Remover stopwords\nstopwords_pt &lt;- stopwords(\"pt\")\ndados_tokens &lt;- dados_tokens %&gt;%\n  filter(!term %in% stopwords_pt)\n\n# Visualizar tokens\nhead(dados_tokens, 20)\n\n\n7.6.5 Atribuindo Polaridade às Palavras\n\n# Juntar tokens com o léxico de sentimentos\ndados_sent &lt;- dados_tokens %&gt;%\n  left_join(sentiLex_lem_PT02, by = \"term\")\n\n# Visualizar resultado (mostra polaridade para cada palavra)\ndados_sent %&gt;%\n  select(id, term, polarity) %&gt;%\n  filter(!is.na(polarity)) %&gt;%  # Apenas palavras com polaridade\n  head(20)\n\n\n7.6.6 Calculando Sentimento Total por Resposta\n\n# Calcular sentimento total por ID (somar polaridades)\nsentimentos_lexicon &lt;- dados_sent %&gt;%\n  group_by(id) %&gt;%\n  summarise(sentimento_total = sum(polarity, na.rm = TRUE),\n            n_palavras_sentimento = sum(!is.na(polarity)))\n\n# Visualizar distribuição\nsentimentos_lexicon %&gt;%\n  ggplot(aes(x = sentimento_total)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Distribuição do Sentimento (Léxico)\",\n       x = \"Escore de Sentimento\",\n       y = \"Frequência\") +\n  theme_minimal()\n\nInterpretação:\n\n\nSentimento total &gt; 0: Sentimento predominantemente positivo\n\nSentimento total &lt; 0: Sentimento predominantemente negativo\n\nSentimento total ≈ 0: Sentimento neutro ou misto\n\n7.6.7 Classificando em Categorias\n\n# Classificar em categorias\nsentimentos_lexicon &lt;- sentimentos_lexicon %&gt;%\n  mutate(categoria_sentimento = case_when(\n    sentimento_total &gt; 0 ~ \"Positivo\",\n    sentimento_total &lt; 0 ~ \"Negativo\",\n    TRUE ~ \"Neutro\"\n  ))\n\n# Contar categorias\nsentimentos_lexicon %&gt;%\n  count(categoria_sentimento) %&gt;%\n  mutate(percentual = n / sum(n) * 100)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#análise-de-sentimento-abordagem-com-llms",
    "href": "analise-texto.html#análise-de-sentimento-abordagem-com-llms",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.7 Análise de Sentimento: Abordagem com LLMs",
    "text": "7.7 Análise de Sentimento: Abordagem com LLMs\nOs Large Language Models (LLMs) oferecem uma abordagem mais sofisticada para análise de sentimento, capturando nuances contextuais que léxicos não conseguem.\n\n7.7.1 Sobre Ollama e o Pacote mall\nOllama é uma ferramenta que permite rodar LLMs localmente (sem necessidade de APIs pagas ou conexão com internet após download do modelo).\nmall é um pacote R que fornece interface para interagir com LLMs através do Ollama.\n\n7.7.2 Instalação do Ollama (Passo a Passo)\n\n\n\n\n\n\nConfiguração Necessária\n\n\n\nEsta seção requer instalação prévia do Ollama no seu computador. Siga os passos:\n\nBaixe o Ollama: https://ollama.com/download\nInstale seguindo instruções para seu sistema operacional\n\nBaixe um modelo (recomendado: llama3.2):\nollama pull llama3.2\n\n\nVerifique se está rodando:\nollama list\n\n\nAlternativa: Se não puder instalar Ollama, pule esta seção e use apenas a abordagem baseada em léxico.\n\n\n\n7.7.3 Configurando o Modelo LLM\n\n# Escolher modelo (deve estar instalado via Ollama)\nllm_use(model = \"llama3.2\", seed = 100)  # seed para reprodutibilidade\n\nModelos disponíveis no Ollama:\n\n\nllama3.2 (3B parâmetros): Rápido, bom para tarefas simples\n\nllama3.1 (8B parâmetros): Balanceado entre velocidade e qualidade\n\nmistral (7B parâmetros): Alternativa de alta qualidade\n\ngemma2 (9B parâmetros): Desenvolvido pelo Google\n\n7.7.4 Análise de Sentimento com LLM\n\n# Realizar análise de sentimento usando LLM\ndados_marca_llm &lt;- dados_marca %&gt;%\n  llm_sentiment(percepcao_da_marca,\n                pred_name = \"sentimento_resposta\",\n                additional_prompt = \"Realize uma análise de sentimento em cada linha, que corresponde a uma resposta de uma entrevista sobre a percepção de uma marca. Classifique como positivo, negativo ou neutro.\")\n\n# Mover coluna de sentimento para melhor visualização\ndados_marca_llm &lt;- dados_marca_llm %&gt;%\n  relocate(sentimento_resposta, .before = sugestoes_de_melhoria)\n\n# Converter para fator\ndados_marca_llm$sentimento_resposta &lt;- as.factor(dados_marca_llm$sentimento_resposta)\n\n# Visualizar resultado\ntable(dados_marca_llm$sentimento_resposta)\n\n\n7.7.5 Visualizando Resultados do LLM\n\n# Gráfico de barras - contagens\nggplot(dados_marca_llm, aes(x = sentimento_resposta)) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title = \"Distribuição de Sentimentos (LLM)\",\n       x = \"Sentimento\",\n       y = \"Frequência\") +\n  theme_minimal()\n\n# Gráfico de barras - proporções\ndados_prop &lt;- dados_marca_llm %&gt;%\n  count(sentimento_resposta) %&gt;%\n  mutate(percent = n / sum(n) * 100)\n\nggplot(dados_prop, aes(x = sentimento_resposta, y = percent)) +\n  geom_bar(stat = \"identity\", fill = \"lightblue\") +\n  geom_text(aes(label = paste0(round(percent, 1), \"%\")),\n            vjust = -0.5) +\n  labs(title = \"Proporção de Sentimentos (LLM)\",\n       x = \"Sentimento\",\n       y = \"Porcentagem (%)\") +\n  scale_y_continuous(limits = c(0, 100)) +\n  theme_minimal()\n\n\n7.7.6 Outras Capacidades dos LLMs\n\n7.7.6.1 Sumarização de Texto\n\n# Sumarizar respostas longas\ndados_sumarizados &lt;- dados_entrevistas %&gt;%\n  llm_summarize(`Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`,\n                pred_name = \"resumo\",\n                max_words = 50)  # Resumo em até 50 palavras\n\n# Ver resumos\ndados_sumarizados %&gt;%\n  select(ID, resumo) %&gt;%\n  head(5)\n\n\n7.7.6.2 Classificação Customizada\n\n# Classificar em categorias customizadas\ndados_classificados &lt;- dados_entrevistas %&gt;%\n  llm_classify(`Quais são os principais desafios para a implementação dessas tecnologias nas instituições de ensino?`,\n               labels = c(\"infraestrutura\", \"capacitação\", \"resistência\", \"custos\"),\n               pred_name = \"categoria_desafio\")\n\n# Ver distribuição de categorias\ntable(dados_classificados$categoria_desafio)\n\n\n7.7.7 Vantagens e Desvantagens: Léxico vs. LLM\n\n\nAspecto\nAbordagem Léxico\nAbordagem LLM\n\n\n\nVelocidade\nMuito rápida\nMais lenta\n\n\nRecursos computacionais\nMínimos\nRequer GPU ou espera\n\n\nPrecisão\nModerada\nAlta\n\n\nNuances contextuais\nNão captura\nCaptura bem\n\n\nIronia/Sarcasmo\nNão detecta\nPode detectar\n\n\nConfiguração\nSimples\nRequer instalação Ollama\n\n\nReprodutibilidade\nAlta\nAlta (com seed)\n\n\nCusto\nGratuito\nGratuito (local)\n\n\n\nRecomendação: Use léxico para análises exploratórias rápidas e LLM para análises finais onde precisão é crítica.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#regressão-multinomial",
    "href": "analise-texto.html#regressão-multinomial",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.8 Regressão Multinomial",
    "text": "7.8 Regressão Multinomial\nA regressão multinomial é uma extensão da regressão logística para variáveis resposta categóricas com 3+ níveis não ordenados.\n\n7.8.1 Quando Usar?\n\n\nVariável resposta: Categórica com 3+ categorias (ex: positivo, neutro, negativo)\n\nVariáveis preditoras: Numéricas e/ou categóricas\n\nObjetivo: Modelar a probabilidade de cada categoria em função das preditoras\n\n7.8.2 Preparando Dados para Regressão\n\n# Remover NAs (regressão não aceita valores faltantes)\ndados_modelo &lt;- dados_marca_llm %&gt;%\n  drop_na(sentimento_resposta, idade, genero)\n\n# Converter sentimento para fator (se ainda não for)\ndados_modelo$sentimento_resposta &lt;- as.factor(dados_modelo$sentimento_resposta)\n\n# Verificar níveis da variável resposta\nlevels(dados_modelo$sentimento_resposta)\n\n\n7.8.3 Ajustando o Modelo Multinomial\n\nlibrary(nnet)\n\n# Ajustar modelo multinomial\n# \"neutro\" será a categoria de referência (por padrão, a primeira)\nmodelo_multi &lt;- multinom(sentimento_resposta ~ idade + genero,\n                         data = dados_modelo)\n\n# Resumo do modelo\nsummary(modelo_multi)\n\n\n7.8.4 Interpretação dos Coeficientes\nA regressão multinomial estima coeficientes para cada categoria em relação a uma categoria de referência.\nExemplo de output:\nCall:\nmultinom(formula = sentimento_resposta ~ idade + genero, data = dados_modelo)\n\nCoefficients:\n           (Intercept)      idade  generoMasculino\nnegativo     -0.234      0.012         -0.456\npositivo      1.123     -0.008          0.234\nInterpretação:\n\n\nCategoria de referência: “neutro” (não aparece no output)\n\nCoeficientes para “negativo”: Log-odds de negativo vs. neutro\n\n\nidade = 0.012: Para cada ano adicional, log-odds de negativo vs. neutro aumenta 0.012\n\ngeneroMasculino = -0.456: Homens têm log-odds menores de negativo vs. neutro (comparado a mulheres)\n\n\n\nCoeficientes para “positivo”: Log-odds de positivo vs. neutro\n\n7.8.5 Odds Ratios (Razões de Chance)\n\n# Calcular odds ratios (exponentiate os coeficientes)\nexp(coef(modelo_multi))\n\n# Ou usar gtsummary para tabela formatada\ntbl_regression(modelo_multi, exponentiate = TRUE)\n\nInterpretação de OR:\n\n\nOR = 1: Sem efeito\n\nOR &gt; 1: Aumenta a chance daquela categoria (vs. referência)\n\nOR &lt; 1: Diminui a chance daquela categoria (vs. referência)\n\n7.8.6 Verificando Multicolinearidade\n\nlibrary(car)\n\n# Calcular VIF (Variance Inflation Factor)\nvif(modelo_multi)\n\nInterpretação:\n\n\nVIF &lt; 5: Multicolinearidade aceitável\n\nVIF &gt; 10: Multicolinearidade problemática\n\n7.8.7 Predições do Modelo\n\n# Predições de probabilidade para cada categoria\npredicoes &lt;- predict(modelo_multi, type = \"probs\")\n\n# Adicionar ao dataframe\ndados_modelo &lt;- dados_modelo %&gt;%\n  bind_cols(as.data.frame(predicoes))\n\n# Visualizar primeiras predições\ndados_modelo %&gt;%\n  select(sentimento_resposta, negativo, neutro, positivo) %&gt;%\n  head(10)\n\n\n7.8.8 Visualizando Probabilidades Preditas\n\n# Criar grid de valores para predição\ngrid_predicao &lt;- expand.grid(\n  idade = seq(18, 65, by = 1),\n  genero = c(\"Feminino\", \"Masculino\")\n)\n\n# Predizer probabilidades\ngrid_predicao &lt;- grid_predicao %&gt;%\n  bind_cols(as.data.frame(predict(modelo_multi, newdata = grid_predicao, type = \"probs\")))\n\n# Transformar para formato longo\ngrid_longo &lt;- grid_predicao %&gt;%\n  pivot_longer(cols = c(negativo, neutro, positivo),\n               names_to = \"sentimento\",\n               values_to = \"probabilidade\")\n\n# Plotar\nggplot(grid_longo, aes(x = idade, y = probabilidade, color = sentimento)) +\n  geom_line(size = 1.2) +\n  facet_wrap(~ genero) +\n  labs(title = \"Probabilidade Predita de Sentimento por Idade e Gênero\",\n       x = \"Idade\",\n       y = \"Probabilidade\",\n       color = \"Sentimento\") +\n  scale_color_manual(values = c(\"negativo\" = \"red\",\n                                 \"neutro\" = \"gray\",\n                                 \"positivo\" = \"green\")) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#considerações-éticas",
    "href": "analise-texto.html#considerações-éticas",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.9 Considerações Éticas",
    "text": "7.9 Considerações Éticas\n\n7.9.1 Privacidade e Anonimização\n\n\nRemova informações identificáveis antes de análise (nomes, CPF, endereços)\n\nAgregue resultados quando reportar para evitar identificação individual\n\nObtenha consentimento quando usar dados de redes sociais ou comentários públicos\n\n7.9.2 Viés em Análise de Sentimento\n\n\nLéxicos podem ter viés cultural ou temporal\n\nLLMs podem herdar vieses dos dados de treinamento\n\nSempre valide resultados com amostra manual antes de generalizar\n\n7.9.3 Considerações Culturais para Português\n\nPortuguês brasileiro vs. europeu têm diferenças lexicais\n\nContexto importa: “legal” pode ser positivo (“que legal!”) ou neutro (“aspecto legal”)\n\nRegionalismos podem não ser capturados por léxicos gerais",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#aplicações-práticas-em-saúde",
    "href": "analise-texto.html#aplicações-práticas-em-saúde",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.10 Aplicações Práticas em Saúde",
    "text": "7.10 Aplicações Práticas em Saúde\n\n7.10.1 1. Análise de Feedback de Pacientes\n\n# Exemplo: Analisar satisfação em comentários de alta hospitalar\ncomentarios &lt;- tibble(\n  paciente_id = 1:5,\n  comentario = c(\n    \"O atendimento foi excelente, médicos muito atenciosos\",\n    \"Demora muito para ser atendido, experiência frustrante\",\n    \"Hospital limpo, mas falta comunicação da equipe\",\n    \"Tratamento eficaz, me senti acolhido pela equipe\",\n    \"Infraestrutura precária, muito barulho nos corredores\"\n  )\n)\n\n# Análise de sentimento\ncomentarios %&gt;%\n  llm_sentiment(comentario, pred_name = \"satisfacao\") %&gt;%\n  count(satisfacao)\n\n\n7.10.2 2. Pesquisa Qualitativa\n\n# Exemplo: Identificar temas em entrevistas sobre adesão a tratamento\nentrevistas_adesao &lt;- tibble(\n  participante = 1:3,\n  resposta = c(\n    \"Esqueci de tomar o remédio várias vezes porque é difícil lembrar\",\n    \"O custo elevado dificulta a compra mensal dos medicamentos\",\n    \"Sinto muitos efeitos colaterais e isso me desanima a continuar\"\n  )\n)\n\n# Classificar em categorias de barreiras\nentrevistas_adesao %&gt;%\n  llm_classify(resposta,\n               labels = c(\"esquecimento\", \"custo\", \"efeitos_colaterais\", \"complexidade\"),\n               pred_name = \"barreira_principal\")\n\n\n7.10.3 3. Monitoramento de Redes Sociais\n\n# Exemplo: Analisar discussões sobre vacinação no Twitter\n# (dados hipotéticos)\ntweets &lt;- tibble(\n  tweet_id = 1:4,\n  texto = c(\n    \"Tomei a vacina hoje e me sinto protegido, recomendo!\",\n    \"Efeitos colaterais muito fortes, precisamos de mais informação\",\n    \"Vacina é importante mas o acesso ainda é difícil em algumas regiões\",\n    \"Campanhas de vacinação são essenciais para saúde pública\"\n  )\n)\n\n# Análise de sentimento\ntweets %&gt;%\n  llm_sentiment(texto, pred_name = \"sentimento\") %&gt;%\n  count(sentimento)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "analise-texto.html#exercícios-práticos",
    "href": "analise-texto.html#exercícios-práticos",
    "title": "\n7  Análise de Dados Textuais e Mineração de Texto\n",
    "section": "\n7.11 Exercícios Práticos",
    "text": "7.11 Exercícios Práticos\n\n7.11.1 Exercício 1: Análise de Frequência\nUse o dataset de entrevistas para:\n\nTokenizar as respostas da segunda pergunta (desafios de implementação)\nRemover stopwords\nCalcular e visualizar as 15 palavras mais frequentes\nCriar um word cloud\nInterpretar os principais temas identificados\n\n7.11.2 Exercício 2: Comparação Léxico vs. LLM\n\nUse o dataset de percepção de marca\nRealize análise de sentimento usando abordagem léxico\nRealize análise de sentimento usando LLM (se disponível)\nCompare os resultados: qual proporção de concordância?\nExamine casos de discordância e tente explicar as diferenças\n\n7.11.3 Exercício 3: Regressão Multinomial\nUse os resultados de sentimento (LLM ou léxico) como variável resposta:\n\nAjuste um modelo multinomial com idade, gênero e escolaridade como preditores\nCalcule e interprete os odds ratios\nVerifique multicolinearidade com VIF\nCrie visualizações das probabilidades preditas\nEscreva uma interpretação dos resultados em formato de artigo\n\n7.11.4 Exercício 4: Análise Temática\n\nUse o dataset de entrevistas\nUse LLM para classificar respostas em temas customizados (escolha 4-5 temas)\nConte a frequência de cada tema\nCrie um gráfico de barras mostrando a distribuição\nPara cada tema, crie um word cloud das respostas classificadas naquele tema\n\n7.11.5 Exercício 5: Aplicação em Saúde\nEscolha um cenário de saúde (satisfação do paciente, adesão a tratamento, percepção de risco):\n\nCrie um pequeno dataset simulado com 10-15 respostas textuais\nRealize análise completa: tokenização, word cloud, análise de sentimento\nSe apropriado, ajuste um modelo multinomial\nInterprete os resultados no contexto clínico\nDiscuta limitações e considerações éticas\n\n\nReferências:\n\nSilge, J., & Robinson, D. (2017). Text Mining with R: A Tidy Approach. O’Reilly Media.\nWelbers, K., Van Atteveldt, W., & Benoit, K. (2017). Text analysis in R. Communication Methods and Measures, 11(4), 245-265.\nTaboada, M., et al. (2011). Lexicon-based methods for sentiment analysis. Computational Linguistics, 37(2), 267-307.\nDevlin, J., et al. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. NAACL-HLT.\nFreire, T., et al. (2014). SENTILEX-PT: Principais características e potencialidades. Oslo Studies in Language, 6(1).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análise de Dados Textuais e Mineração de Texto</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referências",
    "section": "",
    "text": "Pacotes R Utilizados\nEste livro faz uso extensivo de diversos pacotes do ecossistema R. Agradecemos aos desenvolvedores e mantenedores dessas ferramentas:",
    "crumbs": [
      "Referências"
    ]
  },
  {
    "objectID": "references.html#pacotes-r-utilizados",
    "href": "references.html#pacotes-r-utilizados",
    "title": "Referências",
    "section": "",
    "text": "Manipulação e Visualização de Dados\n\ntidyverse [@wickham2019]: Coleção de pacotes para ciência de dados\n\nWickham H, Averick M, Bryan J, et al. (2019). “Welcome to the tidyverse.” Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\ndplyr [@wickham2023dplyr]: Manipulação de dados\n\nWickham H, François R, Henry L, Müller K (2023). dplyr: A Grammar of Data Manipulation. https://dplyr.tidyverse.org\n\nggplot2 [@wickham2016]: Visualização de dados\n\nWickham H (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\nreadxl [@wickham2023readxl]: Leitura de arquivos Excel\n\nWickham H, Bryan J (2023). readxl: Read Excel Files. https://readxl.tidyverse.org\n\n\n\n\nEstatística e Modelagem\n\ngtsummary [@sjoberg2021]: Tabelas de resumo estatístico\n\nSjoberg DD, Whiting K, Curry M, Lavery JA, Larmarange J (2021). “Reproducible Summary Tables with the gtsummary Package.” The R Journal, 13(1), 570-580. https://doi.org/10.32614/RJ-2021-053\n\njtools [@long2020]: Análise e visualização de modelos de regressão\n\nLong JA (2020). jtools: Analysis and Presentation of Social Scientific Data. https://jtools.jacob-long.com\n\ncar [@fox2019]: Funções complementares para análise de regressão\n\nFox J, Weisberg S (2019). An R Companion to Applied Regression, Third edition. Sage, Thousand Oaks CA. https://socialsciences.mcmaster.ca/jfox/Books/Companion/\n\nlmtest [@zeileis2002]: Testes para modelos lineares\n\nZeileis A, Hothorn T (2002). “Diagnostic Checking in Regression Relationships.” R News, 2(3), 7-10. https://CRAN.R-project.org/package=lmtest\n\nBatra, Neale, et al. The Epidemiologist R Handbook. 2021. https://www.epirhandbook.com/en/\n\n\n\nTabelas e Relatórios\n\nflextable [@gohel2023]: Criação de tabelas para publicação\n\nGohel D, Skintzos P (2023). flextable: Functions for Tabular Reporting. https://ardata-fr.github.io/flextable-book/\n\nofficer [@gohel2023officer]: Manipulação de documentos Office\n\nGohel D (2023). officer: Manipulation of Microsoft Word and PowerPoint Documents. https://davidgohel.github.io/officer/\n\n\n\n\nUtilidades\n\njanitor [@firke2023]: Limpeza de dados\n\nFirke S (2023). janitor: Simple Tools for Examining and Cleaning Dirty Data. https://sfirke.github.io/janitor/",
    "crumbs": [
      "Referências"
    ]
  },
  {
    "objectID": "references.html#referências-bibliográficas-em-bioestatística",
    "href": "references.html#referências-bibliográficas-em-bioestatística",
    "title": "Referências",
    "section": "Referências Bibliográficas em Bioestatística",
    "text": "Referências Bibliográficas em Bioestatística\n\nBECKER, A. D.; GRENFELL, B. T. tsiR: An R package for time-series Susceptible-Infected-Recovered models of epidemics. PloS one, [S.l.], v. 12, n. 9, p. e0185528, Sept. 2017. DOI 10.1371/journal.pone.0185528. Disponível em: https://doi.org/10.1371/journal.pone.0185528.\nBATRA, Neale et al. The Epidemiologist R Handbook. 2021.\nBROWN, ANNA. Psychometrics in Exercises using R and RStudio. Textbook and data resource. 2023. Available from https://bookdown.org/annabrown/psychometricsR.\nCHAN, B. K. C. Data Analysis Using R Programming. Advances in experimental medicine and biology, [S.l.], v. 1082, p. 47-122, 2018. DOI 10.1007/978-3-319-93791-5_2. Disponível em: https://doi.org/10.1007/978-3-319-93791-5_2.\nCOLEMAN, A.; BOSE, A.; MITRA, S. Metagenomics Data Visualization Using R. Methods in molecular biology (Clifton, N.J.), [S.l.], v. 2649, p. 359-392, 2023. DOI 10.1007/978-1-0716-3072-3_19. Disponível em: https://doi.org/10.1007/978-1-0716-3072-3_19.\nFEINSTEIN, J. A. et al. R Package for Pediatric Complex Chronic Condition Classification. JAMA pediatrics, [S.l.], v. 172, n. 6, p. 596-598, June 2018. DOI 10.1001/jamapediatrics.2018.0256. Disponível em: https://doi.org/10.1001/jamapediatrics.2018.0256.\nGIOGIO, F. M.; CERAOLO, C.; MERCATELLI, D. The R Language: An Engine for Bioinformatics and Data Science. Life (Basel, Switzerland), [S.l.], v. 12, n. 5, p. 648, May 2022. DOI 10.3390/life12050648. Disponível em: https://doi.org/10.3390/life12050648.\nJALAL, H. et al. An Overview of R in Health Decision Sciences. Medical decision making : an international journal of the Society for Medical Decision Making, [S.l.], v. 37, n. 7, p. 735-746, July 2017. DOI 10.1177/0272989X16686559. Disponível em: https://doi.org/10.1177/0272989X16686559.\nJIA, L. et al. Development of interactive biological web applications with R/Shiny. Briefings in bioinformatics, [S.l.], v. 23, n. 1, p. bbab415, Jan. 2022. DOI 10.1093/bib/bbab415. Disponível em: https://doi.org/10.1093/bib/bbab415.\nKAMVAR, Z. N. et al. Epidemic curves made easy using the R package incidence. F1000Research, [S.l.], v. 8, p. 139, 2019. DOI 10.12688/f1000research.18002.1. Disponível em: https://doi.org/10.12688/f1000research.18002.1.\nKRIJKAMP, E. M. et al. Microsimulation Modeling for Health Decision Sciences Using R: A Tutorial. Medical decision making : an international journal of the Society for Medical Decision Making, [S.l.], v. 38, n. 3, p. 400-422, May 2018. DOI 10.1177/0272989X18754513. Disponível em: https://doi.org/10.1177/0272989X18754513.\nPALM, J.; MEINEKE, F. A.; PRZYBILLA, J.; PESCHEL, T. “fhircrackr”: An R Package Unlocking Fast Healthcare Interoperability Resources for Statistical Analysis. Applied clinical informatics, [S.l.], v. 14, n. 1, p. 54-64, Jan. 2023. DOI 10.1055/s-0042-1760436. Disponível em: https://doi.org/10.1055/s-0042-1760436.\nSEPULVEDA, J. L. Using R and Bioconductor in Clinical Genomics and Transcriptomics. The Journal of molecular diagnostics : JMD, [S.l.], v. 22, n. 1, p. 3-20, Jan. 2020. DOI 10.1016/j.jmoldx.2019.08.006. Disponível em: https://doi.org/10.1016/j.jmoldx.2019.08.006.\nSTAPLES, T. L. Expansion and evolution of the R programming language. Royal Society open science, [S.l.], v. 10, n. 4, p. 221550, Apr. 2023. DOI 10.1098/rsos.221550. Disponível em: https://doi.org/10.1098/rsos.221550.",
    "crumbs": [
      "Referências"
    ]
  },
  {
    "objectID": "references.html#recursos-online",
    "href": "references.html#recursos-online",
    "title": "Referências",
    "section": "Recursos Online",
    "text": "Recursos Online\n\nDocumentação Oficial\n\nR Project: https://www.r-project.org/\nRStudio: https://posit.co/products/open-source/rstudio/\nTidyverse: https://www.tidyverse.org/\nQuarto: https://quarto.org/\n\n\n\nTutoriais e Guias\n\nR for Data Science (Wickham & Grolemund): https://r4ds.had.co.nz/\nggplot2 Book: https://ggplot2-book.org/\nStatistical Inference via Data Science (ModernDive): https://moderndive.com/\nRegression and Other Stories (Gelman et al.): https://avehtari.github.io/ROS-Examples/",
    "crumbs": [
      "Referências"
    ]
  },
  {
    "objectID": "references.html#dados-utilizados",
    "href": "references.html#dados-utilizados",
    "title": "Referências",
    "section": "Dados Utilizados",
    "text": "Dados Utilizados\nOs dados de internações hospitalares utilizados neste livro são provenientes do:\n\nSistema de Informações Hospitalares do SUS (SIH/SUS)\n\nMunicípio: Maringá-PR\nPeríodo: 2024\nFonte: DATASUS - Departamento de Informática do SUS\nDisponível em: https://datasus.saude.gov.br/",
    "crumbs": [
      "Referências"
    ]
  },
  {
    "objectID": "references.html#citação-recomendada",
    "href": "references.html#citação-recomendada",
    "title": "Referências",
    "section": "Citação Recomendada",
    "text": "Citação Recomendada\nPara citar este livro, utilize:\n\nPavanello A, Costa KM, Oliveira LP (2026). Bioestatística Aplicada à Saúde usando R. Material didático do curso de Pós-graduação. Disponível em: [https://audreipavanello.github.io/bioestatistica_r/]",
    "crumbs": [
      "Referências"
    ]
  },
  {
    "objectID": "references.html#repositório-do-código",
    "href": "references.html#repositório-do-código",
    "title": "Referências",
    "section": "Repositório do Código",
    "text": "Repositório do Código\nTodo o código-fonte deste livro está disponível no GitHub:\n\nRepositório: [https://github.com/AudreiPavanello/bioestatistica_r]\nLicença: CC BY-NC-SA 4.0 (conteúdo) e MIT (código)",
    "crumbs": [
      "Referências"
    ]
  },
  {
    "objectID": "references.html#software",
    "href": "references.html#software",
    "title": "Referências",
    "section": "Software",
    "text": "Software\nEste livro foi criado usando:\n\nR versão 4.3+ (https://www.r-project.org/)\nRStudio (https://posit.co/products/open-source/rstudio/)\nQuarto (https://quarto.org/)",
    "crumbs": [
      "Referências"
    ]
  }
]