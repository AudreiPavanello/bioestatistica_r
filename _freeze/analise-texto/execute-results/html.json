{
  "hash": "5b09b2bb519fece239e59334111e2d1f",
  "result": {
    "engine": "knitr",
    "markdown": "# Análise de Dados Textuais e Mineração de Texto\n\n## Introdução à Mineração de Texto\n\nA **mineração de texto (text mining)** e a **análise de sentimento** são técnicas cada vez mais importantes em pesquisas de saúde, permitindo extrair informações valiosas de dados não estruturados como narrativas de pacientes, respostas abertas em questionários, postagens em redes sociais, registros médicos, e transcrições de entrevistas.\n\n### Aplicações em Saúde\n\n- **Análise de feedback de pacientes**: Avaliar satisfação através de comentários abertos\n- **Pesquisa qualitativa**: Processar transcrições de entrevistas e grupos focais\n- **Monitoramento de redes sociais**: Acompanhar discussões públicas sobre saúde\n- **Análise de registros médicos**: Extrair informações de notas clínicas\n- **Pesquisas de percepção**: Avaliar atitudes em relação a medicamentos, tratamentos, ou políticas de saúde\n\n### Estrutura do Capítulo\n\nNeste capítulo, abordaremos:\n\n1. **Preparação e limpeza** de dados textuais\n2. **Tokenização** e análise de frequência\n3. **Visualização** com word clouds\n4. **Análise de sentimento** usando dois métodos:\n   - Abordagem baseada em **léxico** (dicionário)\n   - Abordagem baseada em **LLMs** (Large Language Models)\n5. **Regressão multinomial** para modelar sentimento\n\n## Preparação do Ambiente\n\n### Carregando Pacotes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)      # Manipulação de dados\nlibrary(readxl)         # Leitura de Excel\nlibrary(janitor)        # Limpeza de nomes\nlibrary(tidytext)       # Mineração de texto (tokenização)\nlibrary(wordcloud)      # Nuvens de palavras\nlibrary(quanteda)       # Análise quantitativa de texto\nlibrary(lexiconPT)      # Léxico de sentimentos em português\nlibrary(tm)             # Text mining básico\nlibrary(mall)           # Interface para LLMs locais\nlibrary(nnet)           # Regressão multinomial\nlibrary(gtsummary)      # Tabelas de regressão\n\n# Remover notação científica\noptions(scipen = 999)\n```\n:::\n\n\n### Sobre os Datasets\n\nUtilizaremos dois conjuntos de dados neste capítulo:\n\n1. **entrevistas.xlsx**: Respostas abertas sobre impacto de tecnologias digitais na educação\n2. **respostas_questionario.xlsx**: Dados de percepção de marca com variáveis demográficas\n\n## Tokenização e Análise de Frequência\n\nA **tokenização** é o processo de dividir texto em unidades menores chamadas **tokens** (palavras, frases, ou n-gramas).\n\n### Importando Dados de Entrevistas\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Importar dados de entrevistas\ndados_entrevistas <- read_excel(\"data/entrevistas.xlsx\")\n\n# Visualizar estrutura\nglimpse(dados_entrevistas)\n```\n:::\n\n\n### Tokenização por Sentenças\n\nPrimeiro, vamos segmentar o texto em **sentenças** para facilitar análises posteriores:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tokenizar em sentenças\nentrevistas_frases <- dados_entrevistas %>%\n  # Segmentar em frases (sentences)\n  unnest_tokens(output = frase,\n                input = `Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`,\n                token = \"sentences\") %>%\n  # Agrupar por ID da entrevista\n  group_by(ID) %>%\n  # Criar identificador de frase dentro de cada entrevista\n  mutate(id_frase_entrevista = row_number()) %>%\n  ungroup() %>%\n  # Selecionar colunas relevantes\n  select(ID, id_frase_entrevista, frase)\n\n# Visualizar resultado\nhead(entrevistas_frases, 10)\n```\n:::\n\n\n**Explicação:**\n\n- `unnest_tokens()`: Função do tidytext que separa texto em tokens\n- `token = \"sentences\"`: Especifica tokenização por sentenças\n- `row_number()`: Cria ID sequencial para cada frase dentro de cada entrevista\n\n### Tokenização por Palavras\n\nPara análise de frequência, tokenizamos em **palavras**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tokenizar em palavras\npalavras_tokens <- dados_entrevistas %>%\n  unnest_tokens(output = word,\n                input = `Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`,\n                token = \"words\") %>%\n  select(ID, word)\n\n# Visualizar\nhead(palavras_tokens, 20)\n```\n:::\n\n\n## Remoção de Stopwords\n\n**Stopwords** são palavras muito comuns que geralmente não carregam significado importante para análise (ex: \"a\", \"o\", \"que\", \"de\", \"em\").\n\n### Criando Lista de Stopwords em Português\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Stopwords em português (lista customizada)\nstop_words_pt <- tibble(\n  word = c(\"a\", \"o\", \"que\", \"e\", \"do\", \"da\", \"em\", \"um\", \"para\", \"é\",\n           \"com\", \"não\", \"uma\", \"os\", \"no\", \"se\", \"na\", \"por\", \"mais\", \"as\",\n           \"dos\", \"como\", \"mas\", \"foi\", \"ao\", \"ele\", \"das\", \"tem\", \"à\", \"seu\",\n           \"sua\", \"ou\", \"ser\", \"quando\", \"muito\", \"há\", \"nos\", \"já\", \"está\",\n           \"eu\", \"também\", \"só\", \"pelo\", \"pela\", \"até\", \"isso\", \"ela\", \"entre\",\n           \"era\", \"depois\", \"sem\", \"mesmo\", \"aos\", \"ter\", \"seus\", \"quem\", \"nas\",\n           \"me\", \"esse\", \"eles\", \"estão\", \"você\", \"tinha\", \"foram\", \"essa\",\n           \"num\", \"nem\", \"suas\", \"meu\", \"às\", \"minha\", \"têm\", \"numa\", \"pelos\",\n           \"elas\", \"havia\", \"seja\", \"qual\", \"será\", \"nós\", \"tenho\", \"lhe\",\n           \"deles\", \"essas\", \"esses\", \"pelas\", \"este\", \"fosse\", \"dele\", \"tu\",\n           \"te\", \"vocês\", \"vos\", \"lhes\", \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\",\n           \"tuas\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"dela\", \"delas\",\n           \"esta\", \"estes\", \"estas\", \"aquele\", \"aquela\", \"aqueles\", \"aquelas\",\n           \"isto\", \"aquilo\", \"sabe\", \"acho\", \"pode\", \"podem\", \"então\", \"vai\",\n           \"são\", \"ainda\", \"bem\", \"só\", \"cada\", \"cada\", \"onde\", \"muitos\",\n           \"alguma\", \"alguns\", \"tudo\", \"toda\", \"todos\", \"todas\")\n)\n\n# Alternativamente, usar pacote stopwords\nlibrary(stopwords)\nstopwords_pt_pacote <- tibble(word = stopwords(\"pt\"))\n```\n:::\n\n\n### Calculando Frequência de Palavras\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcular frequência, removendo stopwords\npalavras_frequentes <- dados_entrevistas %>%\n  unnest_tokens(word, `Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`) %>%\n  anti_join(stop_words_pt, by = \"word\") %>%  # Remove stopwords\n  count(word, sort = TRUE) %>%                # Conta frequência\n  filter(n > 1)                               # Remove palavras únicas\n\n# Visualizar top 20 palavras\nprint(palavras_frequentes, n = 20)\n```\n:::\n\n\n### Visualizando Frequência com Gráfico de Barras\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Top 20 palavras mais frequentes\npalavras_frequentes %>%\n  slice_max(n, n = 20) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = n, y = word)) +\n  geom_col(fill = \"steelblue\") +\n  labs(title = \"20 Palavras Mais Frequentes\",\n       x = \"Frequência\",\n       y = \"Palavra\") +\n  theme_minimal()\n```\n:::\n\n\n## Visualização com Word Clouds\n\n**Word clouds (nuvens de palavras)** são representações visuais onde o tamanho da palavra é proporcional à sua frequência.\n\n### Criando uma Função para Word Cloud\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Função para criar word cloud\ncriar_wordcloud <- function(coluna) {\n  # Processar texto\n  palavras <- coluna %>%\n    str_to_lower() %>%                         # Minúsculas\n    str_replace_all(\"[[:punct:]]\", \"\") %>%     # Remover pontuação\n    str_replace_all(\"[[:digit:]]\", \"\") %>%     # Remover números\n    str_split(\"\\\\s+\") %>%                      # Dividir por espaços\n    unlist()\n\n  # Remover stopwords e palavras curtas\n  stopwords_pt <- stopwords(\"portuguese\")\n  palavras <- palavras[!palavras %in% stopwords_pt & nchar(palavras) > 2]\n\n  # Contar frequência\n  freq_palavras <- table(palavras) %>%\n    as.data.frame() %>%\n    arrange(desc(Freq)) %>%\n    filter(Freq > 1)  # Apenas palavras que aparecem mais de 1 vez\n\n  # Plotar word cloud\n  wordcloud(words = freq_palavras$palavras,\n            freq = freq_palavras$Freq,\n            max.words = 100,              # Máximo de palavras\n            scale = c(3, 0.5),            # Escala de tamanho\n            random.order = FALSE,         # Palavras mais frequentes no centro\n            rot.per = 0.35,               # 35% de palavras rotacionadas\n            colors = brewer.pal(8, \"Dark2\"))  # Paleta de cores\n}\n```\n:::\n\n\n### Aplicando a Função\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Word cloud para primeira pergunta\ncriar_wordcloud(dados_entrevistas$`Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`)\n\n# Word cloud para segunda pergunta\ncriar_wordcloud(dados_entrevistas$`Quais são os principais desafios para a implementação dessas tecnologias nas instituições de ensino?`)\n```\n:::\n\n\n**Interpretação:**\n\n- Palavras **maiores** aparecem com maior frequência\n- Palavras **centrais** geralmente são as mais frequentes\n- **Cores** ajudam a diferenciar grupos de palavras\n- Útil para identificar temas principais rapidamente\n\n## Análise de Sentimento: Abordagem Baseada em Léxico\n\nA **análise de sentimento baseada em léxico** usa dicionários pré-definidos que atribuem polaridade (positiva, negativa, neutra) a palavras.\n\n### Sobre o Léxico SentiLex-PT\n\nO **SentiLex-PT** é um léxico de sentimentos para português que atribui:\n\n- **Polaridade**: -1 (negativo), 0 (neutro), +1 (positivo)\n- **Scores contínuos**: Valores intermediários indicam intensidade\n\n### Importando Dados de Percepção de Marca\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Importar dados de questionário sobre percepção de marca\ndados_marca <- read_excel(\"data/respostas_questionario.xlsx\")\n\n# Limpar nomes e preparar dados\ndados_marca <- dados_marca %>%\n  clean_names() %>%\n  mutate(across(c(genero, estado, nivel_de_escolaridade,\n                  avaliacao_da_marca_1_5), as.factor))\n\n# Visualizar estrutura\nglimpse(dados_marca)\n```\n:::\n\n\n### Carregando o Léxico de Sentimentos\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Carregar léxico SentiLex-PT\ndata(\"sentiLex_lem_PT02\")\n\n# Visualizar estrutura do léxico\nhead(sentiLex_lem_PT02)\n```\n:::\n\n\n### Pré-processamento do Texto\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pré-processar texto e tokenizar\ndados_tokens <- dados_marca %>%\n  mutate(percepcao_da_marca = percepcao_da_marca %>%\n           tolower() %>%              # Converter para minúsculas\n           removePunctuation()) %>%   # Remover pontuação\n  unnest_tokens(term, percepcao_da_marca)  # Tokenizar\n\n# Remover stopwords\nstopwords_pt <- stopwords(\"pt\")\ndados_tokens <- dados_tokens %>%\n  filter(!term %in% stopwords_pt)\n\n# Visualizar tokens\nhead(dados_tokens, 20)\n```\n:::\n\n\n### Atribuindo Polaridade às Palavras\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Juntar tokens com o léxico de sentimentos\ndados_sent <- dados_tokens %>%\n  left_join(sentiLex_lem_PT02, by = \"term\")\n\n# Visualizar resultado (mostra polaridade para cada palavra)\ndados_sent %>%\n  select(id, term, polarity) %>%\n  filter(!is.na(polarity)) %>%  # Apenas palavras com polaridade\n  head(20)\n```\n:::\n\n\n### Calculando Sentimento Total por Resposta\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcular sentimento total por ID (somar polaridades)\nsentimentos_lexicon <- dados_sent %>%\n  group_by(id) %>%\n  summarise(sentimento_total = sum(polarity, na.rm = TRUE),\n            n_palavras_sentimento = sum(!is.na(polarity)))\n\n# Visualizar distribuição\nsentimentos_lexicon %>%\n  ggplot(aes(x = sentimento_total)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Distribuição do Sentimento (Léxico)\",\n       x = \"Escore de Sentimento\",\n       y = \"Frequência\") +\n  theme_minimal()\n```\n:::\n\n\n**Interpretação:**\n\n- **Sentimento total > 0**: Sentimento predominantemente positivo\n- **Sentimento total < 0**: Sentimento predominantemente negativo\n- **Sentimento total ≈ 0**: Sentimento neutro ou misto\n\n### Classificando em Categorias\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Classificar em categorias\nsentimentos_lexicon <- sentimentos_lexicon %>%\n  mutate(categoria_sentimento = case_when(\n    sentimento_total > 0 ~ \"Positivo\",\n    sentimento_total < 0 ~ \"Negativo\",\n    TRUE ~ \"Neutro\"\n  ))\n\n# Contar categorias\nsentimentos_lexicon %>%\n  count(categoria_sentimento) %>%\n  mutate(percentual = n / sum(n) * 100)\n```\n:::\n\n\n## Análise de Sentimento: Abordagem com LLMs\n\nOs **Large Language Models (LLMs)** oferecem uma abordagem mais sofisticada para análise de sentimento, capturando nuances contextuais que léxicos não conseguem.\n\n### Sobre Ollama e o Pacote mall\n\n**Ollama** é uma ferramenta que permite rodar LLMs localmente (sem necessidade de APIs pagas ou conexão com internet após download do modelo).\n\n**mall** é um pacote R que fornece interface para interagir com LLMs através do Ollama.\n\n### Instalação do Ollama (Passo a Passo)\n\n::: {.callout-important}\n## Configuração Necessária\n\nEsta seção requer instalação prévia do Ollama no seu computador. Siga os passos:\n\n1. **Baixe o Ollama**: [https://ollama.com/download](https://ollama.com/download)\n2. **Instale** seguindo instruções para seu sistema operacional\n3. **Baixe um modelo** (recomendado: llama3.2):\n   ```bash\n   ollama pull llama3.2\n   ```\n4. **Verifique** se está rodando:\n   ```bash\n   ollama list\n   ```\n\n**Alternativa:** Se não puder instalar Ollama, pule esta seção e use apenas a abordagem baseada em léxico.\n:::\n\n### Configurando o Modelo LLM\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Escolher modelo (deve estar instalado via Ollama)\nllm_use(model = \"llama3.2\", seed = 100)  # seed para reprodutibilidade\n```\n:::\n\n\n**Modelos disponíveis no Ollama:**\n\n- **llama3.2** (3B parâmetros): Rápido, bom para tarefas simples\n- **llama3.1** (8B parâmetros): Balanceado entre velocidade e qualidade\n- **mistral** (7B parâmetros): Alternativa de alta qualidade\n- **gemma2** (9B parâmetros): Desenvolvido pelo Google\n\n### Análise de Sentimento com LLM\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Realizar análise de sentimento usando LLM\ndados_marca_llm <- dados_marca %>%\n  llm_sentiment(percepcao_da_marca,\n                pred_name = \"sentimento_resposta\",\n                additional_prompt = \"Realize uma análise de sentimento em cada linha, que corresponde a uma resposta de uma entrevista sobre a percepção de uma marca. Classifique como positivo, negativo ou neutro.\")\n\n# Mover coluna de sentimento para melhor visualização\ndados_marca_llm <- dados_marca_llm %>%\n  relocate(sentimento_resposta, .before = sugestoes_de_melhoria)\n\n# Converter para fator\ndados_marca_llm$sentimento_resposta <- as.factor(dados_marca_llm$sentimento_resposta)\n\n# Visualizar resultado\ntable(dados_marca_llm$sentimento_resposta)\n```\n:::\n\n\n### Visualizando Resultados do LLM\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gráfico de barras - contagens\nggplot(dados_marca_llm, aes(x = sentimento_resposta)) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title = \"Distribuição de Sentimentos (LLM)\",\n       x = \"Sentimento\",\n       y = \"Frequência\") +\n  theme_minimal()\n\n# Gráfico de barras - proporções\ndados_prop <- dados_marca_llm %>%\n  count(sentimento_resposta) %>%\n  mutate(percent = n / sum(n) * 100)\n\nggplot(dados_prop, aes(x = sentimento_resposta, y = percent)) +\n  geom_bar(stat = \"identity\", fill = \"lightblue\") +\n  geom_text(aes(label = paste0(round(percent, 1), \"%\")),\n            vjust = -0.5) +\n  labs(title = \"Proporção de Sentimentos (LLM)\",\n       x = \"Sentimento\",\n       y = \"Porcentagem (%)\") +\n  scale_y_continuous(limits = c(0, 100)) +\n  theme_minimal()\n```\n:::\n\n\n### Outras Capacidades dos LLMs\n\n#### Sumarização de Texto\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sumarizar respostas longas\ndados_sumarizados <- dados_entrevistas %>%\n  llm_summarize(`Como você avalia o impacto das tecnologias digitais na qualidade do ensino?`,\n                pred_name = \"resumo\",\n                max_words = 50)  # Resumo em até 50 palavras\n\n# Ver resumos\ndados_sumarizados %>%\n  select(ID, resumo) %>%\n  head(5)\n```\n:::\n\n\n#### Classificação Customizada\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Classificar em categorias customizadas\ndados_classificados <- dados_entrevistas %>%\n  llm_classify(`Quais são os principais desafios para a implementação dessas tecnologias nas instituições de ensino?`,\n               labels = c(\"infraestrutura\", \"capacitação\", \"resistência\", \"custos\"),\n               pred_name = \"categoria_desafio\")\n\n# Ver distribuição de categorias\ntable(dados_classificados$categoria_desafio)\n```\n:::\n\n\n### Vantagens e Desvantagens: Léxico vs. LLM\n\n| **Aspecto** | **Abordagem Léxico** | **Abordagem LLM** |\n|-------------|---------------------|------------------|\n| **Velocidade** | Muito rápida | Mais lenta |\n| **Recursos computacionais** | Mínimos | Requer GPU ou espera |\n| **Precisão** | Moderada | Alta |\n| **Nuances contextuais** | Não captura | Captura bem |\n| **Ironia/Sarcasmo** | Não detecta | Pode detectar |\n| **Configuração** | Simples | Requer instalação Ollama |\n| **Reprodutibilidade** | Alta | Alta (com seed) |\n| **Custo** | Gratuito | Gratuito (local) |\n\n**Recomendação:** Use léxico para análises exploratórias rápidas e LLM para análises finais onde precisão é crítica.\n\n## Regressão Multinomial\n\nA **regressão multinomial** é uma extensão da regressão logística para variáveis resposta **categóricas com 3+ níveis não ordenados**.\n\n### Quando Usar?\n\n- **Variável resposta**: Categórica com 3+ categorias (ex: positivo, neutro, negativo)\n- **Variáveis preditoras**: Numéricas e/ou categóricas\n- **Objetivo**: Modelar a probabilidade de cada categoria em função das preditoras\n\n### Preparando Dados para Regressão\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remover NAs (regressão não aceita valores faltantes)\ndados_modelo <- dados_marca_llm %>%\n  drop_na(sentimento_resposta, idade, genero)\n\n# Converter sentimento para fator (se ainda não for)\ndados_modelo$sentimento_resposta <- as.factor(dados_modelo$sentimento_resposta)\n\n# Verificar níveis da variável resposta\nlevels(dados_modelo$sentimento_resposta)\n```\n:::\n\n\n### Ajustando o Modelo Multinomial\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nnet)\n\n# Ajustar modelo multinomial\n# \"neutro\" será a categoria de referência (por padrão, a primeira)\nmodelo_multi <- multinom(sentimento_resposta ~ idade + genero,\n                         data = dados_modelo)\n\n# Resumo do modelo\nsummary(modelo_multi)\n```\n:::\n\n\n### Interpretação dos Coeficientes\n\nA regressão multinomial estima coeficientes para cada categoria **em relação a uma categoria de referência**.\n\n**Exemplo de output:**\n\n```\nCall:\nmultinom(formula = sentimento_resposta ~ idade + genero, data = dados_modelo)\n\nCoefficients:\n           (Intercept)      idade  generoMasculino\nnegativo     -0.234      0.012         -0.456\npositivo      1.123     -0.008          0.234\n```\n\n**Interpretação:**\n\n- **Categoria de referência**: \"neutro\" (não aparece no output)\n- **Coeficientes para \"negativo\"**: Log-odds de negativo vs. neutro\n  - `idade = 0.012`: Para cada ano adicional, log-odds de negativo vs. neutro aumenta 0.012\n  - `generoMasculino = -0.456`: Homens têm log-odds menores de negativo vs. neutro (comparado a mulheres)\n- **Coeficientes para \"positivo\"**: Log-odds de positivo vs. neutro\n\n### Odds Ratios (Razões de Chance)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcular odds ratios (exponentiate os coeficientes)\nexp(coef(modelo_multi))\n\n# Ou usar gtsummary para tabela formatada\ntbl_regression(modelo_multi, exponentiate = TRUE)\n```\n:::\n\n\n**Interpretação de OR:**\n\n- **OR = 1**: Sem efeito\n- **OR > 1**: Aumenta a chance daquela categoria (vs. referência)\n- **OR < 1**: Diminui a chance daquela categoria (vs. referência)\n\n### Verificando Multicolinearidade\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\n\n# Calcular VIF (Variance Inflation Factor)\nvif(modelo_multi)\n```\n:::\n\n\n**Interpretação:**\n\n- **VIF < 5**: Multicolinearidade aceitável\n- **VIF > 10**: Multicolinearidade problemática\n\n### Predições do Modelo\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Predições de probabilidade para cada categoria\npredicoes <- predict(modelo_multi, type = \"probs\")\n\n# Adicionar ao dataframe\ndados_modelo <- dados_modelo %>%\n  bind_cols(as.data.frame(predicoes))\n\n# Visualizar primeiras predições\ndados_modelo %>%\n  select(sentimento_resposta, negativo, neutro, positivo) %>%\n  head(10)\n```\n:::\n\n\n### Visualizando Probabilidades Preditas\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Criar grid de valores para predição\ngrid_predicao <- expand.grid(\n  idade = seq(18, 65, by = 1),\n  genero = c(\"Feminino\", \"Masculino\")\n)\n\n# Predizer probabilidades\ngrid_predicao <- grid_predicao %>%\n  bind_cols(as.data.frame(predict(modelo_multi, newdata = grid_predicao, type = \"probs\")))\n\n# Transformar para formato longo\ngrid_longo <- grid_predicao %>%\n  pivot_longer(cols = c(negativo, neutro, positivo),\n               names_to = \"sentimento\",\n               values_to = \"probabilidade\")\n\n# Plotar\nggplot(grid_longo, aes(x = idade, y = probabilidade, color = sentimento)) +\n  geom_line(size = 1.2) +\n  facet_wrap(~ genero) +\n  labs(title = \"Probabilidade Predita de Sentimento por Idade e Gênero\",\n       x = \"Idade\",\n       y = \"Probabilidade\",\n       color = \"Sentimento\") +\n  scale_color_manual(values = c(\"negativo\" = \"red\",\n                                 \"neutro\" = \"gray\",\n                                 \"positivo\" = \"green\")) +\n  theme_minimal()\n```\n:::\n\n\n## Considerações Éticas\n\n### Privacidade e Anonimização\n\n- **Remova informações identificáveis** antes de análise (nomes, CPF, endereços)\n- **Agregue resultados** quando reportar para evitar identificação individual\n- **Obtenha consentimento** quando usar dados de redes sociais ou comentários públicos\n\n### Viés em Análise de Sentimento\n\n- **Léxicos** podem ter viés cultural ou temporal\n- **LLMs** podem herdar vieses dos dados de treinamento\n- **Sempre valide** resultados com amostra manual antes de generalizar\n\n### Considerações Culturais para Português\n\n- Português brasileiro vs. europeu têm diferenças lexicais\n- **Contexto importa**: \"legal\" pode ser positivo (\"que legal!\") ou neutro (\"aspecto legal\")\n- **Regionalismos** podem não ser capturados por léxicos gerais\n\n## Aplicações Práticas em Saúde\n\n### 1. Análise de Feedback de Pacientes\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exemplo: Analisar satisfação em comentários de alta hospitalar\ncomentarios <- tibble(\n  paciente_id = 1:5,\n  comentario = c(\n    \"O atendimento foi excelente, médicos muito atenciosos\",\n    \"Demora muito para ser atendido, experiência frustrante\",\n    \"Hospital limpo, mas falta comunicação da equipe\",\n    \"Tratamento eficaz, me senti acolhido pela equipe\",\n    \"Infraestrutura precária, muito barulho nos corredores\"\n  )\n)\n\n# Análise de sentimento\ncomentarios %>%\n  llm_sentiment(comentario, pred_name = \"satisfacao\") %>%\n  count(satisfacao)\n```\n:::\n\n\n### 2. Pesquisa Qualitativa\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exemplo: Identificar temas em entrevistas sobre adesão a tratamento\nentrevistas_adesao <- tibble(\n  participante = 1:3,\n  resposta = c(\n    \"Esqueci de tomar o remédio várias vezes porque é difícil lembrar\",\n    \"O custo elevado dificulta a compra mensal dos medicamentos\",\n    \"Sinto muitos efeitos colaterais e isso me desanima a continuar\"\n  )\n)\n\n# Classificar em categorias de barreiras\nentrevistas_adesao %>%\n  llm_classify(resposta,\n               labels = c(\"esquecimento\", \"custo\", \"efeitos_colaterais\", \"complexidade\"),\n               pred_name = \"barreira_principal\")\n```\n:::\n\n\n### 3. Monitoramento de Redes Sociais\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exemplo: Analisar discussões sobre vacinação no Twitter\n# (dados hipotéticos)\ntweets <- tibble(\n  tweet_id = 1:4,\n  texto = c(\n    \"Tomei a vacina hoje e me sinto protegido, recomendo!\",\n    \"Efeitos colaterais muito fortes, precisamos de mais informação\",\n    \"Vacina é importante mas o acesso ainda é difícil em algumas regiões\",\n    \"Campanhas de vacinação são essenciais para saúde pública\"\n  )\n)\n\n# Análise de sentimento\ntweets %>%\n  llm_sentiment(texto, pred_name = \"sentimento\") %>%\n  count(sentimento)\n```\n:::\n\n\n## Exercícios Práticos\n\n### Exercício 1: Análise de Frequência\n\nUse o dataset de entrevistas para:\n\na) Tokenizar as respostas da segunda pergunta (desafios de implementação)\nb) Remover stopwords\nc) Calcular e visualizar as 15 palavras mais frequentes\nd) Criar um word cloud\ne) Interpretar os principais temas identificados\n\n### Exercício 2: Comparação Léxico vs. LLM\n\na) Use o dataset de percepção de marca\nb) Realize análise de sentimento usando abordagem léxico\nc) Realize análise de sentimento usando LLM (se disponível)\nd) Compare os resultados: qual proporção de concordância?\ne) Examine casos de discordância e tente explicar as diferenças\n\n### Exercício 3: Regressão Multinomial\n\nUse os resultados de sentimento (LLM ou léxico) como variável resposta:\n\na) Ajuste um modelo multinomial com idade, gênero e escolaridade como preditores\nb) Calcule e interprete os odds ratios\nc) Verifique multicolinearidade com VIF\nd) Crie visualizações das probabilidades preditas\ne) Escreva uma interpretação dos resultados em formato de artigo\n\n### Exercício 4: Análise Temática\n\na) Use o dataset de entrevistas\nb) Use LLM para classificar respostas em temas customizados (escolha 4-5 temas)\nc) Conte a frequência de cada tema\nd) Crie um gráfico de barras mostrando a distribuição\ne) Para cada tema, crie um word cloud das respostas classificadas naquele tema\n\n### Exercício 5: Aplicação em Saúde\n\nEscolha um cenário de saúde (satisfação do paciente, adesão a tratamento, percepção de risco):\n\na) Crie um pequeno dataset simulado com 10-15 respostas textuais\nb) Realize análise completa: tokenização, word cloud, análise de sentimento\nc) Se apropriado, ajuste um modelo multinomial\nd) Interprete os resultados no contexto clínico\ne) Discuta limitações e considerações éticas\n\n---\n\n**Referências:**\n\n- Silge, J., & Robinson, D. (2017). *Text Mining with R: A Tidy Approach*. O'Reilly Media.\n- Welbers, K., Van Atteveldt, W., & Benoit, K. (2017). Text analysis in R. *Communication Methods and Measures*, 11(4), 245-265.\n- Taboada, M., et al. (2011). Lexicon-based methods for sentiment analysis. *Computational Linguistics*, 37(2), 267-307.\n- Devlin, J., et al. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. *NAACL-HLT*.\n- Freire, T., et al. (2014). SENTILEX-PT: Principais características e potencialidades. *Oslo Studies in Language*, 6(1).\n",
    "supporting": [
      "analise-texto_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}