{
  "hash": "130dd1d1a382d66a28afd060f4a9841c",
  "result": {
    "engine": "knitr",
    "markdown": "# Testes Estatísticos\n\n## Introdução aos Testes de Hipóteses\n\nOs **testes estatísticos** são ferramentas fundamentais para responder perguntas científicas com base em dados. Eles nos permitem tomar decisões fundamentadas sobre relações, diferenças e associações entre variáveis, quantificando a incerteza das nossas conclusões.\n\n### Lógica dos Testes de Hipóteses\n\nTodo teste estatístico segue uma lógica baseada em duas hipóteses complementares:\n\n- **Hipótese Nula (H₀)**: Assume que não existe efeito, diferença ou associação entre as variáveis. É a hipótese de \"status quo\" ou \"nenhuma mudança\".\n- **Hipótese Alternativa (H₁)**: Propõe que existe um efeito, diferença ou associação. É o que geralmente buscamos evidenciar.\n\n**Exemplo prático:**\n```\nH₀: A média de idade entre homens e mulheres internados é igual\nH₁: A média de idade entre homens e mulheres internados é diferente\n```\n\n### Valor-p e Significância Estatística\n\nO **valor-p** (p-value) representa a probabilidade de obter os resultados observados (ou mais extremos) assumindo que a hipótese nula é verdadeira.\n\n**Interpretação:**\n\n- **p < 0,05**: Rejeitamos H₀ → evidência estatisticamente significativa de que existe diferença/associação\n- **p ≥ 0,05**: Não rejeitamos H₀ → não há evidência estatística suficiente para afirmar que existe diferença/associação\n\n**Importante:** Significância estatística (p < 0,05) não implica necessariamente relevância clínica ou prática. Sempre interprete os resultados no contexto do estudo.\n\n### Intervalos de Confiança\n\nOs **intervalos de confiança (IC)** fornecem uma faixa de valores plausíveis para o parâmetro populacional.\n\n- **IC 95%**: Temos 95% de confiança que o valor verdadeiro está dentro deste intervalo\n- Se o IC não inclui zero (para diferenças) ou 1 (para razões), o resultado é estatisticamente significativo (p < 0,05)\n\n### Erros em Testes de Hipóteses\n\n| | **H₀ Verdadeira** | **H₀ Falsa** |\n|---|---|---|\n| **Rejeitar H₀** | Erro Tipo I (α) | Decisão correta |\n| **Não rejeitar H₀** | Decisão correta | Erro Tipo II (β) |\n\n- **Erro Tipo I (α)**: Falso positivo - rejeitar H₀ quando ela é verdadeira (fixado em 0,05)\n- **Erro Tipo II (β)**: Falso negativo - não rejeitar H₀ quando ela é falsa\n\n## Árvore de Decisão: Qual Teste Usar?\n\nAntes de realizar qualquer teste, é fundamental escolher o teste apropriado para suas variáveis e pergunta de pesquisa.\n\n### Fluxograma de Seleção de Testes\n\n```{mermaid}\nflowchart TD\n    A[Qual é o seu objetivo?] --> B{Comparar grupos?}\n    A --> C{Testar associação?}\n    A --> D{Medir correlação?}\n\n    B --> E{Variável dependente}\n    E --> F[Numérica]\n    E --> G[Categórica]\n\n    F --> H{Quantos grupos?}\n    H --> I[2 grupos]\n    H --> J[3+ grupos]\n\n    I --> K{Dados normais?}\n    K --> |Sim| L[Teste t]\n    K --> |Não| M[Mann-Whitney]\n\n    J --> N{Dados normais?}\n    N --> |Sim| O[ANOVA]\n    N --> |Não| P[Kruskal-Wallis]\n\n    C --> Q{Ambas categóricas}\n    Q --> R{Tamanho da amostra?}\n    R --> |Grande| S[Qui-quadrado]\n    R --> |Pequena| T[Teste Exato de Fisher]\n\n    D --> U{Ambas numéricas}\n    U --> V{Dados normais?}\n    V --> |Sim| W[Correlação de Pearson]\n    V --> |Não| X[Correlação de Spearman]\n```\n\n### Tabela Resumo de Testes\n\n| **Objetivo** | **Variável Dependente** | **Variável Independente** | **Teste Paramétrico** | **Teste Não-Paramétrico** |\n|--------------|-------------------------|---------------------------|----------------------|--------------------------|\n| Comparar 2 grupos | Numérica | Categórica (2 níveis) | Teste t | Mann-Whitney |\n| Comparar 3+ grupos | Numérica | Categórica (3+ níveis) | ANOVA | Kruskal-Wallis |\n| Testar associação | Categórica | Categórica | Qui-quadrado | Teste Exato de Fisher |\n| Medir correlação | Numérica | Numérica | Pearson | Spearman / Kendall |\n\n## Preparação dos Dados\n\nAntes de realizar os testes estatísticos, precisamos carregar os pacotes e preparar os dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)    # Manipulação de dados\nlibrary(readxl)       # Leitura de Excel\nlibrary(janitor)      # Limpeza de dados\nlibrary(car)          # Testes estatísticos avançados\nlibrary(FSA)          # Teste de Dunn (post-hoc Kruskal-Wallis)\nlibrary(ggpubr)       # Gráficos estatísticos\n\n# Remover notação científica\noptions(scipen = 999)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Carregar dados de internações\ndados <- read_excel(\"data/dados_internacoes_maringa_2024.xlsx\")\n\n# Preparar dados\ndados_limpos <- dados |>\n  clean_names() |>\n  filter(cod_idade == \"Anos\") |>\n  select(sexo, val_tot, raca_cor, idade, morte, dias_perm) |>\n  mutate(\n    raca_cor = case_when(\n      raca_cor == '01' ~ \"Branca\",\n      raca_cor == \"02\" ~ \"Preta\",\n      raca_cor == \"03\" ~ \"Parda\",\n      raca_cor == \"04\" ~ \"Amarela\",\n      raca_cor == \"05\" ~ \"Indígena\"\n    )\n  ) |>\n  mutate(across(c(val_tot, idade, dias_perm), as.numeric)) |>\n  mutate(across(c(sexo, raca_cor, morte), as.factor)) |>\n  rename(df = everything())  # Para compatibilidade com scripts existentes\n```\n:::\n\n\n## Pressupostos dos Testes Paramétricos\n\nOs testes **paramétricos** (t-test, ANOVA, Pearson) assumem que os dados seguem certas condições. Quando essas condições não são atendidas, devemos usar alternativas **não-paramétricas**.\n\n### Teste de Normalidade\n\nA normalidade dos dados é o pressuposto mais importante para testes paramétricos.\n\n#### Avaliação Visual\n\nO **gráfico de densidade** ou **histograma** fornece uma primeira impressão sobre a distribuição:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histograma da idade\nggplot(dados_limpos, aes(x = idade)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  labs(title = \"Distribuição da Idade\",\n       x = \"Idade (anos)\",\n       y = \"Frequência\") +\n  theme_minimal()\n```\n:::\n\n\n#### Teste de Shapiro-Wilk\n\nO **teste de Shapiro-Wilk** é o teste mais utilizado para avaliar normalidade:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de Shapiro-Wilk (para amostras < 5000)\nshapiro.test(sample(dados_limpos$idade, 5000))\n```\n:::\n\n\n**Interpretação:**\n\n- **H₀**: Os dados seguem distribuição normal\n- **p > 0,05**: Não rejeitamos H₀ → dados são normais\n- **p < 0,05**: Rejeitamos H₀ → dados não são normais\n\n**Importante:** O teste de Shapiro-Wilk é sensível ao tamanho da amostra. Com amostras muito grandes, pequenos desvios da normalidade podem ser significativos. Use também avaliação visual.\n\n#### Teste de Kolmogorov-Smirnov\n\nAlternativa para grandes amostras:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de Kolmogorov-Smirnov\nks.test(dados_limpos$idade, \"pnorm\",\n        mean = mean(dados_limpos$idade),\n        sd = sd(dados_limpos$idade))\n```\n:::\n\n\n### Homogeneidade de Variâncias\n\nPara testes que comparam grupos (t-test, ANOVA), as variâncias entre grupos devem ser similares.\n\n#### Teste de Levene\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de Levene para homogeneidade de variâncias\nleveneTest(idade ~ sexo, data = dados_limpos)\n```\n:::\n\n\n**Interpretação:**\n\n- **H₀**: As variâncias dos grupos são iguais\n- **p > 0,05**: Variâncias homogêneas → pode usar teste t padrão\n- **p < 0,05**: Variâncias heterogêneas → usar Welch's t-test\n\n## Testes Paramétricos\n\n### Teste t de Student\n\nO **teste t** compara as médias de **dois grupos independentes** assumindo distribuição normal e variâncias homogêneas.\n\n#### Quando usar?\n\n- **Variável dependente**: Numérica contínua (ex: idade, custo, tempo)\n- **Variável independente**: Categórica binária (ex: sexo, grupo tratamento/controle)\n- **Pressupostos**: Normalidade e homogeneidade de variâncias\n\n#### Exemplo: Diferença de idade entre sexos\n\n**Pergunta de pesquisa:** Há diferença na idade média de internação entre homens e mulheres?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Passo 1: Verificar pressupostos\n# Normalidade\nshapiro.test(sample(dados_limpos$idade, 5000))\n\n# Homogeneidade de variâncias\nleveneTest(idade ~ sexo, data = dados_limpos)\n\n# Passo 2: Realizar teste t\n# Se variâncias iguais (Levene p > 0.05)\nt.test(idade ~ sexo, data = dados_limpos, var.equal = TRUE)\n\n# Se variâncias diferentes (Levene p < 0.05) - Welch's t-test\nt.test(idade ~ sexo, data = dados_limpos, var.equal = FALSE)\n```\n:::\n\n\n#### Interpretação dos Resultados\n\n```\nWelch Two Sample t-test\n\ndata:  idade by sexo\nt = -5.3159, df = 28465, p-value = 1.066e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.925  -1.094\nsample estimates:\nmean in group Feminino mean in group Masculino\n              45.09                  46.60\n```\n\n**Interpretação:**\n\n- **t = -5.32**: Estatística t (quanto maior, maior a diferença entre grupos)\n- **df = 28.465**: Graus de liberdade (relacionado ao tamanho da amostra)\n- **p < 0,001**: Forte evidência de diferença significativa entre sexos\n- **IC 95% [-1,93; -1,09]**: Não inclui zero → diferença é significativa\n- **Médias**: Homens são internados, em média, 1,51 anos mais velhos que mulheres (46,60 - 45,09)\n\n#### Visualização\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dados_limpos, aes(x = sexo, y = idade, fill = sexo)) +\n  geom_boxplot(alpha = 0.6) +\n  stat_compare_means(method = \"t.test\") +  # Adiciona p-valor\n  labs(title = \"Distribuição da Idade por Sexo\",\n       x = \"Sexo\",\n       y = \"Idade (anos)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n:::\n\n\n### ANOVA (Análise de Variância)\n\nA **ANOVA** compara as médias de **três ou mais grupos independentes**.\n\n#### Quando usar?\n\n- **Variável dependente**: Numérica contínua\n- **Variável independente**: Categórica com 3+ níveis (ex: raça/cor, região, faixa etária)\n- **Pressupostos**: Normalidade dos resíduos e homogeneidade de variâncias\n\n#### Exemplo: Idade média entre grupos de raça/cor\n\n**Pergunta de pesquisa:** A idade média de internação varia entre os diferentes grupos de raça/cor?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ajustar modelo ANOVA\nmodelo_anova <- aov(idade ~ raca_cor, data = dados_limpos)\n\n# Resultados da ANOVA\nsummary(modelo_anova)\n```\n:::\n\n\n#### Interpretação dos Resultados\n\n```\n            Df   Sum Sq Mean Sq F value   Pr(>F)\nraca_cor     4    24015    6004   23.11 < 2e-16 ***\nResiduals 28994  7531748     260\n```\n\n**Interpretação:**\n\n- **F = 23,11**: Estatística F (razão entre variância entre grupos / variância dentro dos grupos)\n- **p < 0,001**: Pelo menos um grupo difere significativamente dos demais\n- **Limitação**: A ANOVA apenas indica que existe diferença, mas não informa **quais** grupos diferem\n\n#### Post-hoc: Teste de Tukey HSD\n\nPara identificar **quais grupos** diferem entre si, usamos testes post-hoc:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de Tukey para comparações múltiplas\nTukeyHSD(modelo_anova)\n```\n:::\n\n\n#### Interpretação do Teste de Tukey\n\n```\n           diff      lwr      upr   p adj\nPreta-Branca     -2.14   -3.85   -0.43  0.0047\nParda-Branca     -1.67   -2.35   -0.98  0.0000\nAmarela-Branca    0.84   -2.76    4.44  0.9785\nIndígena-Branca  -4.23  -10.80    2.34  0.4320\n...\n```\n\n**Interpretação:**\n\n- **diff**: Diferença média entre os grupos\n- **lwr / upr**: Intervalo de confiança 95%\n- **p adj**: Valor-p ajustado para múltiplas comparações\n- Se **p adj < 0,05** e o IC não inclui zero → grupos diferem significativamente\n\n**Exemplo:** Pessoas de raça Preta são internadas, em média, 2,14 anos mais jovens que pessoas de raça Branca (p = 0,0047).\n\n#### Verificação dos Pressupostos da ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Normalidade dos resíduos\nshapiro.test(sample(residuals(modelo_anova), 5000))\n\n# Q-Q plot dos resíduos\nqqnorm(residuals(modelo_anova))\nqqline(residuals(modelo_anova), col = \"red\")\n\n# 2. Homogeneidade de variâncias\nleveneTest(idade ~ raca_cor, data = dados_limpos)\n```\n:::\n\n\n#### Visualização\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dados_limpos, aes(x = raca_cor, y = idade, fill = raca_cor)) +\n  geom_boxplot(alpha = 0.6) +\n  stat_compare_means(method = \"anova\") +\n  labs(title = \"Distribuição da Idade por Raça/Cor\",\n       x = \"Raça/Cor\",\n       y = \"Idade (anos)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1))\n```\n:::\n\n\n## Testes Não-Paramétricos\n\nQuando os pressupostos dos testes paramétricos não são atendidos (dados não normais ou variâncias heterogêneas), usamos alternativas não-paramétricas.\n\n### Teste de Mann-Whitney (Wilcoxon)\n\nAlternativa não-paramétrica ao **teste t** para comparar **dois grupos independentes**.\n\n#### Quando usar?\n\n- Os dados **não** seguem distribuição normal\n- Variâncias muito heterogêneas\n- Dados ordinais (ex: escalas Likert)\n- Presença de outliers extremos\n\n#### Exemplo\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de Mann-Whitney\nwilcox.test(idade ~ sexo, data = dados_limpos)\n```\n:::\n\n\n#### Interpretação\n\n```\nWilcoxon rank sum test with continuity correction\n\ndata:  idade by sexo\nW = 98234567, p-value = 2.234e-07\nalternative hypothesis: true location shift is not equal to 0\n```\n\n**Interpretação:**\n\n- **W**: Estatística do teste (soma dos ranks)\n- **p < 0,001**: Diferença significativa entre os grupos\n- O teste compara **medianas** e distribuições, não médias\n- Para identificar a direcionalidade, calcular medianas por grupo:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados_limpos %>%\n  group_by(sexo) %>%\n  summarise(\n    Mediana = median(idade, na.rm = TRUE),\n    Media = mean(idade, na.rm = TRUE),\n    n = n()\n  )\n```\n:::\n\n\n### Teste de Kruskal-Wallis\n\nAlternativa não-paramétrica à **ANOVA** para comparar **três ou mais grupos**.\n\n#### Quando usar?\n\n- Dados não seguem distribuição normal\n- Variâncias heterogêneas\n- Variável dependente ordinal\n\n#### Exemplo\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de Kruskal-Wallis\nkruskal.test(idade ~ raca_cor, data = dados_limpos)\n```\n:::\n\n\n#### Interpretação\n\n```\nKruskal-Wallis rank sum test\n\ndata:  idade by raca_cor\nKruskal-Wallis chi-squared = 89.456, df = 4, p-value < 2.2e-16\n```\n\n**Interpretação:**\n\n- **χ² = 89,46**: Estatística do teste\n- **df = 4**: Graus de liberdade (número de grupos - 1)\n- **p < 0,001**: Pelo menos um grupo difere dos demais\n\n#### Post-hoc: Teste de Dunn\n\nPara comparações múltiplas após Kruskal-Wallis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de Dunn com correção de Bonferroni\ndunnTest(idade ~ raca_cor, data = dados_limpos, method = \"bonferroni\")\n```\n:::\n\n\n**Interpretação:** Similar ao Tukey HSD, identifica quais pares de grupos diferem significativamente.\n\n## Testes para Variáveis Categóricas\n\n### Teste Qui-Quadrado (χ²)\n\nO **teste qui-quadrado** avalia a associação entre **duas variáveis categóricas**.\n\n#### Quando usar?\n\n- Ambas as variáveis são categóricas\n- Tamanho amostral grande (todas as células da tabela de contingência devem ter frequência esperada ≥ 5)\n\n#### Exemplo: Associação entre sexo e mortalidade\n\n**Pergunta de pesquisa:** Existe associação entre sexo e mortalidade hospitalar?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Criar tabela de contingência\ntabela_contingencia <- table(dados_limpos$sexo, dados_limpos$morte)\n\n# Visualizar tabela\ntabela_contingencia\n\n# Aplicar teste qui-quadrado\nchisq.test(tabela_contingencia)\n```\n:::\n\n\n#### Interpretação\n\n```\nPearson's Chi-squared test with Yates' continuity correction\n\ndata:  tabela_contingencia\nX-squared = 12.34, df = 1, p-value = 0.0004432\n```\n\n**Interpretação:**\n\n- **X² = 12,34**: Estatística qui-quadrado (mede discrepância entre frequências observadas e esperadas)\n- **df = 1**: Graus de liberdade = (linhas - 1) × (colunas - 1)\n- **p < 0,001**: Existe associação significativa entre sexo e mortalidade\n\nPara entender a **direção** da associação:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Proporções por linha\nprop.table(tabela_contingencia, margin = 1)\n```\n:::\n\n\n#### Visualização com Mosaic Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vcd)\n\nmosaic(~ sexo + morte, data = dados_limpos,\n       shade = TRUE,\n       legend = TRUE,\n       main = \"Associação entre Sexo e Mortalidade\")\n```\n:::\n\n\n### Teste Exato de Fisher\n\nAlternativa ao qui-quadrado para **amostras pequenas** (frequência esperada < 5 em alguma célula).\n\n#### Quando usar?\n\n- Variáveis categóricas\n- Tabelas 2×2 ou pequenas\n- Frequências esperadas < 5\n\n#### Exemplo\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Criar tabela de contingência\ntabela2 <- table(dados_limpos$raca_cor, dados_limpos$sexo)\n\n# Teste exato de Fisher\nfisher.test(tabela2, simulate.p.value = TRUE)  # Simulação para tabelas maiores\n```\n:::\n\n\n**Nota:** Para tabelas maiores que 2×2, o teste pode ser computacionalmente intensivo. Use `simulate.p.value = TRUE` para aproximação por simulação.\n\n## Testes de Correlação\n\nA **correlação** mede a força e direção da relação linear entre **duas variáveis numéricas**.\n\n### Coeficiente de Correlação\n\nO coeficiente varia de **-1 a +1**:\n\n- **r = +1**: Correlação positiva perfeita\n- **r = 0**: Sem correlação linear\n- **r = -1**: Correlação negativa perfeita\n\n**Interpretação da magnitude:**\n\n| Valor de \\|r\\| | Interpretação |\n|---------------|---------------|\n| 0,00 - 0,10 | Desprezível |\n| 0,10 - 0,30 | Fraca |\n| 0,30 - 0,50 | Moderada |\n| 0,50 - 0,70 | Forte |\n| 0,70 - 1,00 | Muito forte |\n\n### Correlação de Pearson\n\nA **correlação de Pearson** mede a relação **linear** entre variáveis com distribuição normal.\n\n#### Quando usar?\n\n- Ambas as variáveis são numéricas contínuas\n- Relação linear entre as variáveis\n- Dados seguem distribuição normal\n\n#### Exemplo: Correlação entre idade e custo de internação\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de correlação de Pearson\ncor.test(dados_limpos$idade, dados_limpos$val_tot, method = \"pearson\")\n```\n:::\n\n\n#### Interpretação\n\n```\nPearson's product-moment correlation\n\ndata:  dados_limpos$idade and dados_limpos$val_tot\nt = 8.234, df = 28998, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.0357  0.0589\nsample estimates:\n      cor\n0.0473\n```\n\n**Interpretação:**\n\n- **r = 0,047**: Correlação positiva muito fraca\n- **p < 0,001**: A correlação é estatisticamente significativa\n- **IC 95% [0,036; 0,059]**: Não inclui zero → significativo\n- **Conclusão**: Embora estatisticamente significativa, a correlação é muito fraca (praticamente desprezível), indicando que idade explica apenas 0,22% da variabilidade no custo (r² = 0,047² = 0,0022)\n\n### Correlação de Spearman\n\nAlternativa não-paramétrica que mede correlação **monotônica** (não necessariamente linear).\n\n#### Quando usar?\n\n- Dados não seguem distribuição normal\n- Relação monotônica (não linear)\n- Presença de outliers\n- Dados ordinais\n\n#### Exemplo\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de correlação de Spearman\ncor.test(dados_limpos$idade, dados_limpos$val_tot, method = \"spearman\")\n```\n:::\n\n\n### Visualização de Correlação\n\n#### Gráfico de Dispersão\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dados_limpos, aes(x = idade, y = val_tot)) +\n  geom_point(alpha = 0.3, size = 1) +\n  geom_smooth(method = \"loess\", color = \"red\", se = TRUE) +\n  labs(title = \"Relação entre Idade e Custo de Internação\",\n       x = \"Idade (anos)\",\n       y = \"Custo da Internação (R$)\") +\n  scale_y_continuous(labels = scales::number_format(big.mark = \".\", decimal.mark = \",\")) +\n  theme_minimal()\n```\n:::\n\n\n**Observações:**\n\n- A curva de suavização (loess) mostra uma relação quase plana\n- Muitos outliers (custos muito altos) podem distorcer a correlação\n- A visualização confirma a correlação muito fraca encontrada no teste\n\n#### Matriz de Correlação\n\nPara examinar múltiplas correlações simultaneamente:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(corrplot)\n\n# Selecionar variáveis numéricas\nvars_numericas <- dados_limpos %>%\n  select(idade, val_tot, dias_perm) %>%\n  na.omit()\n\n# Calcular matriz de correlação\nmatriz_cor <- cor(vars_numericas, method = \"spearman\")\n\n# Visualizar\ncorrplot(matriz_cor,\n         method = \"color\",\n         type = \"upper\",\n         addCoef.col = \"black\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         diag = FALSE)\n```\n:::\n\n\n## Resumo e Recomendações\n\n### Escolhendo o Teste Apropriado\n\n1. **Identifique o tipo de variáveis:**\n   - Numéricas contínuas → testes t, ANOVA, correlação\n   - Categóricas → qui-quadrado, Fisher\n\n2. **Verifique os pressupostos:**\n   - Normalidade (Shapiro-Wilk, Q-Q plot)\n   - Homogeneidade de variâncias (Levene)\n\n3. **Escolha entre paramétrico e não-paramétrico:**\n   - Pressupostos atendidos → testes paramétricos (mais poder estatístico)\n   - Pressupostos violados → testes não-paramétricos (mais robustos)\n\n### Tabela de Decisão Rápida\n\n| **Situação** | **Teste Recomendado** |\n|--------------|----------------------|\n| Comparar 2 grupos (normal) | Teste t |\n| Comparar 2 grupos (não normal) | Mann-Whitney |\n| Comparar 3+ grupos (normal) | ANOVA + Tukey |\n| Comparar 3+ grupos (não normal) | Kruskal-Wallis + Dunn |\n| Associação entre categóricas (n grande) | Qui-quadrado |\n| Associação entre categóricas (n pequeno) | Teste Exato de Fisher |\n| Correlação (normal, linear) | Pearson |\n| Correlação (não normal, monotônica) | Spearman |\n\n### Boas Práticas\n\n1. **Sempre verifique os pressupostos** antes de escolher o teste\n2. **Visualize os dados** antes de interpretar os testes\n3. **Reporte os intervalos de confiança**, não apenas p-valores\n4. **Interprete no contexto clínico/prático**, não apenas estatístico\n5. **Use testes post-hoc** para comparações múltiplas (Tukey, Dunn)\n6. **Considere o tamanho do efeito**, não apenas significância\n\n### Reportando Resultados\n\nAo reportar resultados de testes estatísticos em artigos científicos:\n\n- **Teste t**: \"Homens foram internados com idade média significativamente maior que mulheres (46,6 vs 45,1 anos; t = -5,32; p < 0,001; IC 95%: -1,93 a -1,09)\"\n\n- **ANOVA**: \"A idade média de internação diferiu significativamente entre grupos de raça/cor (F(4, 28994) = 23,11; p < 0,001). Testes post-hoc de Tukey revelaram...\"\n\n- **Qui-quadrado**: \"Observou-se associação significativa entre sexo e mortalidade (χ² = 12,34; df = 1; p < 0,001)\"\n\n- **Correlação**: \"Idade e custo de internação apresentaram correlação positiva fraca, mas estatisticamente significativa (r = 0,047; p < 0,001; IC 95%: 0,036 a 0,059)\"\n\n## Exercícios Práticos\n\n### Exercício 1: Teste t\n\nUse o dataset de internações para responder: Existe diferença significativa no tempo de permanência hospitalar (dias_perm) entre pacientes que foram a óbito e os que sobreviveram?\n\na) Verifique os pressupostos (normalidade e homogeneidade de variâncias)\nb) Escolha o teste apropriado\nc) Realize o teste e interprete os resultados\nd) Crie um boxplot visualizando a comparação\n\n### Exercício 2: ANOVA\n\nInvestigue se o custo médio de internação (val_tot) difere entre os diferentes meses de competência (mes_cmpt).\n\na) Realize ANOVA\nb) Se significativo, faça o teste post-hoc de Tukey\nc) Identifique quais meses diferem significativamente\nd) Crie um gráfico de boxplot com os resultados\n\n### Exercício 3: Qui-quadrado\n\nAnalise se existe associação entre raça/cor (raca_cor) e mortalidade (morte).\n\na) Crie uma tabela de contingência\nb) Calcule as proporções de óbito por grupo\nc) Realize o teste qui-quadrado\nd) Crie um mosaic plot para visualizar a associação\n\n### Exercício 4: Correlação\n\nExamine a relação entre dias de permanência (dias_perm) e custo de internação (val_tot).\n\na) Crie um gráfico de dispersão\nb) Avalie a normalidade das variáveis\nc) Calcule a correlação apropriada (Pearson ou Spearman)\nd) Interprete a força e direção da correlação\n\n### Exercício 5: Comparações Múltiplas\n\nEscolha uma variável numérica e uma categórica do dataset. Realize uma análise completa:\n\na) Formule uma pergunta de pesquisa\nb) Verifique pressupostos\nc) Escolha e realize o teste apropriado\nd) Visualize os resultados\ne) Escreva uma conclusão em formato de artigo científico\n\n---\n\n**Referências:**\n\n- Field, A., Miles, J., & Field, Z. (2012). *Discovering Statistics Using R*. SAGE Publications.\n- Motulsky, H. (2014). *Intuitive Biostatistics: A Nonmathematical Guide to Statistical Thinking*. Oxford University Press.\n- Whitlock, M. C., & Schluter, D. (2015). *The Analysis of Biological Data*. Roberts and Company Publishers.\n",
    "supporting": [
      "testes-estatisticos_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}