{
  "hash": "213645f1c31ae927fe887ec0f8adb5ca",
  "result": {
    "markdown": "# Análise Psicométrica\n\n## Introdução à Psicometria\n\nA **psicometria** é uma especialidade dentro das ciências comportamentais e sociais dedicada à mensuração de fenômenos psicológicos e sociais. Em pesquisas de saúde, a psicometria é fundamental para validar instrumentos que avaliam construtos como qualidade de vida, satisfação do paciente, literacia em saúde, sintomas psicológicos, entre outros.\n\n### Por que fazer um estudo antes de fazer um estudo?\n\nEsta é a pergunta central da análise psicométrica. Antes de utilizar um questionário ou escala em uma pesquisa substantiva, é essencial validar o instrumento para garantir que ele mede o que realmente pretende medir.\n\n### O Custo de Medidas Inadequadas\n\nUsar instrumentos que não avaliam corretamente o que propõem leva a **decisões erradas** baseadas em dados não confiáveis. Enquanto uma medida imperfeita pode ser melhor que nenhuma medida, pesquisadores devem reconhecer quando os procedimentos são falhos e moderar suas conclusões adequadamente.\n\n> **Princípio fundamental:** Medidas adequadas são uma condição necessária para pesquisa válida.\n\n### Aplicações em Saúde\n\n- **Validação transcultural** de instrumentos (adaptação entre idiomas e culturas)\n- **Desenvolvimento de escalas** (criação de novos instrumentos)\n- **Avaliação de propriedades psicométricas** de questionários existentes\n- **Garantia de qualidade** dos instrumentos antes da pesquisa principal\n\n**Exemplo:** Adaptação do Questionário SF-8 para Swahili (Tanzânia) para populações com lesão cerebral traumática.\n\n## Preparação dos Dados Psicométricos\n\nNeste capítulo, utilizaremos o dataset **literacia_data.csv**, que contém respostas de uma pesquisa sobre literacia digital, incluindo dados demográficos e 10 itens de escala (L1 a L10).\n\n### Carregando Pacotes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)    # Manipulação de dados\nlibrary(psych)        # Análise psicométrica (Alpha, Omega, EFA)\nlibrary(corrplot)     # Visualização de correlações\nlibrary(lavaan)       # Análise Fatorial Confirmatória (CFA)\nlibrary(semPlot)      # Visualização de modelos SEM\nlibrary(qgraph)       # Análise de redes\nlibrary(GGally)       # Gráficos de correlação\n\n# Remover notação científica\noptions(scipen = 999)\n```\n:::\n\n\n### Importando e Explorando os Dados\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Importar dados de literacia digital\ndados <- read_csv(\"data/literacia_data.csv\")\n\n# Visualizar primeiras linhas\nhead(dados)\n\n# Estrutura do dataframe\nstr(dados)\n\n# Resumo estatístico\nsummary(dados)\n```\n:::\n\n\n### Convertendo Variáveis Categóricas\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Converter variáveis qualitativas em fatores\ndados <- dados %>%\n  mutate(across(c(sexo, etnia, estcivil, escolaridade, economia,\n                  renda, beneficio, comunicacao, celular,\n                  internet, acesso), as.factor))\n\n# Verificar estrutura após conversão\nstr(dados)\n```\n:::\n\n\n### Tratamento de Dados Faltantes\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Verificar quantidade de dados faltantes por coluna\ncolSums(is.na(dados))\n\n# Proporção de dados faltantes (%)\ncolMeans(is.na(dados)) * 100\n\n# Estratégias de tratamento:\n# 1. Exclusão listwise (casos completos)\ndados_completo <- dados[complete.cases(dados), ]\n\n# 2. Imputação por média (se apropriado)\n# dados$idade[is.na(dados$idade)] <- mean(dados$idade, na.rm = TRUE)\n```\n:::\n\n\n**Importante:** A escolha da estratégia de tratamento de dados faltantes depende do padrão dos missing data (MCAR, MAR, MNAR) e dos objetivos da pesquisa. Para análises psicométricas, geralmente preferimos casos completos.\n\n## Matriz de Correlação\n\nAntes de realizar análises fatoriais, é útil examinar a estrutura de correlações entre os itens.\n\n### Calculando e Visualizando Correlações\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecionar itens da escala de literacia (L1 a L10) e idade\ndados_cor <- dados %>%\n  select(L1:L10, idade)\n\n# Calcular matriz de correlação\nmatriz_cor <- cor(dados_cor, use = \"complete.obs\")\n\n# Visualização com corrplot - círculos\ncorrplot(matriz_cor,\n         method = \"circle\",\n         type = \"upper\",\n         tl.col = \"black\",\n         tl.srt = 45)\n\n# Visualização com números\ncorrplot(matriz_cor,\n         method = \"number\",\n         type = \"upper\",\n         tl.col = \"black\",\n         tl.srt = 45)\n\n# Visualização com cores e ordenação por clusters\ncorrplot(matriz_cor,\n         method = \"color\",\n         type = \"upper\",\n         order = \"hclust\",\n         addCoef.col = \"black\",\n         tl.col = \"black\",\n         tl.srt = 45,\n         number.cex = 0.7)\n```\n:::\n\n\n### Interpretação da Matriz de Correlação\n\nOs valores de correlação variam de -1 a +1:\n\n- **r ≈ +1**: Correlação positiva forte\n- **r ≈ 0**: Correlação fraca ou ausente\n- **r ≈ -1**: Correlação negativa forte\n\nPara análise fatorial, esperamos:\n\n- **Correlações moderadas a fortes** entre itens do mesmo fator\n- **Correlações mais fracas** entre itens de fatores diferentes\n- **Ausência de correlações muito altas** (r > 0,90), que indicam redundância\n\n### Heatmap de Correlação\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Heatmap com cores\nheatmap(matriz_cor,\n        col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(20),\n        main = \"Heatmap de Correlações - Itens de Literacia\")\n```\n:::\n\n\n## Análise de Redes\n\nA **análise de redes** oferece uma perspectiva alternativa sobre as relações entre itens, visualizando-os como nós conectados por arestas.\n\n### Criando a Rede\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecionar itens da escala\ndados_rede <- dados %>%\n  select(L1:L10) %>%\n  na.omit()\n\n# Calcular matriz de correlação\nmatriz_rede <- cor(dados_rede)\n\n# Calcular tamanho da amostra\nn_amostra <- nrow(dados_rede)\n\n# Criar rede com qgraph\nrede <- qgraph(matriz_rede,\n               graph = \"glasso\",        # Regularização LASSO\n               layout = \"spring\",       # Layout spring\n               vsize = 8,               # Tamanho dos nós\n               sampleSize = n_amostra,  # Tamanho da amostra\n               edge.labels = TRUE,      # Mostrar valores nas arestas\n               edge.label.cex = 0.8,    # Tamanho dos rótulos\n               title = \"Rede de Literacia Digital\")\n```\n:::\n\n\n### Interpretação da Análise de Redes\n\n- **Nós**: Representam as variáveis (itens)\n- **Arestas**: Representam relações entre variáveis\n- **Espessura das arestas**: Indica a força da relação\n- **Cor das arestas**: Verde = positiva, Vermelho = negativa\n- **Posição dos nós**: Algoritmo agrupa nós fortemente relacionados\n\n**Medidas de centralidade** (grau, intermediação, proximidade) podem identificar os itens mais importantes na rede.\n\n## Análise de Confiabilidade\n\nA **confiabilidade** refere-se ao grau de consistência e precisão de um instrumento de medida. Representa a proporção da variância atribuível ao verdadeiro escore da variável latente.\n\n### Alfa de Cronbach\n\nO **Alfa de Cronbach (α)** é a medida mais amplamente utilizada de consistência interna.\n\n#### Teoria\n\n- Baseado nas correlações entre itens\n- Usa a matriz de covariância dos itens\n- Valores aceitáveis: **α > 0,70**\n- Valores ideais: **0,70 < α < 0,95**\n\n**Fórmula:**\n\n$$\n\\alpha = \\frac{k}{k-1} \\left(1 - \\frac{\\sum \\sigma^2_i}{\\sigma^2_T}\\right)\n$$\n\nOnde:\n- k = número de itens\n- σ²ᵢ = variância de cada item\n- σ²_T = variância total da escala\n\n#### Calculando o Alfa de Cronbach\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecionar itens da escala\nitens_escala <- dados %>%\n  select(L1:L10) %>%\n  na.omit()\n\n# Calcular Alfa de Cronbach\nalfa <- psych::alpha(itens_escala,\n                     n.iter = 1000,      # Iterações para bootstrap\n                     check.keys = TRUE)  # Verifica itens reversos\n\n# Exibir resultados\nprint(alfa)\n```\n:::\n\n\n#### Interpretação do Output\n\n```\nReliability analysis\n\nraw_alpha std.alpha G6(smc) average_r S/N\n     0.89      0.89    0.91      0.42  8.1\n\nlower alpha upper     95% confidence boundaries\n0.87  0.89  0.91\n```\n\n**Interpretação:**\n\n- **raw_alpha = 0,89**: Alfa de Cronbach bruto (excelente consistência interna)\n- **std.alpha = 0,89**: Alfa padronizado\n- **average_r = 0,42**: Correlação média entre itens\n- **IC 95% [0,87; 0,91]**: Intervalo de confiança do alfa\n\n**Critérios de interpretação:**\n\n| Alfa de Cronbach | Consistência Interna |\n|------------------|---------------------|\n| α < 0,60 | Inaceitável |\n| 0,60 ≤ α < 0,70 | Questionável |\n| 0,70 ≤ α < 0,80 | Aceitável |\n| 0,80 ≤ α < 0,90 | Boa |\n| α ≥ 0,90 | Excelente (pode indicar redundância) |\n\n#### Limitação Importante\n\n> **\"Alpha não valida um teste\"**\n\nAlta consistência interna **não garante** que o instrumento mede o que afirma medir. Confiabilidade é necessária, mas não suficiente para validade.\n\n### Ômega de McDonald\n\nO **Ômega de McDonald (ω)** é uma medida alternativa de confiabilidade composta, considerada mais geral que o Alfa de Cronbach.\n\n#### Teoria\n\n- Calculado usando cargas fatoriais e unicidades da análise fatorial\n- Baseado em estrutura CFA\n- Mais apropriado para escalas multidimensionais\n- Valores aceitáveis: **ω > 0,70**\n\n**Fórmula:**\n\n$$\n\\omega = \\frac{(\\sum \\lambda_i)^2}{(\\sum \\lambda_i)^2 + \\sum \\theta_i}\n$$\n\nOnde:\n- λᵢ = cargas fatoriais\n- θᵢ = variâncias de erro\n\n#### Calculando o Ômega de McDonald\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcular Ômega de McDonald\nomega_result <- omega(itens_escala)\n\n# Exibir resultados\nprint(omega_result)\n```\n:::\n\n\n### Comparação: Alfa vs. Ômega\n\n| **Característica** | **Alfa de Cronbach** | **Ômega de McDonald** |\n|-------------------|---------------------|----------------------|\n| Base de cálculo | Matriz de covariância | Cargas fatoriais (CFA) |\n| Estrutura fatorial | Não requer | Requer modelo CFA |\n| Dimensionalidade | Assume unidimensionalidade | Adequado para multidimensional |\n| Generalidade | Mais restrito | Mais geral |\n\n**Recomendação:** Reporte ambos os índices quando possível, especialmente para escalas multidimensionais.\n\n## Análise Fatorial Exploratória (EFA)\n\nA **Análise Fatorial Exploratória (AFE)** é usada para **desenvolvimento de teoria**, explorando a estrutura latente dos dados sem hipóteses prévias sobre o número de fatores.\n\n### Teoria da EFA\n\n#### Características Principais\n\n1. **Natureza exploratória**: Número de fatores determinado pelos dados\n2. **Cargas não fixadas**: Padrão de cargas emerge dos dados\n3. **Redução de dimensionalidade**: Reduz muitos itens a poucos fatores latentes\n4. **Rotação**: Fatores rotacionados para interpretação mais clara\n\n#### Equação Básica\n\n$$\nX = \\Lambda F + \\epsilon\n$$\n\nOnde:\n- X = variáveis observadas (itens)\n- Λ = matriz de cargas fatoriais\n- F = fatores latentes\n- ε = erros de medida\n\n### Pressupostos da EFA\n\n#### Teste KMO (Kaiser-Meyer-Olkin)\n\nO **KMO** avalia a adequação da amostra para análise fatorial.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcular KMO\nkmo_resultado <- KMO(itens_escala)\n\n# Imprimir KMO geral\ncat(\"KMO geral:\", kmo_resultado$MSA, \"\\n\")\n\n# Interpretar resultado\nif (kmo_resultado$MSA >= 0.9) {\n  cat(\"A adequação da amostra é excelente.\\n\")\n} else if (kmo_resultado$MSA >= 0.8) {\n  cat(\"A adequação da amostra é boa.\\n\")\n} else if (kmo_resultado$MSA >= 0.7) {\n  cat(\"A adequação da amostra é razoável.\\n\")\n} else if (kmo_resultado$MSA >= 0.6) {\n  cat(\"A adequação da amostra é medíocre.\\n\")\n} else if (kmo_resultado$MSA >= 0.5) {\n  cat(\"A adequação da amostra é inadequada.\\n\")\n} else {\n  cat(\"A adequação da amostra é inaceitável.\\n\")\n}\n```\n:::\n\n\n**Critérios de interpretação:**\n\n| KMO | Adequação da Amostra |\n|-----|---------------------|\n| KMO ≥ 0,90 | Excelente |\n| 0,80 ≤ KMO < 0,90 | Boa |\n| 0,70 ≤ KMO < 0,80 | Razoável |\n| 0,60 ≤ KMO < 0,70 | Medíocre |\n| 0,50 ≤ KMO < 0,60 | Inadequada |\n| KMO < 0,50 | Inaceitável |\n\n#### Teste de Esfericidade de Bartlett\n\nTesta se a matriz de correlação é significativamente diferente de uma matriz identidade.\n\n- **H₀**: Matriz de correlação é uma matriz identidade (variáveis não correlacionadas)\n- **H₁**: Existem correlações significativas entre variáveis\n- **Desejado**: p < 0,05 (rejeitar H₀)\n\n### Determinando o Número de Fatores\n\n#### Análise Paralela\n\nA **análise paralela** é o método mais confiável para determinar o número de fatores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Realizar análise paralela\nfa.parallel(itens_escala,\n            fa = \"fa\",          # Análise fatorial (não PCA)\n            n.iter = 100,       # Número de iterações\n            main = \"Análise Paralela - Scree Plot\")\n```\n:::\n\n\n**Interpretação:**\n\n- **Linha azul**: Autovalores observados nos dados reais\n- **Linha vermelha**: Autovalores médios de dados aleatórios (simulados)\n- **Linha verde**: Autovalores do 95º percentil dos dados simulados\n- **Decisão**: Reter fatores onde a linha azul está **acima** da linha vermelha\n\n#### Regra de Kaiser (Autovalores > 1)\n\nMétodo tradicional, mas menos confiável que análise paralela.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scree plot simples\nscree(itens_escala, main = \"Scree Plot\")\n```\n:::\n\n\n### Realizando a EFA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Determinar número de fatores (baseado em análise paralela)\nn_fatores <- 4  # Ajustar baseado em análise paralela\n\n# Realizar EFA\nefa_resultado <- fa(itens_escala,\n                    nfactors = n_fatores,\n                    rotate = \"varimax\",  # Rotação ortogonal\n                    fm = \"ml\")           # Máxima verossimilhança\n\n# Imprimir resultados\nprint(efa_resultado)\n\n# Visualizar diagrama de fatores\nfa.diagram(efa_resultado)\n```\n:::\n\n\n### Interpretação das Cargas Fatoriais\n\nAs **cargas fatoriais (factor loadings)** representam a correlação entre item e fator.\n\n**Critérios de interpretação:**\n\n| Carga Fatorial | Interpretação |\n|---------------|---------------|\n| \\|λ\\| ≥ 0,70 | Excelente |\n| \\|λ\\| ≥ 0,63 | Muito boa |\n| \\|λ\\| ≥ 0,55 | Boa |\n| \\|λ\\| ≥ 0,45 | Razoável |\n| \\|λ\\| ≥ 0,32 | Fraca |\n| \\|λ\\| < 0,32 | Inaceitável |\n\n**Variância explicada**: λ² = R²\n\nExemplo: Carga de 0,70 explica 0,49 (49%) da variância do item.\n\n### Rotação de Fatores\n\n- **Varimax** (ortogonal): Fatores não correlacionados - mais simples de interpretar\n- **Oblimin** (oblíqua): Permite correlação entre fatores - mais realista em muitos contextos\n\n### EFA Unidimensional (Exemplo com Literacia)\n\nSe a teoria sugere que o instrumento é unidimensional:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# EFA com 1 fator (modelo teórico unidimensional)\nefa_uni <- fa(itens_escala,\n              nfactors = 1,\n              rotate = \"none\",   # Sem rotação (1 fator)\n              fm = \"ml\")\n\n# Resultados\nprint(efa_uni)\n\n# Diagrama\nfa.diagram(efa_uni)\n```\n:::\n\n\n## Análise Fatorial Confirmatória (CFA)\n\nA **Análise Fatorial Confirmatória (AFC)** é usada para **testar teoria**, verificando se uma estrutura fatorial pré-especificada se ajusta aos dados.\n\n### Teoria da CFA\n\n#### Características Principais\n\n1. **Natureza confirmatória**: Número de fatores especificado *a priori*\n2. **Cargas fixadas**: Padrão de cargas especificado antes da análise\n3. **Testa teoria**: Verifica se estrutura teórica se ajusta aos dados empíricos\n4. **Fatores correlacionados**: Geralmente permite correlações entre fatores\n\n#### Diferenças EFA vs. CFA\n\n| **Aspecto** | **EFA** | **CFA** |\n|------------|---------|---------|\n| Objetivo | Desenvolvimento de teoria | Teste de teoria |\n| Fatores | Determinados pelos dados | Especificados *a priori* |\n| Cargas | Não fixadas | Padrão fixo |\n| Rotação | Sim (para interpretação) | Não aplicável |\n| Correlação entre fatores | Geralmente ortogonais | Geralmente correlacionados |\n| Erros correlacionados | Não permitidos | Podem ser permitidos |\n| Testes estatísticos | Limitados | Extensivos (índices de ajuste) |\n\n### Especificação do Modelo no lavaan\n\nO pacote **lavaan** usa sintaxe intuitiva para especificar modelos CFA.\n\n#### Sintaxe básica\n\n```\n# =~ define fatores latentes\n# ~~ define correlações/covariâncias\n```\n\n#### Exemplo: Modelo Unidimensional\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Carregar lavaan\nlibrary(lavaan)\n\n# Especificar modelo unidimensional\nmodelo_cfa <- '\n  # Definição do fator latente\n  Literacia =~ L1 + L2 + L3 + L4 + L5 + L6 + L7 + L8 + L9 + L10\n'\n\n# Estimar modelo\najuste_cfa <- cfa(modelo_cfa,\n                  data = itens_escala,\n                  estimator = \"ML\")  # Máxima verossimilhança\n\n# Sumarizar resultados\nsummary(ajuste_cfa,\n        fit.measures = TRUE,    # Mostrar índices de ajuste\n        standardized = TRUE)    # Mostrar coeficientes padronizados\n```\n:::\n\n\n#### Exemplo: Modelo Bidimensional\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modelo com 2 fatores correlacionados\nmodelo_cfa_2f <- '\n  # Definição dos fatores\n  Fator1 =~ L1 + L2 + L3 + L4 + L5\n  Fator2 =~ L6 + L7 + L8 + L9 + L10\n'\n\n# Estimar modelo\najuste_cfa_2f <- cfa(modelo_cfa_2f, data = itens_escala)\n\n# Resultados\nsummary(ajuste_cfa_2f, fit.measures = TRUE, standardized = TRUE)\n```\n:::\n\n\n### Índices de Ajuste do Modelo\n\nOs **índices de ajuste (fit indices)** avaliam o quão bem o modelo teórico se ajusta aos dados observados.\n\n#### 1. Qui-Quadrado (χ²)\n\n**Teste formal de ajuste exato:**\n\n- **H₀**: O modelo se ajusta perfeitamente aos dados\n- **Bom ajuste**: p > 0,05 (não rejeitar H₀)\n- **Problema**: Sensível ao tamanho da amostra (sempre significativo com n grande)\n\n**Qui-quadrado normalizado:**\n\n- **χ²/df < 2**: Bom ajuste\n- **χ²/df < 3**: Ajuste aceitável\n\n#### 2. CFI (Comparative Fit Index)\n\n- Compara o modelo proposto com modelo nulo (independência)\n- **Bom ajuste**: CFI ≥ 0,95\n- **Ajuste aceitável**: CFI ≥ 0,90\n\n#### 3. TLI (Tucker-Lewis Index)\n\n- Similar ao CFI, mas penaliza complexidade do modelo\n- **Bom ajuste**: TLI ≥ 0,95\n- **Ajuste aceitável**: TLI ≥ 0,90\n\n#### 4. RMSEA (Root Mean Square Error of Approximation)\n\n- Mede erro de aproximação na população\n- **Bom ajuste**: RMSEA ≤ 0,05\n- **Ajuste aceitável**: RMSEA ≤ 0,08\n- **Ajuste mediocre**: 0,08 < RMSEA ≤ 0,10\n- **Ajuste ruim**: RMSEA > 0,10\n\n**Importante:** O IC 90% do RMSEA também deve ser considerado.\n\n#### 5. SRMR (Standardized Root Mean Square Residual)\n\n- Raiz quadrada média do resíduo padronizado\n- **Bom ajuste**: SRMR ≤ 0,05\n- **Ajuste aceitável**: SRMR ≤ 0,08\n\n### Tabela Resumo de Critérios de Ajuste\n\n| **Índice** | **Bom Ajuste** | **Ajuste Aceitável** |\n|-----------|---------------|---------------------|\n| χ²/df | ≤ 2 | ≤ 3 |\n| CFI | ≥ 0,95 | ≥ 0,90 |\n| TLI | ≥ 0,95 | ≥ 0,90 |\n| RMSEA | ≤ 0,05 | ≤ 0,08 |\n| SRMR | ≤ 0,05 | ≤ 0,08 |\n\n### Interpretação dos Resultados da CFA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exibir índices de ajuste\nfitMeasures(ajuste_cfa, c(\"chisq\", \"df\", \"pvalue\", \"cfi\", \"tli\", \"rmsea\", \"srmr\"))\n\n# Exibir cargas fatoriais padronizadas\nstandardizedSolution(ajuste_cfa)\n\n# Exibir R² dos itens\ninspect(ajuste_cfa, \"r2\")\n```\n:::\n\n\n### Modificação de Modelos\n\nSe o modelo não ajustar bem, considere modificações baseadas em:\n\n1. **Teoria**: Modificações devem ser teoricamente justificáveis\n2. **Índices de modificação**: Sugestões estatísticas do lavaan\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Índices de modificação\nmodindices(ajuste_cfa, sort = TRUE, maximum.number = 10)\n```\n:::\n\n\n**Cuidado:** Não realize modificações baseadas apenas em estatísticas - sempre justifique teoricamente.\n\n### Visualização do Modelo com semPaths\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(semPlot)\n\n# Plotar modelo CFA\nsemPaths(ajuste_cfa,\n         what = \"std\",             # Coeficientes padronizados\n         layout = \"tree2\",         # Layout hierárquico\n         edge.label.cex = 0.8,     # Tamanho das etiquetas\n         sizeMan = 8,              # Tamanho dos nós observados\n         sizeLat = 10,             # Tamanho dos nós latentes\n         esize = 1,                # Tamanho das setas\n         residuals = TRUE,         # Mostrar resíduos\n         intercepts = FALSE,       # Não mostrar interceptos\n         title = TRUE,\n         nCharNodes = 0)           # Sem abreviação de nomes\n```\n:::\n\n\n**Elementos do diagrama:**\n\n- **Retângulos**: Variáveis observadas (itens)\n- **Elipses/Círculos**: Variáveis latentes (fatores)\n- **Setas unidirecionais (→)**: Relações de regressão\n- **Setas bidirecionais (↔)**: Correlações/Covariâncias\n- **Pequenos círculos → retângulos**: Erros de medida\n\n## Validação de Constructo\n\nA **validação baseada na estrutura interna** avalia se as relações entre itens e componentes do teste se conformam ao constructo teórico.\n\n### Métodos de Validação\n\n1. **Análise fatorial** (EFA e CFA)\n2. **Correlações item-total**\n3. **Correlações inter-itens**\n4. **Coeficientes de confiabilidade** (α, ω)\n\n### Critérios de Avaliação\n\n- Agrupamento de itens corresponde à teoria\n- Índices de ajuste adequados (CFA)\n- Confiabilidade aceitável\n- Cargas fatoriais apropriadas\n\n## Exercícios Práticos\n\n### Exercício 1: Confiabilidade\n\nUse o dataset de literacia para:\n\na) Calcular o Alfa de Cronbach para os 10 itens\nb) Calcular o Ômega de McDonald\nc) Identificar se algum item reduz a confiabilidade (item-total correlations)\nd) Comparar os dois índices e interpretar os resultados\n\n### Exercício 2: Análise Fatorial Exploratória\n\na) Calcule o KMO e interprete a adequação da amostra\nb) Realize análise paralela para determinar o número de fatores\nc) Realize EFA com o número apropriado de fatores\nd) Interprete as cargas fatoriais e nomeie os fatores\ne) Compare a solução unidimensional vs. multidimensional\n\n### Exercício 3: Análise Fatorial Confirmatória\n\na) Especifique um modelo CFA unidimensional para os 10 itens\nb) Estime o modelo e avalie os índices de ajuste\nc) Examine as cargas fatoriais padronizadas\nd) Se o ajuste for inadequado, explore índices de modificação\ne) Visualize o modelo final com semPaths\n\n### Exercício 4: Comparação de Modelos\n\nCompare três modelos CFA:\n\n- **Modelo 1**: Unidimensional (1 fator geral)\n- **Modelo 2**: Bidimensional (2 fatores correlacionados)\n- **Modelo 3**: Hierárquico (2 fatores de primeira ordem + 1 fator de segunda ordem)\n\na) Especifique e estime os três modelos\nb) Compare os índices de ajuste\nc) Use o teste qui-quadrado de diferença para modelos aninhados\nd) Selecione o melhor modelo e justifique\n\n### Exercício 5: Análise de Redes\n\na) Crie uma rede psicométrica para os 10 itens\nb) Identifique os itens mais centrais na rede\nc) Examine se há comunidades (clusters) de itens\nd) Compare a estrutura da rede com os resultados da análise fatorial\n\n---\n\n**Referências:**\n\n- Cronbach, L. J. (1951). Coefficient alpha and the internal structure of tests. *Psychometrika*, 16(3), 297-334.\n- DeVellis, R. F. (2003). *Scale Development: Theory and Applications*. SAGE Publications.\n- Fornell, C., & Larcker, D. F. (1981). Evaluating structural equation models with unobservable variables and measurement error. *Journal of Marketing Research*, 18(1), 39-50.\n- Hu, L. T., & Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis. *Structural Equation Modeling*, 6(1), 1-55.\n- McDonald, R. P. (1999). *Test Theory: A Unified Treatment*. Lawrence Erlbaum Associates.\n- Rosseel, Y. (2012). lavaan: An R package for structural equation modeling. *Journal of Statistical Software*, 48(2), 1-36.\n",
    "supporting": [
      "psicometria_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}